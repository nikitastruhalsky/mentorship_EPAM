{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3382be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.environ['PROJECT_ROOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabad7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import shap\n",
    "import pdpipe as pdp\n",
    "import statsmodels.api as sm\n",
    "from optuna.integration.lightgbm import LightGBMTunerCV\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import LGBMRegressor\n",
    "from boruta import BorutaPy\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, MetaEstimatorMixin, TransformerMixin, clone\n",
    "from datetime import timedelta\n",
    "from category_encoders import TargetEncoder\n",
    "from statistics import median, mean, stdev\n",
    "from pdpipe import df, PdPipelineStage\n",
    "from pathlib import Path\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from mentorship.ml.models.reg import PositiveRegressor\n",
    "from mentorship.ml.models.common import SplitPipeline\n",
    "from mentorship.ml.models.kaggle.storesales.boosting import PipelineLGBMRegressor\n",
    "from mentorship.features.kaggle.storesales.etl import ETLTransformer\n",
    "from mentorship.features.history import cut_history\n",
    "from mentorship.ml.cv.split import DateTimeSeriesSplit\n",
    "from mentorship.ml.cv.util import print_cv_test_scores\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_METRICS = [\n",
    "    'neg_mean_squared_log_error',\n",
    "    'neg_root_mean_squared_error',\n",
    "    'neg_mean_absolute_error',\n",
    "    'r2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc28e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('data', 'kaggle', 'store-sales-time-series-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271bf15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STORES = train['store_nbr'].nunique()\n",
    "N_FAMILIES = train['family'].nunique()\n",
    "N_TIME_SERIES = N_STORES * N_FAMILIES\n",
    "\n",
    "DAYS_IN_YEAR = 365\n",
    "N_HORIZONS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a16bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositiveRegressor1(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator, fit_params={}):\n",
    "        \"\"\"Regressor that always predicts positive values\"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.fit_params = fit_params\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self.estimator.fit(X, y, **self.fit_params)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.estimator.predict(X)\n",
    "        return np.clip(y_pred, 0, None)\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        \"\"\"\n",
    "        Return attributes of the underlying estimator\n",
    "        (for easier hyper-parameter tuning)\n",
    "        \"\"\"\n",
    "        if item in self.__dict__.keys():\n",
    "            return getattr(self, item)\n",
    "        else:\n",
    "            return getattr(self.estimator, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveTSEstimator1(BaseEstimator):\n",
    "    def __init__(self, base_pipeline, split_key):\n",
    "        self.split_key = split_key\n",
    "        self.base_pipeline = base_pipeline\n",
    "        self.pipelines_ = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for key, X_part in X.groupby(self.split_key):\n",
    "            y_part = y.loc[X_part.index]\n",
    "            pipeline = clone(self.base_pipeline)\n",
    "            \n",
    "            if pipeline.use_final_metric:\n",
    "                y_part = np.log(y_part + 1)\n",
    "            \n",
    "            pipeline = pipeline.fit(X_part.drop(columns=[self.split_key]), y_part)\n",
    "            \n",
    "            self.pipelines_[key] = pipeline\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_preds = {}\n",
    "        for split_key_value, X_part in X.groupby(self.split_key):\n",
    "            pipeline = self.pipelines_[split_key_value]\n",
    "            \n",
    "            sorted_dates = X_part[pipeline.date_column].unique()\n",
    "            sorted_dates.sort()\n",
    "            for current_day_number, current_day in enumerate(sorted_dates):\n",
    "                X_current_day = X_part[X_part[pipeline.date_column] == current_day]\n",
    "                for lag in pipeline.lags:\n",
    "                    # filling lags with the predictions of previous test days\n",
    "                    if current_day_number + 1 > lag:\n",
    "                        X_current_day['lag_{}'.format(lag)] = y_preds[(split_key_value, str(pd.to_datetime(current_day) - timedelta(days=lag)).split(' ')[0])].tolist()\n",
    "                \n",
    "                y_pred = pipeline.predict(X_current_day.drop(columns=self.split_key))\n",
    "                y_preds[(split_key_value, current_day)] = pd.Series(data=y_pred, index=X_current_day.index, name='forecast')\n",
    "                \n",
    "            if pipeline.use_final_metric:\n",
    "                for current_key in [key for key in y_preds.keys() if key[0] == split_key_value]:\n",
    "                    y_preds[current_key] = np.exp(y_preds[current_key]) - 1\n",
    "                    \n",
    "        y_pred = pd.concat(y_preds.values()).loc[X.index]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LagComputer1(PdPipelineStage):\n",
    "    def __init__(self, target_col, lags, split_key, date_column='date'):\n",
    "        self.split_key = split_key\n",
    "        self.lags = lags\n",
    "        self.target_col = target_col\n",
    "        self.date_column = date_column\n",
    "        self.is_fitted = False\n",
    "        super_kwargs = {\n",
    "            'exraise': True,\n",
    "            'desc': 'Pipeline for lags computing',\n",
    "        }\n",
    "        super().__init__(**super_kwargs)\n",
    "    \n",
    "    def _prec(self, X: pd.DataFrame) -> bool:\n",
    "        if self.date_column not in X.columns:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _fit_transform(self, X, verbose=None):\n",
    "        X_last_date = pd.to_datetime(X[self.date_column].max())\n",
    "\n",
    "        # saving last train days for test data\n",
    "        max_lag = max(self.lags)\n",
    "        self.last_days_train = X[X[self.date_column] > str(X_last_date - pd.Timedelta(days=max_lag)).split(' ')[0]]\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return X\n",
    "\n",
    "\n",
    "    def _transform(self, X, verbose=None):\n",
    "        if self.target_col not in X.columns:\n",
    "\n",
    "            # filling lags for test data with last days 'target' in X\n",
    "            for current_lag in self.lags:\n",
    "                if str(pd.to_datetime(X[self.date_column].unique()[0]) - pd.Timedelta(days=current_lag)).split(' ')[0] in self.last_days_train[self.date_column].unique():\n",
    "                    X['lag_{}'.format(current_lag)] = self.last_days_train[self.last_days_train[self.date_column] == str(pd.to_datetime(X[self.date_column].unique()[0]) - pd.Timedelta(days=current_lag)).split(' ')[0]][self.target_col].tolist()\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d182b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpipe.skintegrate import PdPipelineAndSklearnEstimator\n",
    "\n",
    "class LinearPipeline1(PdPipelineAndSklearnEstimator):\n",
    "    def __init__(self, split_key, target_col, cols_to_scale=None, cols_to_encode=None, drop_columns=None, date_column='date', \n",
    "                 lags=None, fit_params={}, use_final_metric=False):\n",
    "        self.cols_to_scale = cols_to_scale\n",
    "        self.cols_to_encode = cols_to_encode\n",
    "        self.date_column = date_column\n",
    "        self.drop_columns = drop_columns\n",
    "        self.lags = lags\n",
    "        self.split_key = split_key\n",
    "        self.target_col = target_col\n",
    "        self.fit_params = fit_params\n",
    "        self.use_final_metric = use_final_metric\n",
    "\n",
    "        pipeline = pdp.PdPipeline([\n",
    "            LagComputer1(target_col=self.target_col, lags=self.lags, split_key=self.split_key, date_column=self.date_column),\n",
    "            pdp.Scale('MinMaxScaler', self.cols_to_scale),\n",
    "            pdp.OneHotEncode(self.cols_to_encode),\n",
    "            pdp.ColDrop(self.drop_columns + [self.target_col, self.date_column], errors='ignore'),\n",
    "        ])\n",
    "        \n",
    "        model = PositiveRegressor1(LinearRegression(), fit_params=self.fit_params)\n",
    "\n",
    "        super().__init__(pipeline=pipeline, estimator=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpipe.skintegrate import PdPipelineAndSklearnEstimator\n",
    "\n",
    "class LGBMPipeline1(PdPipelineAndSklearnEstimator):\n",
    "    def __init__(self, split_key, target_col, drop_columns=None, date_column='date', lags=None, fit_params={}, \n",
    "                 use_final_metric=False):\n",
    "        self.date_column = date_column\n",
    "        self.drop_columns = drop_columns\n",
    "        self.lags = lags\n",
    "        self.split_key = split_key\n",
    "        self.target_col = target_col\n",
    "        self.fit_params = fit_params\n",
    "        self.use_final_metric = use_final_metric\n",
    "\n",
    "        pipeline = pdp.PdPipeline([\n",
    "            LagComputer1(target_col=self.target_col, lags=self.lags, split_key=self.split_key, date_column=self.date_column),\n",
    "            pdp.ColDrop(self.drop_columns + [self.target_col, self.date_column], errors='ignore'),\n",
    "        ])\n",
    "        \n",
    "        model = PositiveRegressor1(LGBMRegressor(), fit_params=self.fit_params)\n",
    "\n",
    "        super().__init__(pipeline=pipeline, estimator=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETLTransformer1(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_column, id_column, adding_lags=True, lags=None, target_col=None, use_final_metric=False):\n",
    "        self.date_column = date_column\n",
    "        self.id_column = id_column\n",
    "        self.oil_data = pd.read_csv(DATA_ROOT / 'oil.csv')\n",
    "        self.adding_lags = adding_lags\n",
    "        self.lags = lags\n",
    "        self.target_col = target_col\n",
    "        self.use_final_metric = use_final_metric\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.merge(self.oil_data, on=self.date_column, how='left')\n",
    "        X['dcoilwtico'] = X['dcoilwtico'].fillna(method='ffill')\n",
    "        X = X.sort_values(by=[self.id_column], ascending=True, ignore_index=True)\n",
    "        X = X.drop(columns=[self.id_column])\n",
    "        X['family'] = X['family'].str.lower()\n",
    "        \n",
    "        # lags for train set\n",
    "        if self.adding_lags:\n",
    "            X_copy = X.copy()\n",
    "            if self.use_final_metric:\n",
    "                X_copy['sales'] = np.log(X_copy['sales'] + 1)\n",
    "            for current_lag in self.lags:\n",
    "                X.loc[:, 'lag_{}'.format(current_lag)] = X_copy.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_test_scores1(scores):\n",
    "    for metric_name, metric_values in scores.items():\n",
    "        if metric_name.startswith('test_'):\n",
    "            metric_name = metric_name[len('test_'):]\n",
    "            if metric_name.startswith('neg_'):\n",
    "                metric_name = metric_name[len('neg_'):]\n",
    "                metric_values = -metric_values.copy()\n",
    "\n",
    "            if metric_name == 'mean_squared_log_error':\n",
    "                metric_name = 'root_mean_squared_log_error'\n",
    "                metric_values = np.sqrt(metric_values)\n",
    "                scores_RMSLE = metric_values\n",
    "\n",
    "            print(f'{metric_name}: {metric_values.mean():.3f} ± {metric_values.std():.3f}')\n",
    "    plt.plot(scores_RMSLE)\n",
    "    plt.xlabel('Fold number')\n",
    "    plt.ylabel('RMSLE value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a28276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cv_test_scores1(scores):\n",
    "    mean_scores = {}\n",
    "    for metric_name, metric_values in scores.items():\n",
    "        if metric_name.startswith('test_'):\n",
    "            metric_name = metric_name[len('test_'):]\n",
    "            if metric_name.startswith('neg_'):\n",
    "                metric_name = metric_name[len('neg_'):]\n",
    "                metric_values = -metric_values.copy()\n",
    "\n",
    "            if metric_name == 'mean_squared_log_error':\n",
    "                metric_name = 'root_mean_squared_log_error'\n",
    "                metric_values = np.sqrt(metric_values)\n",
    "\n",
    "            mean_scores[metric_name] = f'{metric_values.mean():.3f} ± {metric_values.std():.3f}'\n",
    "\n",
    "    return mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69744941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "def cut_history1(\n",
    "    X: pd.DataFrame,\n",
    "    date_column: str,\n",
    "    keep_interval: pd.Timedelta,\n",
    "    y: Optional[pd.Series] = None\n",
    ") -> Tuple[pd.DataFrame, Optional[pd.Series]]:\n",
    "\n",
    "    last_date = pd.to_datetime(X[date_column].max())\n",
    "    X_train = X[X[date_column] >= str(last_date - keep_interval).split(' ')[0]]\n",
    "    if y is not None:\n",
    "        assert X.index.equals(y.index)\n",
    "        y = y.loc[X_train.index]\n",
    "\n",
    "    return X_train, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b762b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission_file(test_data, model, output_path):\n",
    "    submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "    submission['sales'] = model.predict(test_data)\n",
    "    submission.to_csv(DATA_ROOT / output_path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d4207",
   "metadata": {},
   "source": [
    "# 0.1 test (linear regression with best lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4dc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL stage for the train data\n",
    "\n",
    "lags = [1, 2, 4, 6, 7, 14]\n",
    "\n",
    "X = train.copy()\n",
    "train_transformer = ETLTransformer1(date_column='date', id_column='id', lags=lags, use_final_metric=True)\n",
    "X = train_transformer.transform(X)[0]\n",
    "\n",
    "y = X['sales'].copy()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "\n",
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = LinearPipeline1(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], drop_columns=['onpromotion'], \n",
    "                                lags=lags, split_key='family', target_col='sales', use_final_metric=True)\n",
    "modelling_pipeline = RecursiveTSEstimator1(base_pipeline, split_key='family')\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise')\n",
    "print_cv_test_scores1(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdb33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting X_train and y_train for the final model training\n",
    "\n",
    "X_train, y_train = cut_history1(X=X, date_column='date', keep_interval=pd.Timedelta(days=DAYS_IN_YEAR), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c80b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL stage for the test data\n",
    "\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer1(date_column='date', id_column='id', adding_lags=False)\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c36fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fitting the final model and making submission file\n",
    "\n",
    "modelling_pipeline.fit(X_train, y_train)\n",
    "make_submission_file(test_data, modelling_pipeline, 'linreg_with_recursive_lags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3895a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76813066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bf43c62",
   "metadata": {},
   "source": [
    "# 0.2 test (LGBMRegressor with default params, same features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 4, 6, 7, 14]\n",
    "\n",
    "X = train.copy()\n",
    "train_transformer = ETLTransformer1(date_column='date', id_column='id', lags=lags)\n",
    "X = train_transformer.transform(X)[0]\n",
    "\n",
    "y = X['sales'].copy()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc198ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here I have a question: how to pass 'categorical_feature' parameter to the PositiveRegressor(lgb.LGBMRegressor)?\n",
    "# Inside 'fit' method, X matrix has np.ndarray type, so I can't pass the name of the feature to 'categorical_feature' parameter.\n",
    "# That is why I have to pass indices of the columns I need to mark as 'categorical' (indices become clear only \n",
    "# after ColDrop stage)\n",
    "\n",
    "\n",
    "fit_params = {'categorical_feature': [0], 'eval_metric': 'rmse'}\n",
    "\n",
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = LGBMPipeline1(drop_columns=['onpromotion'], lags=lags, split_key='family', target_col='sales', fit_params=fit_params)\n",
    "modelling_pipeline = RecursiveTSEstimator1(base_pipeline, split_key='family')\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise')\n",
    "print_cv_test_scores1(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history1(X=X, date_column='date', keep_interval=pd.Timedelta(days=DAYS_IN_YEAR), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer1(date_column='date', id_column='id', adding_lags=False)\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train, y_train)\n",
    "make_submission_file(test_data, modelling_pipeline, 'default_LGBM_with_recursive_lags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb116b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a372c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7be092d6",
   "metadata": {},
   "source": [
    "##########################################################################################\n",
    "\n",
    "Next code isn't ready yet.\n",
    "\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8964f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e8a529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a5557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847a3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0017d610",
   "metadata": {},
   "source": [
    "# 1. LightGBM Regressor (one for all families), features: 'store_nbr', 'family', 'dcoilwtico', 'lag' (1, 2, 4, 6, 7, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eecabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X['dcoilwtico'].notna()]\n",
    "X = X.reset_index(drop=True)\n",
    "\n",
    "for current_lag in days_to_shift:\n",
    "    X['lag_{}'.format(current_lag)] = X.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)\n",
    "\n",
    "X = X.dropna()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8abc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns=['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19858eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['family'] = LabelEncoder().fit_transform(X['family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ends = [(16 - x) for x in days_to_shift]\n",
    "ends.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    model = lgb.LGBMRegressor()\n",
    "    model.fit(X_train.drop(columns=['date']), y_train, categorical_feature=['store_nbr', 'family'])\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    days_to_shift_copy = days_to_shift.copy()\n",
    "    start = 0\n",
    "    current_day_index = 0\n",
    "    for end in ends:\n",
    "        for current_day in X_test['date'].unique()[start:end]:\n",
    "            current_day_plus_x = {}\n",
    "            for current_lag in days_to_shift_copy:\n",
    "                current_day_plus_x[current_lag] = X_test['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "            X_test_for_current_day = X_test[X_test['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "            predictions = model.predict(X_test_for_current_day)\n",
    "            predictions[predictions < 0] = 0\n",
    "                \n",
    "            for current_lag in days_to_shift_copy:\n",
    "                X_test.loc[X_test[X_test['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "            current_day_index += 1\n",
    "                \n",
    "        days_to_shift_copy = days_to_shift_copy[:-1]\n",
    "        start = end\n",
    "\n",
    "        \n",
    "    y_pred = model.predict(X_test.drop(columns=['date', 'pred']))\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945a82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3972dace",
   "metadata": {},
   "source": [
    "# 2. LightGBM Regressor for every family, features: 'store_nbr', 'dcoilwtico', 'lag' (1, 2, 4, 6, 7, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b163fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 4, 6, 7, 14]\n",
    "\n",
    "X = train.copy()\n",
    "train_transformer = ETLTransformer1(date_column='date', id_column='id', lags=lags, use_final_metric=True)\n",
    "X = train_transformer.transform(X)[0]\n",
    "\n",
    "y = X['sales'].copy()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e706621",
   "metadata": {},
   "source": [
    "#### Compare scores for each family (linear regression and simplest lgbm regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168005ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "\n",
    "base_pipeline_linear = LinearPipeline1(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], drop_columns=['onpromotion'],\n",
    "                                       lags=lags, split_key='family', target_col='sales', use_final_metric=True)\n",
    "modelling_pipeline_linear = RecursiveTSEstimator1(base_pipeline_linear, split_key='family')\n",
    "\n",
    "fit_params_lgbm = {'categorical_feature': [0], 'eval_metric': 'rmse'}\n",
    "base_pipeline_lgbm = LGBMPipeline1(drop_columns=['onpromotion'], lags=lags, split_key='family', target_col='sales', \n",
    "                                   fit_params=fit_params_lgbm, use_final_metric=True)\n",
    "modelling_pipeline_lgbm = RecursiveTSEstimator1(base_pipeline_lgbm, split_key='family')\n",
    "\n",
    "final_scores_linear, final_scores_lgbm = {}, {}\n",
    "for current_family in X['family'].unique():\n",
    "    print(current_family)\n",
    "    X_current_family = X[X['family'] == current_family]\n",
    "    y_current_family = y.loc[X_current_family.index]\n",
    "    scores_linear = cross_validate(modelling_pipeline_linear, X_current_family, y_current_family, cv=splitter, \n",
    "                                   scoring=CV_METRICS, return_estimator=True, error_score='raise')\n",
    "    scores_lgbm = cross_validate(modelling_pipeline_lgbm, X_current_family, y_current_family, cv=splitter, \n",
    "                                 scoring=CV_METRICS, return_estimator=True, error_score='raise')\n",
    "    \n",
    "    final_scores_linear[current_family] = save_cv_test_scores1(scores_linear)\n",
    "    final_scores_lgbm[current_family] = save_cv_test_scores1(scores_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62457d94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in final_scores_linear.keys():\n",
    "    print(f'{key}: {final_scores_linear[key][\"root_mean_squared_log_error\"]}')\n",
    "    print(f'{key}: {final_scores_lgbm[key][\"root_mean_squared_log_error\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4f3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0df842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f2403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbddf663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd23c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_categories = ['baby care', 'beauty', 'books', 'frozen foods', 'grocery ii', 'home appliances', 'ladieswear', \n",
    "                     'lawn and garden', 'magazines', 'school and office supplies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=DAYS_IN_YEAR), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_lgbm_families = ['baby care', 'books', 'home appliances']\n",
    "\n",
    "for current_family in bad_lgbm_families:\n",
    "    print(current_family)\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family_lgbm = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "    \n",
    "    lgbm_model = lgb.LGBMRegressor(importance_type='gain')\n",
    "    lgbm_model.fit(X_train_current_family_lgbm.drop(columns=['date']), y_train_current_family, categorical_feature=['store_nbr'])\n",
    "    \n",
    "    \n",
    "    X_train_current_family_linear = pd.get_dummies(X_train_current_family_lgbm, columns=['store_nbr'], drop_first=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_current_family_linear[['dcoilwtico']] = scaler.fit_transform(X_train_current_family_linear[['dcoilwtico']])   \n",
    "    linear_model = PositiveRegressor(LinearRegression())\n",
    "    linear_model.fit(X_train_current_family_linear.drop(columns=['date']), y_train_current_family)\n",
    "    \n",
    "    \n",
    "    # linear regression feature importance (weights)\n",
    "    linear_feature_imp = pd.DataFrame(sorted(zip(linear_model.coef_, X_train_current_family_linear.drop(columns=['date']).columns)), columns=['Value', 'Feature'])\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.barplot(x='Value', y='Feature', data=linear_feature_imp.sort_values(by='Value', ascending=False))\n",
    "    plt.title('LinearRegression')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # lgbm feature importance\n",
    "    lgbm_feature_imp = pd.DataFrame(sorted(zip(lgbm_model.feature_importances_, X_train_current_family_lgbm.drop(columns=['date']).columns)), columns=['Value', 'Feature'])\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.barplot(x='Value', y='Feature', data=lgbm_feature_imp.sort_values(by='Value', ascending=False))\n",
    "    plt.title('LightGBM')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab8eb4b",
   "metadata": {},
   "source": [
    "\n",
    "#### Learning curve for default lgbm regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=None, n_jobs=None, scoring=None, train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                        fit_params=None):\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, scoring=scoring, cv=cv, train_sizes=train_sizes, \n",
    "                                                            fit_params=fit_params)\n",
    "    \n",
    "    train_scores_mean = np.mean(-train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(-test_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    plt.grid()\n",
    "    plt.plot(train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3916e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def plotting_validation_curve(estimator, X, y, param_name, param_range, split_key, scoring, cv=None, date_column='date'):\n",
    "    for current_split_key in X[split_key].unique():\n",
    "        X_current_split_key = X[X[split_key] == current_split_key].drop(columns=[date_column, split_key])\n",
    "        y_current_split_key = y.iloc[X_current_split_key.index]\n",
    "\n",
    "        train_scores, test_scores = validation_curve(estimator, X_current_split_key, y_current_split_key, param_name=param_name,\n",
    "                                                     param_range=param_range, scoring=scoring, cv=cv)\n",
    "        \n",
    "        train_scores_mean = np.mean(-train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(-test_scores, axis=1)\n",
    "        \n",
    "        plt.plot(param_range, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "        plt.plot(param_range, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
    "        \n",
    "        plt.title('{}: Validation Curve with LGBMRegressor'.format(current_split_key))\n",
    "        plt.xlabel('n_estimators')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear models\n",
    "for i, current_family in enumerate(X['family'].unique()):\n",
    "    plt.figure(figsize=(20, 130))\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 1)\n",
    "    X_current_family = X[X['family'] == current_family].drop(columns=['family', 'date'])\n",
    "    y_current_family = y.loc[X_current_family.index]\n",
    "    \n",
    "    titles = {'RMSLE': '{}: Learning Curves (default LGBM Regressor), RMSLE'.format(current_family), \n",
    "              'MAE': '{}: Learning Curves (default LGBM Regressor), MAE'.format(current_family)}\n",
    "    tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 120) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "    model = PositiveRegressor(LinearRegression())\n",
    "    plot_learning_curve(model, titles['MAE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 2)\n",
    "    plot_learning_curve(model, titles['RMSLE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_squared_log_error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb018f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, current_family in enumerate(X['family'].unique()):\n",
    "    plt.figure(figsize=(20, 130))\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 1)\n",
    "    X_current_family = X[X['family'] == current_family].drop(columns=['family', 'date'])\n",
    "    y_current_family = y.loc[X_current_family.index]\n",
    "    \n",
    "    titles = {'RMSLE': '{}: Learning Curves (default LGBM Regressor), RMSLE'.format(current_family), \n",
    "              'MAE': '{}: Learning Curves (default LGBM Regressor), MAE'.format(current_family)}\n",
    "    tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 120) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "    model = PositiveRegressor(lgb.LGBMRegressor())\n",
    "    plot_learning_curve(model, titles['MAE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 2)\n",
    "    plot_learning_curve(model, titles['RMSLE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_squared_log_error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f1e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_range = [30, 50, 100, 250, 500, 1000]\n",
    "tscv = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "plotting_validation_curve(lgb.LGBMRegressor(), X, y, param_name='n_estimators', param_range=param_range,\n",
    "                          split_key='family', scoring=custom_RMSLE, cv=tscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1bb01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "416380f3",
   "metadata": {},
   "source": [
    "#### Mixed model (linear regression and lgbm depence on the current_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_default_RMSLE_families = ['automotive', 'baby_care', 'magazines', 'pet_supplies', 'school and office supplies', 'seafood']\n",
    "linear_model_families = ['books', 'frozen foods']\n",
    "lgbm_default_MAE_families = ['celebration', 'dairy', 'eggs', 'grocery i', 'home and kitchen i', 'liquor,wine,beer',\n",
    "                             'meats', 'poultry', 'produce']\n",
    "optuna_RMSLE_families = ['beauty', 'hardware', 'home appliances', 'ladieswear', 'lingerie']\n",
    "optuna_MAE_families = ['beverages', 'bread/bakery', 'cleaning', 'deli', 'grocery ii', 'home and kitchen ii', 'home care', \n",
    "                       'lawn and garden', 'personal care', 'players and electronics', 'prepared foods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc31c752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_boost_round': 1000,\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "split_key = 'family'\n",
    "\n",
    "tscv_outer = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 165) * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)\n",
    "tscv_inner = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 100) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "\n",
    "linear_categories = ['books', 'frozen foods', 'beverages', 'cleaning', 'grocery ii', 'home and kitchen ii', 'home appliances']\n",
    "\n",
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "for train_indices, test_indices in tscv_outer.split(X, y):\n",
    "    X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "    X_test, y_test = X.iloc[test_indices], y.iloc[test_indices]\n",
    "    y_train = np.log(y_train + 1)\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_split_key_value in X['family'].unique():\n",
    "        print(current_split_key_value)\n",
    "        X_train_current_split_key_value = X_train[X_train[split_key] == current_split_key_value].drop(columns=[split_key, 'date'])\n",
    "        y_train_current_split_key_value = y_train.loc[X_train_current_split_key_value.index]\n",
    "        X_test_current_split_key_value = X_test[X_test[split_key] == current_split_key_value].drop(columns=split_key)\n",
    "    \n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        if current_split_key_value in linear_categories:\n",
    "            print(current_split_key_value)\n",
    "            X_train_current_split_key_value = pd.get_dummies(X_train_current_split_key_value, columns=['store_nbr'], drop_first=True)\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train_current_split_key_value[['dcoilwtico']] = scaler.fit_transform(X_train_current_split_key_value[['dcoilwtico']])\n",
    "            model.fit(X_train_current_split_key_value, y_train_current_split_key_value)\n",
    "            current_family_indices_test = X_test[X_test['family'] == current_split_key_value].index\n",
    "            X_test_current_split_key_value = pd.get_dummies(X_test_current_split_key_value, columns=['store_nbr'], drop_first=True)\n",
    "            X_test_current_split_key_value[['dcoilwtico']] = scaler.transform(X_test_current_split_key_value[['dcoilwtico']])\n",
    "        \n",
    "        else:\n",
    "            dtrain = lgb.Dataset(X_train_current_split_key_value, label=y_train_current_split_key_value, \n",
    "                                 categorical_feature=['store_nbr'])\n",
    "\n",
    "            tuner = LightGBMTunerCV(params, dtrain, folds=tscv_inner, callbacks=[early_stopping(25)], return_cvbooster=True)\n",
    "            tuner.run()\n",
    "        \n",
    "            сurrent_family_best_params = {key:tuner.best_params[key] for key in tuner.best_params.keys() if key not in params.keys()}\n",
    "            сurrent_family_best_params['num_boost_round'] = tuner.get_best_booster().best_iteration\n",
    "            print(сurrent_family_best_params)\n",
    "        \n",
    "            model = PositiveRegressor(lgb.LGBMRegressor(**сurrent_family_best_params)) \\\n",
    "                                           .fit(X_train_current_split_key_value, y_train_current_split_key_value)\n",
    "    \n",
    "        lags_copy = lags.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_split_key_value['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in lags_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_split_key_value['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_split_key_value[X_test_current_split_key_value['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in lags_copy:\n",
    "                    X_test_current_split_key_value.loc[X_test_current_split_key_value[X_test_current_split_key_value['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            lags_copy = lags_copy[:-1]\n",
    "            start = end\n",
    "    \n",
    "        X_test.loc[X_test_current_split_key_value.index, 'pred'] = model.predict(X_test_current_split_key_value.drop(columns=['date', 'pred']))\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    y_pred = np.exp(y_pred) - 1\n",
    "\n",
    "    print(mean_squared_log_error(y_test, y_pred, squared=False), mean_squared_error(y_test, y_pred, squared=False), \n",
    "          mean_absolute_error(y_test, y_pred), r2_score(y_test, y_pred))\n",
    "    scores['RMSLE'].append(mean_squared_log_error(y_test, y_pred, squared=False))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73389ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=pd.Timedelta(days=530), y=y)\n",
    "y_train = np.log(y_train + 1)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_boost_round': 1000,\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "split_key = 'family'\n",
    "\n",
    "tscv_inner = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 100) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "\n",
    "linear_categories = ['books', 'frozen foods', 'beverages', 'cleaning', 'grocery ii', 'home and kitchen ii', 'home appliances']\n",
    "\n",
    "best_params = {}\n",
    "for current_split_key_value in [x for x in X[split_key].unique() if x not in linear_categories]:\n",
    "    print(current_split_key_value)\n",
    "    X_train_current_split_key_value = X_train[X_train[split_key] == current_split_key_value].drop(columns=[split_key, 'date'])\n",
    "    y_train_current_split_key_value = y_train.loc[X_train_current_split_key_value.index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train_current_split_key_value, label=y_train_current_split_key_value, \n",
    "                            categorical_feature=['store_nbr'])\n",
    "\n",
    "    tuner = LightGBMTunerCV(params, dtrain, folds=tscv_inner, callbacks=[early_stopping(25)], return_cvbooster=True)\n",
    "    tuner.run()\n",
    "        \n",
    "    сurrent_family_best_params = {key:tuner.best_params[key] for key in tuner.best_params.keys() if key not in params.keys()}\n",
    "    сurrent_family_best_params['num_boost_round'] = tuner.get_best_booster().best_iteration\n",
    "    print(сurrent_family_best_params)\n",
    "    best_params[current_split_key_value] = сurrent_family_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec627043",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "\n",
    "for current_lag in lags:\n",
    "    test_data.loc[:, 'lag_{}'.format(current_lag)] = 0\n",
    "    \n",
    "    for i in range(current_lag):\n",
    "        test_data.loc[test_data[test_data['date'] == test_data['date'].unique()[i]].index, 'lag_{}'.format(current_lag)] = y_train.loc[X_train['date'] == X_train['date'].unique()[-(current_lag - i)]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39469d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "\n",
    "for current_family in X['family'].unique():\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[X_train_current_family.index]\n",
    "    X_test_current_family = test_data[test_data['family'] == current_family].drop(columns=['family'])\n",
    "    \n",
    "    if current_family not in linear_categories:\n",
    "        params = best_params[current_family]\n",
    "        model = PositiveRegressor(lgb.LGBMRegressor(**params))\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family, categorical_feature=['store_nbr'], \n",
    "                  eval_metric='rmse')\n",
    "        \n",
    "    else:\n",
    "        X_train_current_family = pd.get_dummies(X_train_current_family, columns=['store_nbr'], drop_first=True)\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_current_family[['dcoilwtico']] = scaler.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        X_test_current_family = pd.get_dummies(X_test_current_family, columns=['store_nbr'], drop_first=True)\n",
    "        X_test_current_family[['dcoilwtico']] = scaler.transform(X_test_current_family[['dcoilwtico']])\n",
    "    \n",
    "    lags_copy = lags.copy()\n",
    "    start = 0\n",
    "    current_day_index = 0\n",
    "    for end in ends:\n",
    "        for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "            current_day_plus_x = {}\n",
    "            for current_lag in lags_copy:\n",
    "                current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date'])\n",
    "            predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "            for current_lag in lags_copy:\n",
    "                X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "            current_day_index += 1\n",
    "                \n",
    "        lags_copy = lags_copy[:-1]\n",
    "        start = end\n",
    "            \n",
    "        \n",
    "    y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date']))\n",
    "    y_pred_current_family = np.exp(y_pred_current_family) - 1\n",
    "    \n",
    "    test_indices = test_data[test_data['family'] == current_family].index\n",
    "    submission.loc[test_indices, 'sales'] = y_pred_current_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/lgbm_linear_regression_OptunaTunerCV.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b81b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f402677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b02d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, current_family in enumerate(X['family'].unique()):\n",
    "    plt.figure(figsize=(20, 130))\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 1)\n",
    "    X_current_family = X[X['family'] == current_family].drop(columns=['family', 'date'])\n",
    "    y_current_family = y.loc[X_current_family.index]\n",
    "    \n",
    "    titles = {'RMSLE': '{}: Learning Curves (default LGBM Regressor), RMSLE'.format(current_family), \n",
    "              'MAE': '{}: Learning Curves (default LGBM Regressor), MAE'.format(current_family)}\n",
    "    tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 120) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "    \n",
    "    params = {}\n",
    "    if current_family in optuna_RMSLE_families + optuna_MAE_families:\n",
    "        params = current_family_best_params[current_family]\n",
    "        \n",
    "    model = PositiveRegressor(lgb.LGBMRegressor(**params))\n",
    "    fit_params = {'categorical_feature': ['store_nbr']}\n",
    "    plot_learning_curve(model, titles['MAE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_absolute_error',\n",
    "                        fit_params=fit_params)\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 2)\n",
    "    plot_learning_curve(model, titles['RMSLE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_squared_log_error', \n",
    "                        fit_params=fit_params)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8823fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried to increase samples number for some categories to make learning curve converge\n",
    "\n",
    "special = ['hardware', 'ladieswear', 'lawn and garden', 'magazines']\n",
    "for i, current_family in enumerate(special):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.subplot(len(special), 2, 2 * i + 1)\n",
    "    X_current_family = X[X['family'] == current_family].drop(columns=['family', 'date'])\n",
    "    y_current_family = y.loc[X_current_family.index]\n",
    "    \n",
    "    titles = {'RMSLE': '{}: Learning Curves (default LGBM Regressor), RMSLE'.format(current_family), \n",
    "              'MAE': '{}: Learning Curves (default LGBM Regressor), MAE'.format(current_family)}\n",
    "    tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 180) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "    \n",
    "    params = {}\n",
    "    if current_family in optuna_RMSLE_families + optuna_MAE_families:\n",
    "        params = current_family_best_params[current_family]\n",
    "        \n",
    "    model = PositiveRegressor(lgb.LGBMRegressor(**params))\n",
    "    fit_params = {'categorical_feature': ['store_nbr']}\n",
    "    plot_learning_curve(model, titles['MAE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_absolute_error',\n",
    "                        fit_params=fit_params)\n",
    "    plt.subplot(len(special), 2, 2 * i + 2)\n",
    "    plot_learning_curve(model, titles['RMSLE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_squared_log_error', \n",
    "                        fit_params=fit_params)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb3a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa4775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LGBM + linreg; default; 'store_nbr' -> target_encoding\n",
    "\n",
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "linear_categories = ['books', 'frozen foods', 'beverages', 'cleaning', 'grocery ii', 'home and kitchen ii', 'home appliances']\n",
    "\n",
    "tscv = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_train = np.log(y_train + 1)\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        print(current_family)\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "        y_train_current_family = y_train.loc[X_train_current_family.index]\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=['family'])\n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        \n",
    "        X_train_current_family['store_nbr'] = X_train_current_family['store_nbr'].astype('object')\n",
    "        encoder = TargetEncoder()\n",
    "        X_train_current_family['store_nbr'] = encoder.fit_transform(X_train_current_family['store_nbr'], y_train_current_family)\n",
    "        X_test_current_family['store_nbr'] = encoder.transform(X_test_current_family['store_nbr'])\n",
    "        \n",
    "        if current_family not in linear_categories:\n",
    "            #X_train_current_family['store_nbr'] = X_train_current_family['store_nbr'].astype('object')\n",
    "            #encoder = TargetEncoder()\n",
    "            #X_train_current_family['store_nbr'] = encoder.fit_transform(X_train_current_family['store_nbr'], y_train_current_family)\n",
    "            model = PositiveRegressor(lgb.LGBMRegressor())\n",
    "            model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family, eval_metric='rmse')#, categorical_feature=['store_nbr'])\n",
    "            #X_test_current_family['store_nbr'] = encoder.transform(X_test_current_family['store_nbr'])\n",
    "            \n",
    "        else:\n",
    "            #X_train_current_family = pd.get_dummies(X_train_current_family, columns=['store_nbr'], drop_first=True)\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train_current_family[['dcoilwtico']] = scaler.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "            model = PositiveRegressor(LinearRegression())\n",
    "            model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "            #X_test_current_family = pd.get_dummies(X_test_current_family, columns=['store_nbr'], drop_first=True)\n",
    "            X_test_current_family[['dcoilwtico']] = scaler.transform(X_test_current_family[['dcoilwtico']])\n",
    "    \n",
    "        lags_copy = lags.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in lags_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in lags_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            lags_copy = lags_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "        \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    y_pred = np.exp(y_pred) - 1\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb94dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=pd.Timedelta(days=DAYS_IN_YEAR), y=y)\n",
    "y_train = np.log(y_train + 1)\n",
    "\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "\n",
    "for current_lag in lags:\n",
    "    test_data.loc[:, 'lag_{}'.format(current_lag)] = 0\n",
    "    \n",
    "    for i in range(current_lag):\n",
    "        test_data.loc[test_data[test_data['date'] == test_data['date'].unique()[i]].index, 'lag_{}'.format(current_lag)] = y_train.loc[X_train['date'] == X_train['date'].unique()[-(current_lag - i)]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20cc8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "\n",
    "for current_family in X['family'].unique():\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[X_train_current_family.index]\n",
    "    X_test_current_family = test_data[test_data['family'] == current_family].drop(columns=['family'])\n",
    "    \n",
    "    X_train_current_family['store_nbr'] = X_train_current_family['store_nbr'].astype('object')\n",
    "    encoder = TargetEncoder()\n",
    "    X_train_current_family['store_nbr'] = encoder.fit_transform(X_train_current_family['store_nbr'], y_train_current_family)\n",
    "    X_test_current_family['store_nbr'] = encoder.transform(X_test_current_family['store_nbr'])\n",
    "    \n",
    "    if current_family not in linear_categories:\n",
    "        model = PositiveRegressor(lgb.LGBMRegressor())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family, eval_metric='rmse')#, categorical_feature=['store_nbr'])\n",
    "        \n",
    "    else:\n",
    "        #X_train_current_family = X_train_current_family.drop(columns=['onpromotion'])\n",
    "        #X_train_current_family = pd.get_dummies(X_train_current_family, columns=['store_nbr'], drop_first=True)\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_current_family[['dcoilwtico']] = scaler.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        #X_test_current_family = X_test_current_family.drop(columns=['onpromotion'])\n",
    "        #X_test_current_family = pd.get_dummies(X_test_current_family, columns=['store_nbr'], drop_first=True)\n",
    "        X_test_current_family[['dcoilwtico']] = scaler.transform(X_test_current_family[['dcoilwtico']])\n",
    "    \n",
    "    lags_copy = lags.copy()\n",
    "    start = 0\n",
    "    current_day_index = 0\n",
    "    for end in ends:\n",
    "        for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "            current_day_plus_x = {}\n",
    "            for current_lag in lags_copy:\n",
    "                current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date'])\n",
    "            predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "            for current_lag in lags_copy:\n",
    "                X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "            current_day_index += 1\n",
    "                \n",
    "        lags_copy = lags_copy[:-1]\n",
    "        start = end\n",
    "            \n",
    "        \n",
    "    y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date']))\n",
    "    y_pred_current_family = np.exp(y_pred_current_family) - 1\n",
    "    \n",
    "    test_indices = X_test_current_family.index\n",
    "    submission.loc[test_indices, 'sales'] = y_pred_current_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/lgbm_and_linear_regression_v3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = pd.read_csv(DATA_ROOT / 'lgbm_and_linear_regression.csv')\n",
    "(ccc['sales'] - submission['sales']).unique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db26c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5911c932",
   "metadata": {},
   "source": [
    "# adding features from other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99578eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['store_type', 'store_city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642aef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967dbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d9208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LGBM + linreg; default; 'store_type', 'store_city'\n",
    "\n",
    "X = train_transformer.adding_stores_data(X, columns_to_add=['type', 'city'])\n",
    "X['store_type'] = LabelEncoder().fit_transform(X['store_type'])\n",
    "X['store_city'] = LabelEncoder().fit_transform(X['store_city'])\n",
    "\n",
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "linear_categories = ['books', 'frozen foods', 'beverages', 'cleaning', 'grocery ii', 'home and kitchen ii', 'home appliances']\n",
    "\n",
    "tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 120) * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_train = np.log(y_train + 1)\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        print(current_family)\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "        y_train_current_family = y_train.loc[X_train_current_family.index]\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=['family'])\n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        \n",
    "        if current_family not in linear_categories:\n",
    "            model = PositiveRegressor(lgb.LGBMRegressor())\n",
    "            model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family, categorical_feature=['store_nbr', 'store_type', 'store_city'], \n",
    "                      eval_metric='rmse')\n",
    "            \n",
    "        else:\n",
    "            X_train_current_family = X_train_current_family.drop(columns=['store_type', 'store_city'])\n",
    "            X_train_current_family = pd.get_dummies(X_train_current_family, columns=['store_nbr'], drop_first=True)\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train_current_family[['dcoilwtico']] = scaler.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "            model = PositiveRegressor(LinearRegression())\n",
    "            model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "            X_test_current_family = X_test_current_family.drop(columns=['store_type', 'store_city'])\n",
    "            X_test_current_family = pd.get_dummies(X_test_current_family, columns=['store_nbr'], drop_first=True)\n",
    "            X_test_current_family[['dcoilwtico']] = scaler.transform(X_test_current_family[['dcoilwtico']])\n",
    "    \n",
    "        lags_copy = lags.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in lags_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in lags_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            lags_copy = lags_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "        \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    y_pred = np.exp(y_pred) - 1\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc23cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfbc356f",
   "metadata": {},
   "source": [
    "# best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a6e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "linear_categories = ['books', 'frozen foods', 'beverages', 'cleaning', 'grocery ii', 'home and kitchen ii', 'home appliances']\n",
    "\n",
    "tscv = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_train = np.log(y_train + 1)\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        print(current_family)\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "        y_train_current_family = y_train.loc[X_train_current_family.index]\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=['family'])\n",
    "        current_family_indices_test = X_test_current_family.index\n",
    "        \n",
    "        if current_family not in linear_categories:\n",
    "            model = PositiveRegressor(lgb.LGBMRegressor())\n",
    "            model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family, categorical_feature=['store_nbr'], \n",
    "                      eval_metric='rmse')\n",
    "            \n",
    "        else:\n",
    "            X_train_current_family = pd.get_dummies(X_train_current_family, columns=['store_nbr'], drop_first=True)\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train_current_family[['dcoilwtico']] = scaler.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "            model = PositiveRegressor(LinearRegression())\n",
    "            model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "            X_test_current_family = pd.get_dummies(X_test_current_family, columns=['store_nbr'], drop_first=True)\n",
    "            X_test_current_family[['dcoilwtico']] = scaler.transform(X_test_current_family[['dcoilwtico']])\n",
    "    \n",
    "        lags_copy = lags.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in lags_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in lags_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            lags_copy = lags_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "        \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    y_pred = np.exp(y_pred) - 1\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1357ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=pd.Timedelta(days=DAYS_IN_YEAR), y=y)\n",
    "y_train = np.log(y_train + 1)\n",
    "\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "\n",
    "for current_lag in lags:\n",
    "    test_data.loc[:, 'lag_{}'.format(current_lag)] = 0\n",
    "    \n",
    "    for i in range(current_lag):\n",
    "        test_data.loc[test_data[test_data['date'] == test_data['date'].unique()[i]].index, 'lag_{}'.format(current_lag)] = y_train.loc[X_train['date'] == X_train['date'].unique()[-(current_lag - i)]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c66f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "\n",
    "for current_family in X['family'].unique():\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[X_train_current_family.index]\n",
    "    X_test_current_family = test_data[test_data['family'] == current_family].drop(columns=['family'])\n",
    "    \n",
    "    if current_family not in linear_categories:\n",
    "        model = PositiveRegressor(lgb.LGBMRegressor())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family, categorical_feature=['store_nbr'], \n",
    "                  eval_metric='rmse')\n",
    "        \n",
    "    else:\n",
    "        X_train_current_family = pd.get_dummies(X_train_current_family, columns=['store_nbr'], drop_first=True)\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_current_family[['dcoilwtico']] = scaler.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        X_test_current_family = pd.get_dummies(X_test_current_family, columns=['store_nbr'], drop_first=True)\n",
    "        X_test_current_family[['dcoilwtico']] = scaler.transform(X_test_current_family[['dcoilwtico']])\n",
    "    \n",
    "    lags_copy = lags.copy()\n",
    "    start = 0\n",
    "    current_day_index = 0\n",
    "    for end in ends:\n",
    "        for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "            current_day_plus_x = {}\n",
    "            for current_lag in lags_copy:\n",
    "                current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date'])\n",
    "            predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "            for current_lag in lags_copy:\n",
    "                X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "            current_day_index += 1\n",
    "                \n",
    "        lags_copy = lags_copy[:-1]\n",
    "        start = end\n",
    "            \n",
    "        \n",
    "    y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date']))\n",
    "    y_pred_current_family = np.exp(y_pred_current_family) - 1\n",
    "    \n",
    "    test_indices = X_test_current_family.index\n",
    "    submission.loc[test_indices, 'sales'] = y_pred_current_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/lgbm_and_linear_regression_v3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = pd.read_csv(DATA_ROOT / 'lgbm_and_linear_regression.csv')\n",
    "(ccc['sales'] - submission['sales']).unique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca182ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09323d44",
   "metadata": {},
   "source": [
    "#### simplest lgbm without any parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():        \n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "        model = lgb.LGBMRegressor()\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family, categorical_feature=['store_nbr'])\n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=['family'])\n",
    "                  \n",
    "        days_to_shift_copy = days_to_shift.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                predictions[predictions < 0] = 0\n",
    "                \n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            days_to_shift_copy = days_to_shift_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "        \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        y_pred_current_family[y_pred_current_family < 0] = 0\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059298f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616060b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397af06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a51c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928893a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e32569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b94aea0c",
   "metadata": {},
   "source": [
    "# 3. LightGBM Regressor for every family, features: 'store_nbr', 'dcoilwtico', 'lag' (1, 2, 4, 6, 7, 14) with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 4, 6, 7, 14]\n",
    "\n",
    "X_copy = X.copy()\n",
    "X_copy['sales'] = np.log(X_copy['sales'] + 1)\n",
    "\n",
    "for current_lag in lags:\n",
    "    X['lag_{}'.format(current_lag)] = X_copy.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28334ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns=['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=DAYS_IN_YEAR + N_HORIZONS), y=y)\n",
    "X_train = X_train[~X_train['date'].isin(cut_history(X=X, date_column='date', keep_interval=timedelta(days=N_HORIZONS), y=y)[0]['date'].unique())]\n",
    "y_train = y_train.loc[X_train.index]\n",
    "\n",
    "for i, current_family in enumerate(X['family'].unique()):\n",
    "    plt.figure(figsize=(20, 130))\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 1)\n",
    "    X_current_family = X_train[X_train['family'] == current_family].drop(columns=['family', 'date'])\n",
    "    y_current_family = y_train.loc[X_current_family.index]\n",
    "    \n",
    "    titles = {'RMSLE': '{}: Learning Curves (default LGBM Regressor), RMSLE'.format(current_family), \n",
    "              'MAE': '{}: Learning Curves (default LGBM Regressor), MAE'.format(current_family)}\n",
    "    tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR - 4 * N_HORIZONS) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "    model = PositiveRegressor(lgb.LGBMRegressor())\n",
    "    plot_learning_curve(model, titles['MAE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 2)\n",
    "    plot_learning_curve(model, titles['MSLE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_squared_log_error')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_categories = ['books', 'frozen foods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5942f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'l1',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_boost_round': 1000,\n",
    "    'n_jobs': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba0e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [5, 6, 7]\n",
    "np.mean(np.square(np.log1p(a) - np.log1p(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msle_for_lgbm(preds: np.ndarray, data: lgb.Dataset) -> Tuple[str, float, bool]:\n",
    "    \"\"\"Calculate MSLE\"\"\"\n",
    "    label = data.get_label()\n",
    "    # weight = data.get_weight()\n",
    "    # pred_label = (preds > threshold).astype(int)\n",
    "    # acc = np.average(label == pred_label, weights=weight)\n",
    "    preds[preds < 0] = 0\n",
    "    msle = np.mean(np.square(np.log1p(y_pred + 1) - np.log1p(y_true + 1)))\n",
    "    # # eval_name, eval_result, is_higher_better\n",
    "    return 'my_bin_acc', acc, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d0d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize MAE\n",
    "\n",
    "best_params_MAE = {}\n",
    "\n",
    "for current_family in list(set(X['family'].unique())-set(linear_categories)):\n",
    "    print(current_family)\n",
    "    X_current_family = X_train[X_train['family'] == current_family].drop(columns=['family', 'date'])\n",
    "    y_current_family = y_train.loc[X_current_family.index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_current_family, label=y_current_family, categorical_feature=['store_nbr'])\n",
    "    tscv_inner = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR - 4 * N_HORIZONS) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "    \n",
    "    tuner = LightGBMTunerCV(params, dtrain, folds=tscv_inner, callbacks=[early_stopping(25)], return_cvbooster=True)\n",
    "    tuner.run()\n",
    "        \n",
    "    сurrent_family_best_params = {key:tuner.best_params[key] for key in tuner.best_params.keys() if key not in params.keys()}\n",
    "    сurrent_family_best_params['num_boost_round'] = tuner.get_best_booster().best_iteration\n",
    "    print(сurrent_family_best_params)\n",
    "    \n",
    "    best_params_MAE[current_family] = сurrent_family_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a1f2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138c7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e375e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102ec54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3797832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from optuna.integration.lightgbm import LightGBMTunerCV\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "tscv_outer = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)\n",
    "X_for_lgbm_Tuner_CV_indices = [x for x in tscv_outer.split(X, y)][-1][0]\n",
    "X_for_lgbm_Tuner_CV = X.iloc[X_for_lgbm_Tuner_CV_indices]\n",
    "y_for_lgbm_Tuner_CV = y.iloc[X_for_lgbm_Tuner_CV_indices]\n",
    "\n",
    "tscv_inner = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR - 65) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "\n",
    "current_family_best_params = {}\n",
    "current_family_best_scores = {}\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "}\n",
    "\n",
    "for current_family in special:\n",
    "# for current_family in X['family'].unique():\n",
    "    print('\\n\\n', current_family, '\\n\\n')\n",
    "    params['num_boost_round'] = best_n_estimators[current_family]['n_estimators']\n",
    "    X_current_family = X[X['family'] == current_family].drop(columns=['family'])\n",
    "    y_current_family = y.loc[X_current_family.index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_current_family.drop(columns=['date']), label=y_current_family, categorical_feature=['store_nbr'])\n",
    "\n",
    "    tuner = LightGBMTunerCV(\n",
    "        params,\n",
    "        dtrain,\n",
    "        folds=tscv_inner,\n",
    "        callbacks=[early_stopping(25)],\n",
    "    )\n",
    "\n",
    "    tuner.run()\n",
    "    \n",
    "    current_family_best_params[current_family] = tuner.best_params\n",
    "    [current_family_best_params[current_family].pop(key) for key in {'objective', 'metric', 'verbosity'}]\n",
    "    current_family_best_scores[current_family] = tuner.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_family in current_family_best_params.keys():\n",
    "    print(current_family)\n",
    "    for key, value in current_family_best_params[current_family].items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, current_family in enumerate(special):\n",
    "#for i, current_family in enumerate(X['family'].unique()):\n",
    "    plt.figure(figsize=(20, 130))\n",
    "    X_current_family = X[X['family'] == current_family].drop(columns=['family', 'date'])\n",
    "    y_current_family = y.loc[X_current_family.index]\n",
    "    \n",
    "    titles = {'without_tuning': '{}: Learning Curves (default LGBM Regressor), RMSLE'.format(current_family), \n",
    "              'with_tuning': '{}: Learning Curves (LGBM Regressor with LGBMTunerCV), RMSLE'.format(current_family)}\n",
    "    tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 120) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "    model_default = PositiveRegressor(lgb.LGBMRegressor())\n",
    "    model_tuned_params = PositiveRegressor(lgb.LGBMRegressor(**current_family_best_params[current_family]))\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 1)\n",
    "    plot_learning_curve(model_default, titles['without_tuning'], X_current_family, y_current_family, cv=tscv, scoring=custom_RMSLE)\n",
    "    plt.subplot(X['family'].nunique(), 2, 2 * i + 2)\n",
    "    plot_learning_curve(model_tuned_params, titles['with_tuning'], X_current_family, y_current_family, cv=tscv, scoring=custom_RMSLE)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# for i, current_family in enumerate(X['family'].unique()):\n",
    "#     plt.figure(figsize=(20, 130))\n",
    "#     plt.subplot(X['family'].nunique(), 2, 2 * i + 1)\n",
    "#     X_current_family = X[X['family'] == current_family].drop(columns=['family', 'date'])\n",
    "#     y_current_family = y.loc[X_current_family.index]\n",
    "    \n",
    "#     titles = {'RMSLE': '{}: Learning Curves (default LGBM Regressor), RMSLE'.format(current_family), \n",
    "#               'MAE': '{}: Learning Curves (default LGBM Regressor), MAE'.format(current_family)}\n",
    "#     tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 120) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "#     model_default = PositiveRegressor(lgb.LGBMRegressor())\n",
    "#     plot_learning_curve(model, titles['MAE'], X_current_family, y_current_family, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "#     plt.subplot(X['family'].nunique(), 2, 2 * i + 2)\n",
    "#     plot_learning_curve(model, titles['RMSLE'], X_current_family, y_current_family, cv=tscv, scoring=custom_RMSLE)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c1a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "ends = [(16 - x) for x in lags]\n",
    "ends.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceeeb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "def objective(trial, X, y, n_estimators):\n",
    "    param_grid = {\n",
    "        # 'n_estimators': trial.suggest_categorical('n_estimators', [50, 100, 250, 500, 1000]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 8, 500, step=20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 200, 1000, step=100),\n",
    "        'lambda_l1': trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 15),\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 100) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "\n",
    "    cv_scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "    for train_indices, test_indices in tscv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "        model = lgb.LGBMRegressor(n_estimators=n_estimators, **param_grid)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric='rmse', categorical_feature=['store_nbr'],\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial, 'rmse'),\n",
    "                lgb.early_stopping(stopping_rounds=25)\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        cv_scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "        cv_scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "        cv_scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "        cv_scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "    return np.mean(cv_scores['RMSLE']), cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=540), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d41253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params = {family:{} for family in X['family'].unique()}\n",
    "best_values = {family:0 for family in X['family'].unique()}\n",
    "for current_family in X['family'].unique():\n",
    "    print('\\n\\n')\n",
    "    print(current_family)\n",
    "    print('\\n\\n')\n",
    "    X_current_family = X_train[X_train['family'] == current_family].drop(columns=['date', 'family'])\n",
    "    y_current_family = y_train.loc[X_current_family.index]\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction='minimize', study_name='LGBM Regressor')\n",
    "    func = lambda trial: objective(trial, X_current_family, y_current_family, best_n_estimators[current_family]['n_estimators'])[0]\n",
    "    study.optimize(func, n_trials=100)\n",
    "    for key, value in study.best_params.items():\n",
    "        best_params[current_family][key] = value\n",
    "    best_values[current_family] = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family, all_params in best_params.items():\n",
    "    print(family)\n",
    "    for param in all_params.keys():\n",
    "        print('{}:'.format(param), all_params[param])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d800cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_errors = {'{}:'.format(x): best_values[x] for x in best_values.keys()}\n",
    "mean(rmsle_errors.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33292a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR + 100) * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        print(current_family)\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "        y_train_current_family = y_train.loc[X_train_current_family.index]\n",
    "        \n",
    "        current_family_hyper_params = current_family_best_params[current_family]\n",
    "        #if current_family != 'automotive':\n",
    "        #    [current_family_hyper_params.pop(key) for key in {'objective', 'metric', 'verbosity'}]\n",
    "        print(current_family_hyper_params)\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**current_family_hyper_params, verbosity=-1)\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family, categorical_feature=['store_nbr'])\n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=['family'])\n",
    "                  \n",
    "        lags_copy = lags.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in lags_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                predictions[predictions < 0] = 0\n",
    "                \n",
    "                for current_lag in lags_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            lags_copy = lags_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "        \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        y_pred_current_family[y_pred_current_family < 0] = 0\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "        \n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "for current_lag in lags:\n",
    "    test_data.loc[:, 'lag_{}'.format(current_lag)] = 0\n",
    "    \n",
    "    for i in range(current_lag):\n",
    "        test_data.loc[test_data[test_data['date'] == test_data['date'].unique()[i]].index, 'lag_{}'.format(current_lag)] = y_train.loc[X_train['date'] == X_train['date'].unique()[-(current_lag - i)]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lags)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f00706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=DAYS_IN_YEAR), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9cf0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for current_family in X['family'].unique():\n",
    "    print(current_family)\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[X_train_current_family.index]\n",
    "    \n",
    "    current_family_hyper_params = current_family_best_params[current_family]\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**current_family_hyper_params)\n",
    "    model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    \n",
    "    X_test_current_family = test_data[test_data['family'] == current_family].drop(columns=['family'])   \n",
    "    \n",
    "    lags_copy = lags.copy()\n",
    "    start = 0\n",
    "    current_day_index = 0\n",
    "    for end in ends:\n",
    "        for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "            current_day_plus_x = {}\n",
    "            for current_lag in lags_copy:\n",
    "                current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date'])\n",
    "            predictions = model.predict(X_test_for_current_day)\n",
    "            predictions[predictions < 0] = 0    \n",
    "                \n",
    "            for current_lag in lags_copy:\n",
    "                X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "            current_day_index += 1\n",
    "                \n",
    "        lags_copy = lags_copy[:-1]\n",
    "        start = end\n",
    "            \n",
    "        \n",
    "    y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date']))\n",
    "    y_pred_current_family[y_pred_current_family < 0] = 0\n",
    "    \n",
    "    test_indices = test_data[test_data['family'] == current_family].index\n",
    "    submission.loc[test_indices, 'sales'] = y_pred_current_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/lgbmTunerCV_lags_and_dcoilwtico.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fdc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24953e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "558838dc",
   "metadata": {},
   "source": [
    "# 4. LightGBM Regressor for every family, features: 'store_nbr', 'dcoilwtico', 'lag' (1, 2, 4, 6, 7, 14), with 'boruta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006fe1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 4, 6, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X['dcoilwtico'].notna()]\n",
    "X = X.reset_index(drop=True)\n",
    "\n",
    "for current_lag in days_to_shift:\n",
    "    X['lag_{}'.format(current_lag)] = X.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)\n",
    "\n",
    "X = X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns=['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94154e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=365 * 33 * 54, n_splits=4, test_size=16 * 33 * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f30d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ends = [(16 - x) for x in days_to_shift]\n",
    "ends.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4250f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 4, \n",
    "    'max_bin': 128,\n",
    "    'num_leaves': 16,\n",
    "    \"n_estimators\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ff3c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_features = {family:{} for family in X_train['family'].unique()}\n",
    "for current_family in X_train['family'].unique():\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['date', 'family'])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "    \n",
    "    model = lgb.LGBMRegressor(objective='regression', **hyper_params)\n",
    "    boruta = BorutaPy(estimator=model, n_estimators='auto', max_iter = 100)\n",
    "    boruta.fit(np.array(X_train_current_family), np.array(y_train_current_family))\n",
    "    best_features[current_family]['green_area'] = X_train_current_family.columns[boruta.support_].to_list()\n",
    "    best_features[current_family]['blue_area'] = X_train_current_family.columns[boruta.support_weak_].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66087413",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family, all_features in best_features.items():\n",
    "    print(family)\n",
    "    for features in all_features.keys():\n",
    "        print(features, all_features[features])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc277186",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        print(current_family)\n",
    "        columns_to_drop = [feature for feature in X if feature not in best_features[current_family]['green_area'] and \\\n",
    "                                                       feature not in best_features[current_family]['blue_area'] and \\\n",
    "                                                       feature != 'date']\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "        model = lgb.LGBMRegressor(objective='regression', **hyper_params)\n",
    "        if 'store_nbr' in columns_to_drop:\n",
    "            model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        else:\n",
    "            model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family, categorical_feature=['store_nbr'])\n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family]\n",
    "                  \n",
    "        days_to_shift_copy = days_to_shift.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=columns_to_drop) \\\n",
    "                                                                                                            .drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                predictions[predictions < 0] = 0\n",
    "                \n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            days_to_shift_copy = days_to_shift_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "        \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=columns_to_drop).drop(columns=['date', 'pred']))\n",
    "        y_pred_current_family[y_pred_current_family < 0] = 0\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "        \n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192baafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bd9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88bb759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edca4729",
   "metadata": {},
   "source": [
    "# 5. LightGBM Regressor for every family, features: 'store_nbr', 'dcoilwtico', 'lag' (1, 2, 4, 6, 7, 14), 'rolling' with 'boruta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d466f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 4, 6, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa793cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X['dcoilwtico'].notna()]\n",
    "X = X.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c9dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "\n",
    "for current_lag in days_to_shift:\n",
    "    X.loc[:, 'lag_{}'.format(current_lag)] = X.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)\n",
    "    test_data.loc[:, 'lag_{}'.format(current_lag)] = 0\n",
    "    \n",
    "    for i in range(current_lag):\n",
    "        test_data.loc[test_data[test_data['date'] == test_data['date'].unique()[i]].index, 'lag_{}'.format(current_lag)] = X.loc[X[X['date'] == X['date'].unique()[-(current_lag - i)]].index, 'sales'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_periods = {'year': 365, '6m': 183, '3m': 92, '1m': 31, '16d': 16, '10d': 10, '7d': 7, '5d': 5, '3d': 3}\n",
    "aggregate_functions = ['median', 'mean', 'sum', 'max', 'min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for period, days in rolling_periods.items():\n",
    "    for function in aggregate_functions:\n",
    "        X['rolling_{0}_{1}'.format(period, function)] = X.groupby(['store_nbr', 'family'])['sales'].apply(lambda x: x.shift().rolling(days).agg({'sales': function}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns=['sales'])\n",
    "X['sales'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b619ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'max_depth': 6, \n",
    "    'n_estimators': 300,\n",
    "    'num_leaves': 40,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ba7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = {family:{} for family in X_train['family'].unique()}\n",
    "for current_family in X_train['family'].unique():\n",
    "    print(current_family)\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['date', 'family', 'sales'])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "    \n",
    "    model = lgb.LGBMRegressor(objective='regression', **hyper_params)\n",
    "    \n",
    "    boruta = BorutaPy(estimator=model, n_estimators='auto', max_iter=100)\n",
    "    boruta.fit(np.array(X_train_current_family), np.array(y_train_current_family))\n",
    "    best_features[current_family]['green_area'] = X_train_current_family.columns[boruta.support_].to_list()\n",
    "    best_features[current_family]['blue_area'] = X_train_current_family.columns[boruta.support_weak_].to_list()\n",
    "    print('green: ', X_train_current_family.columns[boruta.support_].to_list())\n",
    "    print('blue: ', X_train_current_family.columns[boruta.support_weak_].to_list())\n",
    "    \n",
    "    model.fit(X_train_current_family, y_train_current_family)\n",
    "    explainer = shap.TreeExplainer(model, X_train_current_family)\n",
    "    shap_values = explainer(X_train_current_family)\n",
    "    shap.plots.bar(shap_values, max_display=25)\n",
    "    \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_best_features = {\n",
    "    'automotive': ['dcoilwtico', 'lag_1', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_mean', 'rolling_6m_max',\n",
    "                   'rolling_7d_mean', 'rolling_3m_mean', 'rolling_1m_mean', 'rolling_1m_median',\n",
    "                   'rolling_6m_median', 'rolling_6m_mean', 'rolling_10d_mean', 'rolling_year_median',\n",
    "                   'rolling_16d_mean'],\n",
    "    'baby care': ['dcoilwtico', 'rolling_year_mean', 'rolling_6m_mean', 'rolling_3m_mean', 'rolling_1m_mean', \n",
    "                  'rolling_16d_mean', 'rolling_10d_mean'],\n",
    "    'beauty': ['dcoilwtico', 'lag_1', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_mean', 'rolling_3m_mean', \n",
    "               'rolling_1m_mean', 'rolling_16d_mean', 'rolling_7d_mean', 'rolling_5d_max', 'rolling_3m_min', \n",
    "               'rolling_7d_min', 'rolling_1m_median'],\n",
    "    'beverages': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_1m_min',\n",
    "                  'rolling_16d_mean', 'rolling_16d_max', 'rolling_10d_min', 'rolling_5d_min', 'rolling_3d_median',\n",
    "                  'rolling_3d_max', 'rolling_3d_min', 'rolling_7d_median', 'rolling_7d_mean', 'rolling_5d_median',\n",
    "                  'rolling_10d_median', 'rolling_7d_min', 'rolling_year_mean', 'rolling_16d_median'],\n",
    "    'books': ['rolling_year_mean', 'rolling_3m_mean', 'rolling_1m_mean', 'rolling_16d_mean', 'rolling_16d_max',\n",
    "              'rolling_10d_mean', 'rolling_7d_mean', 'rolling_5d_mean', 'rolling_10d_max'],\n",
    "    'bread/bakery': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_3m_max', \n",
    "                     'rolling_3m_min', 'rolling_16d_max', 'rolling_5d_max', 'rolling_5d_min', 'rolling_3d_median', \n",
    "                     'rolling_3d_min', 'rolling_7d_mean', 'rolling_7d_median', 'rolling_5d_min'],\n",
    "    'celebration': ['dcoilwtico', 'lag_1', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_mean', 'rolling_3m_mean', \n",
    "                    'rolling_1m_median', 'rolling_1m_min', 'rolling_16d_mean', 'rolling_7d_median', 'rolling_7d_mean', \n",
    "                    'rolling_7d_min', 'rolling_5d_mean', 'rolling_3d_mean', 'rolling_3m_median', 'rolling_1m_mean',\n",
    "                    'rolling_6m_mean', 'rolling_year_median', 'lag_4', 'rolling_3d_max'],\n",
    "    'cleaning': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_6m_max', 'rolling_3m_max', \n",
    "                 'rolling_1m_max', 'rolling_16d_median', 'rolling_16d_mean', 'rolling_16d_max', 'rolling_10d_max', \n",
    "                 'rolling_7d_mean', 'rolling_7d_max', 'rolling_5d_median', 'rolling_5d_max', 'rolling_5d_min', \n",
    "                 'rolling_3d_median', 'rolling_3d_max', 'rolling_3m_mean', 'rolling_year_mean', 'rolling_10d_median', \n",
    "                 'rolling_10d_mean', 'rolling_1m_median'],\n",
    "    'dairy': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_6m_min', 'rolling_1m_min', \n",
    "              'rolling_16d_max', 'rolling_5d_median', 'rolling_5d_max', 'rolling_5d_min', 'rolling_3d_median', \n",
    "              'rolling_3d_mean', 'rolling_3d_max', 'rolling_3d_min', 'rolling_7d_mean', 'rolling_7d_median', \n",
    "              'rolling_6m_max', 'rolling_16d_median', 'rolling_year_max'],\n",
    "    'deli': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_6m_min', 'rolling_3m_min', \n",
    "             'rolling_16d_median', 'rolling_16d_max', 'rolling_16d_min', 'rolling_10d_min', 'rolling_5d_min', \n",
    "             'rolling_3d_median', 'rolling_3d_max', 'rolling_3d_min', 'rolling_3m_median', 'rolling_year_median',\n",
    "             'rolling_7d_mean', 'rolling_3m_mean', 'rolling_7d_median'],\n",
    "    'eggs': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_max', 'rolling_1m_max', \n",
    "             'rolling_16d_max', 'rolling_10d_max', 'rolling_7d_mean', 'rolling_3d_max', 'rolling_3d_min', \n",
    "             'rolling_3m_median'],\n",
    "    'frozen foods': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_max', \n",
    "                     'rolling_16d_median', 'rolling_16d_max', 'rolling_10d_max', 'rolling_7d_median', 'rolling_7d_mean', \n",
    "                     'rolling_7d_max', 'rolling_5d_max', 'rolling_5d_min', 'rolling_3d_min', 'rolling_10d_mean'],\n",
    "    'grocery i': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_6m_min', 'rolling_1m_max', \n",
    "                  'rolling_16d_median', 'rolling_16d_mean', 'rolling_16d_max', 'rolling_5d_max', 'rolling_5d_min', \n",
    "                  'rolling_3d_max', 'rolling_3d_min', 'rolling_year_mean', 'rolling_7d_mean', 'rolling_5d_median',\n",
    "                  'rolling_year_median'],\n",
    "    'grocery ii': ['lag_1', 'lag_7', 'lag_14', 'rolling_7d_mean', 'rolling_10d_median', 'rolling_3m_median', \n",
    "                   'rolling_3m_min'],\n",
    "    'hardware': ['dcoilwtico', 'rolling_year_mean', 'rolling_3m_mean', 'rolling_1m_mean'],\n",
    "    'home and kitchen i': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_6', 'lag_7', 'lag_14', 'rolling_3m_median', \n",
    "                           'rolling_16d_median', 'rolling_16d_min', 'rolling_10d_median', 'rolling_7d_median', \n",
    "                           'rolling_7d_mean', 'rolling_5d_median', 'rolling_5d_min', 'rolling_3d_median', 'rolling_3d_mean', \n",
    "                           'rolling_3d_min', 'rolling_6m_median', 'rolling_16d_mean', 'lag_4'],\n",
    "    'home and kitchen ii': ['dcoilwtico', 'lag_1', 'lag_6', 'lag_7', 'lag_14', 'rolling_10d_max', 'rolling_7d_mean', \n",
    "                            'rolling_7d_median', 'rolling_3d_median', 'rolling_16d_mean', 'rolling_3m_mean', \n",
    "                            'rolling_10d_mean', 'rolling_1m_median'],\n",
    "    'home appliances': ['dcoilwtico', 'rolling_year_mean', 'rolling_6m_mean', 'rolling_3m_mean', 'rolling_1m_mean', \n",
    "                        'rolling_16d_mean'],\n",
    "    'home care': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_mean', \n",
    "                  'rolling_6m_min', 'rolling_16d_median', 'rolling_16d_mean', 'rolling_16d_max', 'rolling_16d_min', \n",
    "                  'rolling_7d_mean', 'rolling_7d_min', 'rolling_5d_median', 'rolling_5d_max', 'rolling_5d_min', \n",
    "                  'rolling_3d_median', 'rolling_3d_max', 'rolling_3d_min', 'rolling_3m_median', 'rolling_6m_mean', \n",
    "                  'rolling_10d_median'],\n",
    "    'ladieswear': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_mean', \n",
    "                   'rolling_3m_max', 'rolling_16d_median', 'rolling_16d_mean', 'rolling_7d_mean', 'rolling_5d_max', \n",
    "                   'rolling_3d_mean', 'rolling_3m_mean', 'rolling_6m_mean', 'rolling_year_max', 'rolling_6m_median'],\n",
    "    'lawn and garden': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_6', 'lag_7', 'lag_14', 'rolling_1m_median', 'rolling_1m_mean', \n",
    "                        'rolling_7d_median', 'rolling_7d_mean', 'rolling_5d_max', 'rolling_3d_median', 'rolling_3d_mean', \n",
    "                        'rolling_3d_max', 'rolling_3d_min', 'rolling_7d_min', 'rolling_10d_median'],\n",
    "    'lingerie': ['dcoilwtico', 'lag_1', 'lag_7', 'lag_14', 'rolling_year_mean', 'rolling_16d_mean', 'rolling_7d_mean', \n",
    "                 'rolling_3d_mean', 'rolling_year_median', 'rolling_16d_median', 'rolling_1m_mean'],\n",
    "    'liquor,wine,beer': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_6m_min', \n",
    "                         'rolling_10d_max', 'rolling_7d_min', 'rolling_year_mean'],\n",
    "    'magazines': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_mean', \n",
    "                  'rolling_3m_mean', 'rolling_16d_mean', 'rolling_10d_mean', 'rolling_7d_mean', 'rolling_6m_mean', \n",
    "                  'rolling_10d_min'],\n",
    "    'meats': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_7', 'lag_14', 'rolling_1m_max', 'rolling_7d_max', 'rolling_5d_min', \n",
    "              'rolling_1m_mean', 'rolling_16d_median', 'rolling_5d_max', 'rolling_6m_median', 'rolling_3m_median', \n",
    "              'rolling_6m_mean'],\n",
    "    'personal care': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_16d_median', \n",
    "                      'rolling_16d_mean', 'rolling_16d_max', 'rolling_10d_min', 'rolling_5d_max', 'rolling_5d_min', \n",
    "                      'rolling_3d_median', 'rolling_3d_max', 'rolling_3d_min', 'rolling_3m_median', 'rolling_7d_mean', \n",
    "                      'rolling_3m_mean', 'rolling_year_median', 'rolling_7d_median', 'rolling_year_mean', 'rolling_7d_min'],\n",
    "    'pet supplies': ['dcoilwtico', 'lag_1', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_mean', 'rolling_3m_mean', \n",
    "                     'rolling_1m_mean', 'rolling_16d_mean', 'rolling_7d_mean', 'rolling_5d_mean', 'rolling_5d_max', \n",
    "                     'rolling_16d_median'],\n",
    "    'players and electronics': ['dcoilwtico', 'lag_1', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_mean', \n",
    "                                'rolling_7d_mean', 'rolling_16d_mean', 'rolling_1m_mean', 'rolling_3m_mean', \n",
    "                                'rolling_1m_median'],\n",
    "    'poultry': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_6m_max', 'rolling_3m_min', \n",
    "                'rolling_1m_max', 'rolling_16d_mean', 'rolling_16d_max', 'rolling_10d_min', 'rolling_7d_median', \n",
    "                'rolling_7d_mean', 'rolling_7d_max', 'rolling_5d_mean', 'rolling_5d_min', 'rolling_3d_median', \n",
    "                'rolling_3d_max', 'rolling_3d_min', 'rolling_10d_mean', 'rolling_10d_max', 'rolling_6m_mean', \n",
    "                'rolling_3m_median', 'rolling_year_mean', 'rolling_year_median'],\n",
    "    'prepared foods': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_1m_max', 'rolling_1m_min', \n",
    "                       'rolling_7d_mean', 'rolling_16d_mean', 'rolling_1m_median', 'rolling_year_max', 'rolling_3m_median',\n",
    "                       'rolling_16d_median'],\n",
    "    'produce': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_6m_min', 'rolling_1m_min', \n",
    "                'rolling_16d_max', 'rolling_16d_min', 'rolling_10d_min', 'rolling_7d_median', 'rolling_5d_median', \n",
    "                'rolling_5d_min', 'rolling_3d_median', 'rolling_3d_max', 'rolling_3d_min', 'rolling_7d_mean', \n",
    "                'rolling_3m_mean', 'rolling_3m_median', 'rolling_year_max', 'rolling_7d_max'],\n",
    "    'school and office supplies': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_mean', \n",
    "                                   'rolling_16d_median', 'rolling_10d_mean', 'rolling_7d_median', 'rolling_7d_mean', \n",
    "                                   'rolling_7d_min', 'rolling_5d_mean', 'rolling_5d_min', 'rolling_3d_median', \n",
    "                                   'rolling_3d_mean', 'rolling_3d_max', 'rolling_3d_min', 'rolling_7d_max'],\n",
    "    'seafood': ['dcoilwtico', 'lag_1', 'lag_2', 'lag_4', 'lag_6', 'lag_7', 'lag_14', 'rolling_year_median', 'rolling_1m_max', \n",
    "                'rolling_16d_mean', 'rolling_16d_max', 'rolling_7d_min', 'rolling_5d_max', 'rolling_3d_max', 'rolling_3d_min',\n",
    "                'rolling_10d_min', 'rolling_3d_median']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eda3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [100, 500, 1000, 5000, 10000]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 3000, step=20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 200, 10000, step=100),\n",
    "        'lambda_l1': trial.suggest_int('lambda_l1', 0, 100, step=5),\n",
    "        'lambda_l2': trial.suggest_int('lambda_l2', 0, 100, step=5),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 15),\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(gap=0, max_train_size=365 * 54, n_splits=4, test_size=16 * 54)\n",
    "\n",
    "    cv_scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "    for train_indices, test_indices in tscv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "        model = lgb.LGBMRegressor(objective='regression_l1', **param_grid)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_metric='rmse',\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial, 'rmse'),\n",
    "                lgb.early_stopping(stopping_rounds=100)\n",
    "            ],  # Add a pruning callback\n",
    "        )\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        cv_scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "        cv_scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "        cv_scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "        cv_scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "    return np.mean(cv_scores['RMSLE']), cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a35c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params = {family:{} for family in X['family'].unique()}\n",
    "best_values = {family:0 for family in X['family'].unique()}\n",
    "for current_family in X['family'].unique():\n",
    "    print()\n",
    "    print()\n",
    "    print(current_family)\n",
    "    print()\n",
    "    print()\n",
    "    columns_to_drop = [feature for feature in X if feature not in final_best_features[current_family] and \\\n",
    "                                                   feature != 'store_nbr']\n",
    "    current_family_indices = X[X['family'] == current_family].index\n",
    "    X_current_family = X[X['family'] == current_family].drop(columns=columns_to_drop)\n",
    "    y_current_family = y.loc[current_family_indices]\n",
    "    \n",
    "    \n",
    "    study = optuna.create_study(direction='minimize', study_name='LGBM Regressor')\n",
    "    func = lambda trial: objective(trial, X_current_family, y_current_family)[0]\n",
    "    study.optimize(func, n_trials=20)\n",
    "    for key, value in study.best_params.items():\n",
    "        best_params[current_family][key] = value\n",
    "    best_values[current_family] = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57fad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for family, all_params in best_params.items():\n",
    "    print(family)\n",
    "    for param in all_params.keys():\n",
    "        print('{}:'.format(param), all_params[param])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective='regression', eval_metric='l2' -> ~0.47\n",
    "# objective='regression_l1', eval_metric='rmsle' -> ~0.39\n",
    "\n",
    "rmsle_errors = {'{}:'.format(x): best_values[x] for x in best_values.keys()}\n",
    "median(rmsle_errors.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=365 * 33 * 54, n_splits=4, test_size=16 * 33 * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb8d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'sales'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        print(current_family)\n",
    "        columns_to_drop = [feature for feature in X if feature not in final_best_features[current_family] and \\\n",
    "                                                       feature != 'date' and feature != 'sales' and feature != 'store_nbr']\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "        #del best_params[current_family]['best_value']\n",
    "        current_family_hyper_params = best_params[current_family]\n",
    "        model = lgb.LGBMRegressor(objective='regression_l1', **current_family_hyper_params)\n",
    "        if 'store_nbr' in best_features[current_family]['green_area'] or best_features[current_family]['blue_area']:\n",
    "            model.fit(X_train_current_family.drop(columns=['date', 'sales']), y_train_current_family, categorical_feature=['store_nbr'])\n",
    "        else:\n",
    "            model.fit(X_train_current_family.drop(columns=['date', 'sales', 'store_nbr']), y_train_current_family)\n",
    "        \n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        \n",
    "        current_days_to_shift = [int(x[4:]) for x in X_train_current_family.columns if x[:3] == 'lag']\n",
    "        ends = [(16 - x) for x in current_days_to_shift]\n",
    "        ends.reverse()\n",
    "        \n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in current_days_to_shift:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                current_day_indices = X_test_current_family[X_test_current_family['date'] == current_day].index\n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day]\n",
    "                X_all_rows = pd.concat([X_train_current_family, X_test_current_family])\n",
    "                \n",
    "                rolling_features = [x for x in X_test_for_current_day.columns if x[:7] == 'rolling']\n",
    "                for current_rolling_feature in rolling_features:\n",
    "                    current_period = current_rolling_feature.split('_')[1]\n",
    "                    current_aggregate = current_rolling_feature.split('_')[2]\n",
    "                    X_test_for_current_day[current_rolling_feature] = X_all_rows.groupby(['store_nbr'])['sales'].apply(lambda x: x.shift().rolling(rolling_periods[current_period]).agg({'sales': current_aggregate})).loc[current_day_indices]\n",
    " \n",
    "                \n",
    "                predictions = 0\n",
    "                if 'store_nbr' in best_features[current_family]['green_area'] or best_features[current_family]['blue_area']:\n",
    "                    predictions = model.predict(X_test_for_current_day.drop(columns=['date', 'sales']))\n",
    "                else:\n",
    "                    predictions = model.predict(X_test_for_current_day.drop(columns=['date', 'sales', 'store_nbr']))\n",
    "                \n",
    "                predictions[predictions < 0] = 0\n",
    "                X_test_current_family.loc[current_day_indices, 'sales'] = predictions\n",
    "                \n",
    "                for current_lag in current_days_to_shift:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                current_day_index += 1\n",
    "                \n",
    "            current_days_to_shift = current_days_to_shift[:-1]\n",
    "            start = end\n",
    "        \n",
    "        for current_day in X_test_current_family['date'].unique()[start:16]:\n",
    "            current_day_indices = X_test_current_family[X_test_current_family['date'] == current_day].index\n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day]\n",
    "            X_all_rows = pd.concat([X_train_current_family, X_test_current_family])\n",
    "                \n",
    "            rolling_features = [x for x in X_test_for_current_day.columns if x[:7] == 'rolling']\n",
    "            for current_rolling_feature in rolling_features:\n",
    "                current_period = current_rolling_feature.split('_')[1]\n",
    "                current_aggregate = current_rolling_feature.split('_')[2]\n",
    "                X_test_for_current_day[current_rolling_feature] = X_all_rows.groupby(['store_nbr'])['sales'].apply(lambda x: x.shift().rolling(rolling_periods[current_period]).agg({'sales': current_aggregate})).loc[current_day_indices]\n",
    " \n",
    "                \n",
    "            predictions = 0\n",
    "            if 'store_nbr' in best_features[current_family]['green_area'] or best_features[current_family]['blue_area']:\n",
    "                predictions = model.predict(X_test_for_current_day.drop(columns=['date', 'sales']))\n",
    "            else:\n",
    "                predictions = model.predict(X_test_for_current_day.drop(columns=['date', 'sales', 'store_nbr']))\n",
    "            \n",
    "            predictions[predictions < 0] = 0\n",
    "            X_test_current_family.loc[current_day_indices, 'sales'] = predictions\n",
    "            current_day_index += 1\n",
    "        \n",
    "        \n",
    "        y_pred_current_family = 0\n",
    "        if 'store_nbr' in best_features[current_family]['green_area'] or best_features[current_family]['blue_area']:\n",
    "            y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'sales']))\n",
    "        else:\n",
    "            y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'sales', 'store_nbr']))\n",
    "        \n",
    "        y_pred_current_family[y_pred_current_family < 0] = 0\n",
    "        X_test.loc[current_family_indices_test, 'sales'] = y_pred_current_family\n",
    "        \n",
    "        \n",
    "    y_pred = X_test['sales'].copy()\n",
    "    X_test = X_test.drop(columns=['sales'])\n",
    "    \n",
    "    print(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6108e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for period, days in rolling_periods.items():\n",
    "    for function in aggregate_functions:\n",
    "        test_data['rolling_{0}_{1}'.format(period, function)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24ac3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data['sales'] = 0\n",
    "for current_family in X_train['family'].unique():\n",
    "    print(current_family)\n",
    "    columns_to_drop = [feature for feature in X_train if feature not in best_features[current_family]['green_area'] and \\\n",
    "                                                       feature not in best_features[current_family]['blue_area'] and \\\n",
    "                                                       feature != 'date' and feature != 'sales' and feature != 'store_nbr']\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=columns_to_drop)\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "    \n",
    "    current_family_hyper_params = best_params[current_family]\n",
    "    model = lgb.LGBMRegressor(objective='regression_l1', **current_family_hyper_params)\n",
    "    if 'store_nbr' in best_features[current_family]['green_area'] or best_features[current_family]['blue_area']:\n",
    "        model.fit(X_train_current_family.drop(columns=['date', 'sales']), y_train_current_family, categorical_feature=['store_nbr'])\n",
    "    else:\n",
    "        model.fit(X_train_current_family.drop(columns=['date', 'sales', 'store_nbr']), y_train_current_family)\n",
    "        \n",
    "        \n",
    "    current_family_indices_test = test_data[test_data['family'] == current_family].index\n",
    "    X_test_current_family = test_data[test_data['family'] == current_family].drop(columns=columns_to_drop)\n",
    "    \n",
    "    current_days_to_shift = [int(x[4:]) for x in X_train_current_family.columns if x[:3] == 'lag']\n",
    "    ends = [(16 - x) for x in current_days_to_shift]\n",
    "    ends.reverse()\n",
    "\n",
    "    start = 0\n",
    "    current_day_index = 0\n",
    "    for end in ends:\n",
    "        for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "            current_day_plus_x = {}\n",
    "            for current_lag in current_days_to_shift:\n",
    "                current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "            current_day_indices = X_test_current_family[X_test_current_family['date'] == current_day].index\n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day]\n",
    "            X_all_rows = pd.concat([X_train_current_family, X_test_current_family])\n",
    "                \n",
    "            rolling_features = [x for x in X_test_for_current_day.columns if x[:7] == 'rolling']\n",
    "            for current_rolling_feature in rolling_features:\n",
    "                current_period = current_rolling_feature.split('_')[1]\n",
    "                current_aggregate = current_rolling_feature.split('_')[2]\n",
    "                X_test_for_current_day[current_rolling_feature] = X_all_rows.groupby(['store_nbr'])['sales'].apply(lambda x: x.shift().rolling(rolling_periods[current_period]).agg({'sales': current_aggregate})).loc[current_day_indices]\n",
    " \n",
    "                \n",
    "            predictions = 0\n",
    "            if 'store_nbr' in best_features[current_family]['green_area'] or best_features[current_family]['blue_area']:\n",
    "                predictions = model.predict(X_test_for_current_day.drop(columns=['date', 'sales']))\n",
    "            else:\n",
    "                predictions = model.predict(X_test_for_current_day.drop(columns=['date', 'sales', 'store_nbr']))\n",
    "                \n",
    "            predictions[predictions < 0] = 0\n",
    "            X_test_current_family.loc[current_day_indices, 'sales'] = predictions\n",
    "        \n",
    "            for current_lag in current_days_to_shift:\n",
    "                X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "            current_day_index += 1\n",
    "                \n",
    "        current_days_to_shift = current_days_to_shift[:-1]\n",
    "        start = end\n",
    "        \n",
    "    for current_day in X_test_current_family['date'].unique()[start:16]:\n",
    "        current_day_indices = X_test_current_family[X_test_current_family['date'] == current_day].index\n",
    "        X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day]#.drop(columns=[x for x in X_test_current_family.columns if x in columns_to_drop])\n",
    "        X_all_rows = pd.concat([X_train_current_family, X_test_current_family])\n",
    "                \n",
    "        rolling_features = [x for x in X_test_for_current_day.columns if x[:7] == 'rolling']\n",
    "        for current_rolling_feature in rolling_features:\n",
    "            current_period = current_rolling_feature.split('_')[1]\n",
    "            current_aggregate = current_rolling_feature.split('_')[2]\n",
    "            X_test_for_current_day[current_rolling_feature] = X_all_rows.groupby(['store_nbr'])['sales'].apply(lambda x: x.shift().rolling(rolling_periods[current_period]).agg({'sales': current_aggregate})).loc[current_day_indices]\n",
    " \n",
    "                \n",
    "        predictions = 0\n",
    "        if 'store_nbr' in best_features[current_family]['green_area'] or best_features[current_family]['blue_area']:\n",
    "            predictions = model.predict(X_test_for_current_day.drop(columns=['date', 'sales']))\n",
    "        else:\n",
    "            predictions = model.predict(X_test_for_current_day.drop(columns=['date', 'sales', 'store_nbr']))\n",
    "            \n",
    "        predictions[predictions < 0] = 0\n",
    "        X_test_current_family.loc[current_day_indices, 'sales'] = predictions\n",
    "        current_day_index += 1\n",
    "        \n",
    "        \n",
    "    y_pred_current_family = 0\n",
    "    if 'store_nbr' in best_features[current_family]['green_area'] or best_features[current_family]['blue_area']:\n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'sales']))\n",
    "    else:\n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'sales', 'store_nbr']))\n",
    "        \n",
    "    y_pred_current_family[y_pred_current_family < 0] = 0\n",
    "    submission.loc[current_family_indices_test, 'sales'] = y_pred_current_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e01c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/lgbm_boruta_optuna.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cdc697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5814f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
