{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3382be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.environ['PROJECT_ROOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabad7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "from lightgbm import LGBMRegressor\n",
    "from pathlib import Path\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "from mentorship.features.kaggle.storesales.etl import ETLTransformer\n",
    "from mentorship.features.history import cut_history\n",
    "from mentorship.features.tuning import boruta_features_tuning\n",
    "from mentorship.ml.cv.split import DateTimeSeriesSplit\n",
    "from mentorship.ml.cv.util import format_cv_test_scores\n",
    "from mentorship.ml.models.kaggle.storesales.hyperparams.tuning import tune_hyperparams\n",
    "from mentorship.ml.models.kaggle.storesales.boosting import LGBMPipeline\n",
    "from mentorship.ml.models.kaggle.storesales.linear import LinearPipeline\n",
    "from mentorship.ml.models.common import RecursiveTSEstimator\n",
    "from mentorship.ml.models.kaggle.storesales.estimators import RecursiveTSEstimatorWithZeroCategories\n",
    "from mentorship.ml.tools.kaggle.storesales.submission import make_submission_file\n",
    "from mentorship.ml.tools.kaggle.storesales.curves import plot_learning_curver\n",
    "from mentorship.ml.tools.timeit import timeit\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_METRICS = [\n",
    "    'neg_mean_squared_log_error',\n",
    "    'neg_root_mean_squared_error',\n",
    "    'neg_mean_absolute_error',\n",
    "    'r2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc28e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('data', 'kaggle', 'store-sales-time-series-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271bf15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STORES = train['store_nbr'].nunique()\n",
    "N_FAMILIES = train['family'].nunique()\n",
    "N_TIME_SERIES = N_STORES * N_FAMILIES\n",
    "\n",
    "DAYS_IN_YEAR = 365\n",
    "N_HORIZONS = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d4207",
   "metadata": {},
   "source": [
    "# 0.1 test (linear regression with best lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4dc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL stage for the train data\n",
    "\n",
    "lags = [1, 2, 4, 6, 7, 14]\n",
    "\n",
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(lags=lags, target_col='sales', use_final_metric=False)\n",
    "X = train_transformer.transform(X)\n",
    "\n",
    "y = X['sales'].copy()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "\n",
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    base_pipelines[current_family] = LinearPipeline(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], \n",
    "                                                    drop_columns=['onpromotion'], lags=lags, split_key='family', \n",
    "                                                    target_col='sales', use_final_metric=False)\n",
    "\n",
    "modelling_pipeline = RecursiveTSEstimator(base_pipelines=base_pipelines, split_key='family', target_col='sales')\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise')\n",
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdb33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting X_train and y_train for the final model training\n",
    "\n",
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=pd.Timedelta(days=DAYS_IN_YEAR), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c80b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL stage for the test data\n",
    "\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer()\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the final model and making submission file\n",
    "\n",
    "modelling_pipeline.fit(X_train, y_train)\n",
    "make_submission_file(test_data, modelling_pipeline, 'linreg_with_recursive_lags1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a02d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bf43c62",
   "metadata": {},
   "source": [
    "# 0.2 test (LGBMRegressor with default params, same features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 4, 6, 7, 14]\n",
    "\n",
    "X = train.copy()\n",
    "y = X['sales'].copy()\n",
    "\n",
    "train_transformer = ETLTransformer(lags=lags, target_col='sales')\n",
    "X = train_transformer.transform(X)\n",
    "splitter = DateTimeSeriesSplit()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc198ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here I have a question: how to pass 'categorical_feature' parameter to the PositiveRegressor(lgb.LGBMRegressor)?\n",
    "# Inside 'fit' method, X matrix has np.ndarray type, so I can't pass the name of the feature to 'categorical_feature' parameter.\n",
    "# That is why I have to pass indices of the columns I need to mark as 'categorical' (indices become clear only \n",
    "# after ColDrop stage)\n",
    "\n",
    "params = {'categorical_feature': 'name: \"store_nbr\"'}\n",
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    base_pipelines[current_family] = LGBMPipeline(drop_columns=['onpromotion'], lags=lags, split_key='family', \n",
    "                                                  target_col='sales', level=['store_nbr'], params=params)\n",
    "modelling_pipeline = RecursiveTSEstimator(base_pipelines=base_pipelines, split_key='family', target_col='sales')\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise')\n",
    "format_cv_test_scores(scores, metrics_to_plot=['root_mean_squared_log_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3733b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_cv_test_scores(scores, metrics_to_plot=['root_mean_squared_log_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=pd.Timedelta(days=DAYS_IN_YEAR), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer()\n",
    "test_data = test_transformer.transform(test_data)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train, y_train)\n",
    "make_submission_file(test_data, modelling_pipeline, 'default_LGBM_with_recursive_lags2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a372c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "vvv = pd.read_csv(DATA_ROOT / 'default_LGBM_with_recursive_lags1.csv')\n",
    "www = pd.read_csv(DATA_ROOT / 'default_LGBM_with_recursive_lags2.csv')\n",
    "print((vvv['sales'] - www['sales']).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e652614",
   "metadata": {},
   "outputs": [],
   "source": [
    "www['sales'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94aea0c",
   "metadata": {},
   "source": [
    "# 1. Experiments with LGBMRegressor for every family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b163fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lags = [1, 2, 4, 6, 7, 14]\n",
    "\n",
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(lags=lags, target_col='sales')\n",
    "X = train_transformer.transform(X)\n",
    "y = X['sales'].copy()\n",
    "\n",
    "splitter = DateTimeSeriesSplit()\n",
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=pd.Timedelta(days=DAYS_IN_YEAR), y=y)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer()\n",
    "test_data = test_transformer.transform(test_data)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e706621",
   "metadata": {},
   "source": [
    "#### Compare scores for each family (linear regression and simplest lgbm regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168005ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_scores_linear, final_scores_lgbm = {}, {}\n",
    "for current_family in X['family'].unique():\n",
    "    X_current_family = X[X['family'] == current_family]\n",
    "    y_current_family = y.loc[X_current_family.index]\n",
    "    \n",
    "    base_linear_pipeline = {current_family:LinearPipeline(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], \n",
    "                                                           drop_columns=['onpromotion'], lags=lags, split_key='family', \n",
    "                                                           target_col='sales')}\n",
    "    modelling_pipeline_linear = RecursiveTSEstimator(base_pipelines=base_linear_pipeline, split_key='family', target_col='sales')\n",
    "\n",
    "    fit_params_lgbm = {'categorical_feature': [0]}\n",
    "    base_lgbm_pipeline = {current_family:LGBMPipeline(lags=lags, split_key='family', target_col='sales', \n",
    "                                                       fit_params=fit_params_lgbm)}\n",
    "    modelling_pipeline_lgbm = RecursiveTSEstimator(base_pipelines=base_lgbm_pipeline, split_key='family', target_col='sales')\n",
    "    \n",
    "    scores_linear = cross_validate(modelling_pipeline_linear, X_current_family, y_current_family, cv=splitter, \n",
    "                                   scoring=CV_METRICS, return_estimator=True, error_score='raise', n_jobs=-1)\n",
    "    scores_lgbm = cross_validate(modelling_pipeline_lgbm, X_current_family, y_current_family, cv=splitter, \n",
    "                                 scoring=CV_METRICS, return_estimator=True, error_score='raise', n_jobs=-1)\n",
    "    \n",
    "    final_scores_linear[current_family] = save_cv_test_scores(scores_linear)\n",
    "    final_scores_lgbm[current_family] = save_cv_test_scores(scores_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b971b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in final_scores_linear.keys():\n",
    "    print(f'{key} (linreg): {final_scores_linear[key][0][\"root_mean_squared_log_error\"]:.3f} ± {final_scores_linear[key][1][\"root_mean_squared_log_error\"]:.3f}')\n",
    "    print(f'{key} (lgbm): {final_scores_lgbm[key][0][\"root_mean_squared_log_error\"]:.3f} ± {final_scores_lgbm[key][1][\"root_mean_squared_log_error\"]:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088390b9",
   "metadata": {},
   "source": [
    "<p><i>'books' family will be fitted with LinearRegression (because of big difference in scores and anomalous distribution)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c94625",
   "metadata": {},
   "source": [
    "#### Learning curves for default lgbm (metric: 'msle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31ebe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tscv_inner = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR - 4 * N_HORIZONS) * N_STORES, n_splits=4,\n",
    "                             test_size=N_HORIZONS * N_STORES)\n",
    "train_sizes = [60 * N_STORES, 120 * N_STORES, 180 * N_STORES, 240 * N_STORES, 301 * N_STORES]\n",
    "learning_curves(X, y, tscv_inner=tscv_inner, train_sizes=train_sizes, lags=lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e34e614",
   "metadata": {},
   "source": [
    "#### Hyperparameters tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af2916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters tuning (for cross validation)\n",
    "\n",
    "train_indices = next(splitter.split(X, y))[0]\n",
    "X_train_first_fold, y_train_first_fold = X.iloc[train_indices], y.iloc[train_indices]\n",
    "\n",
    "best_cv_params = hyperparams_tuning(X_train_first_fold, y_train_first_fold, tscv_inner=tscv_inner, lags=lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253486a8",
   "metadata": {},
   "source": [
    "#### Looking for 'zero'-families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba1254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for current_family in X_train['family'].unique():\n",
    "    X_current_family = X_train[X_train['family'] == current_family]\n",
    "    print(f'{current_family}: {(X_current_family[\"sales\"] == 0).mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {'categorical_feature': [0]}\n",
    "\n",
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    base_pipelines[current_family] = LGBMPipeline(lags=lags, split_key='family', target_col='sales', \n",
    "                                                   params=best_cv_params[current_family], fit_params=fit_params)\n",
    "modelling_pipeline = RecursiveTSEstimator(base_pipelines=base_pipelines, split_key='family', target_col='sales',\n",
    "                                           zero_categories=['baby care', 'books'])\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise',\n",
    "                        n_jobs=-1)\n",
    "print_cv_test_scores(scores, metrics_to_plot=['root_mean_squared_log_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3220084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### best params for final model (nested cross validation on X_train, y_train)\n",
    "\n",
    "best_final_params = hyperparams_tuning(X_train, y_train, tscv_inner=tscv_inner, lags=lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    base_pipelines[current_family] = LGBMPipeline(lags=lags, split_key='family', target_col='sales', \n",
    "                                                   params=best_final_params[current_family], fit_params=fit_params)\n",
    "\n",
    "final_modelling_pipeline = RecursiveTSEstimator(base_pipelines=base_pipelines, split_key='family', target_col='sales',\n",
    "                                                 zero_categories=['baby care', 'books'])\n",
    "final_modelling_pipeline.fit(X_train, y_train)\n",
    "make_submission_file(test_data, final_modelling_pipeline, 'optuna_LGBM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2cd4df",
   "metadata": {},
   "source": [
    "### Score on Kaggle: 0.42286"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490147c",
   "metadata": {},
   "source": [
    "### LinearRegression and LGBMRegressor combining "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d711f",
   "metadata": {},
   "source": [
    "#### Learning curves for lgbm with tuned parameters (metric 'msle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77c593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tscv_inner = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR - 4 * N_HORIZONS) * N_STORES, n_splits=4,\n",
    "                             test_size=N_HORIZONS * N_STORES)\n",
    "train_sizes = [60 * N_STORES, 120 * N_STORES, 180 * N_STORES, 240 * N_STORES, 301 * N_STORES]\n",
    "learning_curves(X, y, params=best_cv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812404bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_categories = ['baby care', 'books', 'lawn and garden', 'home appliances']\n",
    "fit_params = {'categorical_feature': [0]}\n",
    "\n",
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    if current_family in linear_categories:\n",
    "        base_pipelines[current_family] = LinearPipeline(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], \n",
    "                                                         drop_columns=['onpromotion'], lags=lags, split_key='family', \n",
    "                                                         target_col='sales')\n",
    "    else:\n",
    "        base_pipelines[current_family] = LGBMPipeline(lags=lags, split_key='family', target_col='sales', \n",
    "                                                       fit_params=fit_params, params=best_cv_params[current_family])\n",
    "\n",
    "\n",
    "modelling_pipeline = RecursiveTSEstimator(split_key='family', target_col='sales', base_pipelines=base_pipelines,\n",
    "                                           zero_categories=['baby care', 'books'])\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise')\n",
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b95800",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    if current_family in linear_categories:\n",
    "        base_pipelines[current_family] = LinearPipeline(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], \n",
    "                                                         drop_columns=['onpromotion'], lags=lags, split_key='family', \n",
    "                                                         target_col='sales')\n",
    "    else:\n",
    "        base_pipelines[current_family] = LGBMPipeline(lags=lags, split_key='family', target_col='sales', \n",
    "                                                       fit_params=fit_params, params=best_final_params[current_family])\n",
    "\n",
    "final_modelling_pipeline = RecursiveTSEstimator(split_key='family', target_col='sales', base_pipelines=base_pipelines, \n",
    "                                                 zero_categories=['baby care', 'books'])\n",
    "final_modelling_pipeline.fit(X_train, y_train)\n",
    "make_submission_file(test_data, final_modelling_pipeline, 'optuna_LGBM_and_linreg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32bbd7",
   "metadata": {},
   "source": [
    "### Score on Kaggle: 0.4185"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae0451",
   "metadata": {},
   "source": [
    "### Adding feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec992a47",
   "metadata": {},
   "source": [
    "#### Feature importance in default LGBMRegressor (for every family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bdd02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm.feature_importances_ on the train set of the first cv fold\n",
    "\n",
    "train_indices = next(splitter.split(X, y))[0]\n",
    "X_train_first_fold, y_train_first_fold = X.iloc[train_indices], y.iloc[train_indices]\n",
    "\n",
    "for i, current_family in enumerate(X_train_first_fold['family'].unique()):\n",
    "    X_current_family = X_train_first_fold[X_train_first_fold['family'] == current_family].drop(columns=['date', 'sales', 'family'])\n",
    "    y_current_family = y_train_first_fold.loc[X_current_family.index]\n",
    "    \n",
    "    lgbm_model = lgb.LGBMRegressor(importance_type='split')\n",
    "    lgbm_model.fit(X_current_family, y_current_family, categorical_feature=['store_nbr'])\n",
    "    lgbm_feature_imp = pd.DataFrame(sorted(zip(lgbm_model.feature_importances_, X_current_family.columns)), \n",
    "                                    columns=['Value', 'Feature'])\n",
    "    sns.barplot(x='Value', y='Feature', data=lgbm_feature_imp.sort_values(by='Value', ascending=False))\n",
    "    plt.title(f'{current_family} (feature_importances_)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c9cc9",
   "metadata": {},
   "source": [
    "#### Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158dbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# boruta for choosing best features\n",
    "\n",
    "train_indices = next(splitter.split(X, y))[0]\n",
    "X_train_first_fold, y_train_first_fold = X.drop(columns=['date', 'sales']).iloc[train_indices], y.iloc[train_indices]\n",
    "best_features = boruta_features_tuning(X_train_first_fold, y_train_first_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec710b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_family in X_train_first_fold['family'].unique():\n",
    "    print(current_family)\n",
    "    print(f'Confirmed: {best_features[current_family][\"green_area\"]}')\n",
    "    print(f'Tentative: {best_features[current_family][\"blue_area\"]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03babadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features which will be removed from the dataset while training final model\n",
    "\n",
    "drop_columns = {family:[feature for feature in X.drop(columns=['sales', 'date', 'family']).columns\n",
    "                        if feature not in best_features[family]['green_area']]\n",
    "                for family in X['family'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc093b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best_cv_params with new features set\n",
    "\n",
    "train_indices = next(splitter.split(X, y))[0]\n",
    "X_train_first_fold, y_train_first_fold = X.iloc[train_indices], y.iloc[train_indices]\n",
    "tscv_inner = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR - 4 * N_HORIZONS) * N_STORES, n_splits=4,\n",
    "                             test_size=N_HORIZONS * N_STORES)\n",
    "best_cv_params_boruta = hyperparams_tuning(X_train_first_fold, y_train_first_fold, tscv_inner=tscv_inner, \n",
    "                                           drop_columns=drop_columns, lags=lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_categories = ['baby care', 'books', 'lawn and garden', 'home appliances']\n",
    "fit_params = {'categorical_feature': [0]}\n",
    "\n",
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    if current_family in linear_categories:\n",
    "        base_pipelines[current_family] = LinearPipeline(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], \n",
    "                                                         drop_columns=['onpromotion'], lags=lags, split_key='family', \n",
    "                                                         target_col='sales')\n",
    "    else:\n",
    "        base_pipelines[current_family] = LGBMPipeline(drop_columns=drop_columns[current_family], lags=lags, \n",
    "                                                       split_key='family', target_col='sales', fit_params=fit_params, \n",
    "                                                       params=best_cv_params_boruta[current_family])\n",
    "        if 'store_nbr' in drop_columns[current_family]:\n",
    "            base_pipelines[current_family].fit_params = {}\n",
    "            \n",
    "modelling_pipeline = RecursiveTSEstimator(split_key='family', target_col='sales', base_pipelines=base_pipelines,\n",
    "                                           zero_categories=['baby care', 'books'])\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise', \n",
    "                        n_jobs=-1)\n",
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba23e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best_final_params with new feature set\n",
    "\n",
    "best_final_params_boruta = hyperparams_tuning(X_train, y_train, drop_columns=drop_columns, lags=lags, tscv_inner=tscv_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_categories = ['baby care', 'books', 'lawn and garden', 'home appliances']\n",
    "fit_params = {'categorical_feature': [0]}\n",
    "\n",
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    if current_family in linear_categories:\n",
    "        base_pipelines[current_family] = LinearPipeline(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], \n",
    "                                                         drop_columns=['onpromotion'], lags=lags, split_key='family', \n",
    "                                                         target_col='sales')\n",
    "    else:\n",
    "        base_pipelines[current_family] = LGBMPipeline(drop_columns=drop_columns[current_family], lags=lags, \n",
    "                                                       split_key='family', target_col='sales', fit_params=fit_params, \n",
    "                                                       params=best_final_params_boruta[current_family])\n",
    "        if 'store_nbr' in drop_columns[current_family]:\n",
    "            base_pipelines[current_family].fit_params = {}\n",
    "            \n",
    "final_modelling_pipeline = RecursiveTSEstimator(split_key='family', target_col='sales', base_pipelines=base_pipelines,\n",
    "                                                 zero_categories=['baby care', 'books'])\n",
    "\n",
    "final_modelling_pipeline.fit(X_train, y_train)\n",
    "make_submission_file(test_data, final_modelling_pipeline, 'optuna_LGBM_and_linreg_boruta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460c4f3",
   "metadata": {},
   "source": [
    "### Score on Kaggle: 0.43458"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5069ea0a",
   "metadata": {},
   "source": [
    "### Adding features from other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_copy = X.copy()\n",
    "# X_copy['is_holiday'] = train_transformer.adding_is_holiday_feature(X_copy)\n",
    "X_copy = train_transformer.adding_stores_data(X_copy, columns_to_add=['city', 'type'])\n",
    "X_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b69cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_categories = ['baby care', 'books', 'lawn and garden', 'home appliances']\n",
    "fit_params = {'categorical_feature': [0, -1, -2]}\n",
    "\n",
    "base_pipelines = {}\n",
    "for current_family in X_copy['family'].unique():\n",
    "    if current_family in linear_categories:\n",
    "        base_pipelines[current_family] = LinearPipeline(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], \n",
    "                                                         drop_columns=['onpromotion', 'store_city', 'store_type'], lags=lags, \n",
    "                                                         split_key='family', target_col='sales')\n",
    "    else:\n",
    "        base_pipelines[current_family] = LGBMPipeline(lags=lags, split_key='family', target_col='sales', \n",
    "                                                       fit_params=fit_params, params=best_cv_params[current_family]) \n",
    "\n",
    "modelling_pipeline = RecursiveTSEstimator(split_key='family', target_col='sales', base_pipelines=base_pipelines, \n",
    "                                           zero_categories=['baby care', 'books'])\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X_copy, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, \n",
    "                        error_score='raise', n_jobs=-1)\n",
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08491b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy, y_train_copy = cut_history(X=X_copy, date_column='date', keep_interval=pd.Timedelta(days=DAYS_IN_YEAR), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_copy = test_data.copy()\n",
    "test_data_copy = test_transformer.adding_stores_data(test_data_copy, columns_to_add=['city', 'type'])\n",
    "test_data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5234e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipelines = {}\n",
    "for current_family in X_copy['family'].unique():\n",
    "    if current_family in linear_categories:\n",
    "        base_pipelines[current_family] = LinearPipeline(cols_to_scale=['dcoilwtico'], cols_to_encode=['store_nbr'], \n",
    "                                                         drop_columns=['onpromotion', 'store_city', 'store_type'], lags=lags, \n",
    "                                                         split_key='family', target_col='sales')\n",
    "    else:\n",
    "        base_pipelines[current_family] = LGBMPipeline(lags=lags, split_key='family', target_col='sales', \n",
    "                                                       fit_params=fit_params, params=best_final_params[current_family])\n",
    "\n",
    "final_modelling_pipeline = RecursiveTSEstimator(split_key='family', target_col='sales', base_pipelines=base_pipelines, \n",
    "                                                 zero_categories=['baby care', 'books'])\n",
    "final_modelling_pipeline.fit(X_train_copy, y_train_copy)\n",
    "make_submission_file(test_data_copy, final_modelling_pipeline, 'optuna_LGBM_and_linreg_v8.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b5cc45",
   "metadata": {},
   "source": [
    "### Score on Kaggle: 0.77113  ---> features from other datasets (holidays, stores data) don't improve score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc1b568",
   "metadata": {},
   "source": [
    "### Adding rolling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 4, 6, 7, 14]\n",
    "rolling_days = [365, 183, 92, 31, 16, 10, 7, 5, 3]\n",
    "rolling_aggr = {np.median: 'median', np.mean: 'mean', np.sum: 'sum', np.max: 'max', np.min: 'min'}\n",
    "\n",
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(lags=lags, target_col='sales', adding_rolling_features=True, \n",
    "                                    rolling_days=rolling_days, rolling_aggr=rolling_aggr)\n",
    "\n",
    "X = train_transformer.transform(X)[0]\n",
    "y = X['sales'].copy()\n",
    "\n",
    "X['store_nbr'] = X['store_nbr'].astype('category')\n",
    "\n",
    "splitter = DateTimeSeriesSplit()\n",
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=pd.Timedelta(days=DAYS_IN_YEAR), y=y)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer(adding_lags=False)\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data['store_nbr'] = test_data['store_nbr'].astype('category')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing best cross-validation and final params\n",
    "import json\n",
    "\n",
    "with open(DATA_ROOT / 'best_cv_params_with_rolling.txt') as f:\n",
    "    data = f.read()\n",
    "best_cv_params_with_rolling = json.loads(data)\n",
    "\n",
    "with open(DATA_ROOT / 'best_features_with_rolling.txt') as f:\n",
    "    data = f.read()\n",
    "best_features_with_rolling = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aab815",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {'categorical_feature': [0]}\n",
    "\n",
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    base_pipelines[current_family] = LGBMPipeline(lags=lags, split_key='family', target_col='sales', \n",
    "                                                   fit_params=fit_params, rolling_days=rolling_days, \n",
    "                                                   rolling_aggr=rolling_aggr)\n",
    "\n",
    "modelling_pipeline = RecursiveTSEstimator(split_key='family', target_col='sales', base_pipelines=base_pipelines,\n",
    "                                           zero_categories=['baby care', 'books'])\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise',\n",
    "                        n_jobs=-1)\n",
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47cf28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boruta\n",
    "\n",
    "train_indices = next(splitter.split(X, y))[0]\n",
    "X_train_first_fold, y_train_first_fold = X.drop(columns=['date', 'sales']).iloc[train_indices], y.iloc[train_indices]\n",
    "best_features_with_rolling = boruta_features_tuning(X_train_first_fold, y_train_first_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a678146",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_family in X_train_first_fold['family'].unique():\n",
    "    print(current_family)\n",
    "    print(f'Confirmed: {best_features_with_rolling[current_family][\"green_area\"]}')\n",
    "    print(f'Tentative: {best_features_with_rolling[current_family][\"blue_area\"]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = {family:[feature for feature in X.drop(columns=['sales', 'date', 'family']).columns\n",
    "                        if feature not in best_features_with_rolling[family]['green_area']]\n",
    "                for family in X['family'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f4e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {'categorical_feature': [0]}\n",
    "\n",
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    base_pipelines[current_family] = LGBMPipeline(lags=lags, split_key='family', target_col='sales', \n",
    "                                                   fit_params=fit_params, rolling_days=rolling_days, \n",
    "                                                   rolling_aggr=rolling_aggr, drop_columns=drop_columns[current_family])\n",
    "\n",
    "modelling_pipeline = RecursiveTSEstimator(split_key='family', target_col='sales', base_pipelines=base_pipelines,\n",
    "                                           zero_categories=['baby care', 'books'])\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise', \n",
    "                        n_jobs=-1)\n",
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe7db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for this nested cv I needed to expand train set of the first fold \n",
    "# (because I need to count rolling features with 365 days window, but train set size of the first fold is 365 days\n",
    "# and it is not enough for this)\n",
    "\n",
    "train_indices = next(splitter.split(X, y))[0]\n",
    "X_train_first_fold, y_train_first_fold = X.iloc[train_indices], y.iloc[train_indices]\n",
    "\n",
    "X_expand_train_first_fold = X[(pd.to_datetime(X['date']) >= pd.to_datetime(X_train_first_fold['date'].min()) - pd.Timedelta(days=4 * N_HORIZONS)) & \n",
    "                              (pd.to_datetime(X['date']) <= pd.to_datetime(X_train_first_fold['date'].max()))]\n",
    "y_expand_train_first_fold = y.loc[X_expand_train_first_fold.index]\n",
    "\n",
    "tscv_inner = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_STORES, n_splits=4, \n",
    "                                        test_size=N_HORIZONS * N_STORES)\n",
    "\n",
    "best_cv_params_with_rolling = hyperparams_tuning(X_expand_train_first_fold, y_expand_train_first_fold, \n",
    "                                                 drop_columns=drop_columns, lags=lags, rolling_days=rolling_days, \n",
    "                                                 rolling_aggr=rolling_aggr, tscv_inner=tscv_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d196885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_params = {'categorical_feature': [0]}\n",
    "\n",
    "base_pipelines = {}\n",
    "for current_family in X['family'].unique():\n",
    "    base_pipelines[current_family] = LGBMPipeline(drop_columns=drop_columns[current_family], lags=lags, \n",
    "                                                   split_key='family', target_col='sales',\n",
    "                                                   params=best_cv_params_with_rolling[current_family], \n",
    "                                                   rolling_days=rolling_days, rolling_aggr=rolling_aggr)\n",
    "#     if 'store_nbr' in drop_columns[current_family]:\n",
    "#         base_pipelines[current_family].fit_params = {}\n",
    "            \n",
    "modelling_pipeline = RecursiveTSEstimator(split_key='family', target_col='sales', base_pipelines=base_pipelines,\n",
    "                                           zero_categories=['baby care', 'books'])\n",
    "\n",
    "scores = cross_validate(modelling_pipeline, X, y, cv=splitter, scoring=CV_METRICS, return_estimator=True, error_score='raise',\n",
    "                        n_jobs=-1)\n",
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indices = next(splitter.split(X, y))[0]\n",
    "# X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "\n",
    "# for current_family in X_train['family'].unique():\n",
    "#     print(current_family)\n",
    "#     X_current_family = X_train[X_train['family'] == current_family].drop(columns=['date', 'family', 'sales'])\n",
    "#     y_current_family = y_train.loc[X_current_family.index]\n",
    "    \n",
    "#     model = lgb.LGBMRegressor()    \n",
    "#     model.fit(X_current_family, y_current_family)\n",
    "#     explainer = shap.TreeExplainer(model, X_current_family)\n",
    "#     shap_values = explainer(X_current_family)\n",
    "#     shap.plots.bar(shap_values, max_display=25)\n",
    "    \n",
    "#     print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
