{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b25974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.environ['PROJECT_ROOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0669a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pdpipe as pdp\n",
    "import statsmodels.api as sm\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, MetaEstimatorMixin, TransformerMixin, clone\n",
    "from datetime import timedelta\n",
    "from statistics import median, mean, stdev\n",
    "from pdpipe import df\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression, mutual_info_regression, RFE\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from mentorship.ml.models.reg import PositiveRegressor\n",
    "from mentorship.ml.models.common import SplitPipeline\n",
    "from mentorship.ml.models.kaggle.storesales.linear import PipelineLinearV1\n",
    "from mentorship.ml.models.kaggle.storesales.ridge import PipelineRidgeV1\n",
    "from mentorship.ml.models.kaggle.storesales.lasso import PipelineLassoV1\n",
    "from mentorship.ml.models.kaggle.storesales.elasticnet import PipelineElasticNetV1\n",
    "from mentorship.features.kaggle.storesales.etl import ETLTransformer\n",
    "from mentorship.ml.cv.split import DateTimeSeriesSplit\n",
    "from mentorship.ml.cv.util import print_cv_test_scores\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c94636",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_METRICS = [\n",
    "    'neg_mean_squared_log_error',\n",
    "    'neg_root_mean_squared_error',\n",
    "    'neg_mean_absolute_error',\n",
    "    # 'neg_mean_absolute_percentage_error',\n",
    "    'r2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebbddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('data', 'kaggle', 'store-sales-time-series-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd374d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb620e",
   "metadata": {},
   "source": [
    " # 1. Linear Regression, features: 'store_nbr', 'dcoilwtico', 'lags' for target (1, 2, 4, 6, 7, 14 days shift) (recursive strategy), 'rolling' features (SelectFromModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d84056",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d58116",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 4, 6, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X['dcoilwtico'].notna()]\n",
    "X = X.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "\n",
    "for current_lag in days_to_shift:\n",
    "    X.loc[:, 'lag_{}'.format(current_lag)] = X.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)\n",
    "    test_data.loc[:, 'lag_{}'.format(current_lag)] = 0\n",
    "    \n",
    "    for i in range(current_lag):\n",
    "        test_data.loc[test_data[test_data['date'] == test_data['date'].unique()[i]].index, 'lag_{}'.format(current_lag)] = X.loc[X[X['date'] == X['date'].unique()[-(current_lag - i)]].index, 'sales'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "\n",
    "test_data.loc[:, 'sales'] = 0\n",
    "for date in test_data['date'].unique():\n",
    "    test_data.loc[test_data[test_data['date'] == date].index, 'sales'] = X_train.groupby(['store_nbr', 'family'])['sales'].median().reset_index([0, 1], drop=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f83000",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sales_copy = X['sales'].copy()\n",
    "X = X.drop(columns=['sales'])\n",
    "X['sales'] = X_sales_copy\n",
    "\n",
    "test_dates = test_data['date'].unique()\n",
    "X_all_rows = pd.concat([X, test_data])\n",
    "X_all_rows = X_all_rows.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6dbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_periods = {'year': 365, '6m': 183, '3m': 92, '1m': 31, '16d': 16, '10d': 10, '7d': 7, '5d': 5, '3d': 3}\n",
    "aggregate_functions = ['median', 'mean', 'sum', 'max', 'min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184bd9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for period, days in rolling_periods.items():\n",
    "    for function in aggregate_functions:\n",
    "        X_all_rows['rolling_{0}_{1}'.format(period, function)] = X_all_rows.groupby(['store_nbr', 'family'])['sales'].apply(lambda x: x.shift().rolling(days).agg({'sales': function}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cfa0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = ['dcoilwtico', 'rolling_year_median', 'rolling_year_mean', 'rolling_year_sum', 'rolling_year_max', \n",
    "                     'rolling_6m_median', 'rolling_6m_mean', 'rolling_6m_sum', 'rolling_6m_max',\n",
    "                     'rolling_3m_median', 'rolling_3m_mean', 'rolling_3m_sum', 'rolling_3m_max', \n",
    "                     'rolling_1m_median', 'rolling_1m_mean', 'rolling_1m_sum', 'rolling_1m_max', \n",
    "                     'rolling_16d_median', 'rolling_16d_mean', 'rolling_16d_sum', 'rolling_16d_max', \n",
    "                     'rolling_10d_median', 'rolling_10d_mean', 'rolling_10d_sum', 'rolling_10d_max', \n",
    "                     'rolling_7d_median', 'rolling_7d_mean', 'rolling_7d_sum', 'rolling_7d_max',\n",
    "                     'rolling_5d_median', 'rolling_5d_mean', 'rolling_5d_sum', 'rolling_5d_max',\n",
    "                     'rolling_3d_median', 'rolling_3d_mean', 'rolling_3d_sum', 'rolling_3d_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee894b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = features_to_scale[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94acb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X_all_rows[X_all_rows['date'].isin(test_dates)].reset_index(drop=True).drop(columns=['sales'])\n",
    "test_data = pd.get_dummies(test_data, columns=['store_nbr'], drop_first=True)\n",
    "X = X_all_rows[~X_all_rows['date'].isin(test_dates)].drop(columns=['sales'])\n",
    "X = pd.get_dummies(X, columns=['store_nbr'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]\n",
    "\n",
    "best_features = {family:0 for family in X_train['family'].unique()}\n",
    "for current_family in X_train['family'].unique():\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "    scalers = []\n",
    "    for current_feature in features_to_scale:\n",
    "        current_scaler = MinMaxScaler()\n",
    "        X_train_current_family[[current_feature]] = current_scaler.fit_transform(X_train_current_family[[current_feature]])\n",
    "        scalers.append(current_scaler)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    \n",
    "    importance = np.abs(model.coef_)\n",
    "    threshold = np.sort(importance)[-2] + 0.01\n",
    "    sfm = SelectFromModel(model, threshold=threshold).fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    best_features[current_family] = X_train_current_family.drop(columns=['date']).columns[sfm.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=365 * 33 * 54, n_splits=4, test_size=16 * 33 * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ends = [(16 - x) for x in days_to_shift]\n",
    "ends.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dfe825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        columns_to_drop = [x for x in features_to_scale if x not in best_features[current_family]]\n",
    "        columns_to_drop.append('family')\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "        all_scalers = {}\n",
    "        for current_feature in [x for x in features_to_scale if x in best_features[current_family]]:\n",
    "            current_scaler = MinMaxScaler()\n",
    "            X_train_current_family[[current_feature]] = current_scaler.fit_transform(X_train_current_family[[current_feature]])\n",
    "            all_scalers[current_feature] = current_scaler\n",
    "        \n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        for current_feature in [x for x in features_to_scale if x in best_features[current_family]]:\n",
    "            X_test_current_family[[current_feature]] = all_scalers[current_feature].transform(X_test_current_family[[current_feature]])\n",
    "        \n",
    "        days_to_shift_copy = days_to_shift.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            days_to_shift_copy = days_to_shift_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "            \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f32a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2adc3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a61542",
   "metadata": {},
   "source": [
    "# 2. Linear Regression, features: 'store_nbr', 'dcoilwtico', 'lags' for target (1, 2, 4, 6, 7, 14 days shift) (recursive strategy), 'rolling' features (SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d620221",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 4, 6, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X['dcoilwtico'].notna()]\n",
    "X = X.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3466db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "\n",
    "for current_lag in days_to_shift:\n",
    "    X.loc[:, 'lag_{}'.format(current_lag)] = X.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)\n",
    "    test_data.loc[:, 'lag_{}'.format(current_lag)] = 0\n",
    "    \n",
    "    for i in range(current_lag):\n",
    "        test_data.loc[test_data[test_data['date'] == test_data['date'].unique()[i]].index, 'lag_{}'.format(current_lag)] = X.loc[X[X['date'] == X['date'].unique()[-(current_lag - i)]].index, 'sales'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf18ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "\n",
    "test_data.loc[:, 'sales'] = 0\n",
    "for date in test_data['date'].unique():\n",
    "    test_data.loc[test_data[test_data['date'] == date].index, 'sales'] = X_train.groupby(['store_nbr', 'family'])['sales'].median().reset_index([0, 1], drop=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sales_copy = X['sales'].copy()\n",
    "X = X.drop(columns=['sales'])\n",
    "X['sales'] = X_sales_copy\n",
    "\n",
    "test_dates = test_data['date'].unique()\n",
    "X_all_rows = pd.concat([X, test_data])\n",
    "X_all_rows = X_all_rows.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff95341",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_periods = {'year': 365, '6m': 183, '3m': 92, '1m': 31, '16d': 16, '10d': 10, '7d': 7, '5d': 5, '3d': 3}\n",
    "aggregate_functions = ['median', 'mean', 'sum', 'max', 'min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb59413",
   "metadata": {},
   "outputs": [],
   "source": [
    "for period, days in rolling_periods.items():\n",
    "    for function in aggregate_functions:\n",
    "        X_all_rows['rolling_{0}_{1}'.format(period, function)] = X_all_rows.groupby(['store_nbr', 'family'])['sales'].apply(lambda x: x.shift().rolling(days).agg({'sales': function}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c280c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = ['dcoilwtico', 'rolling_year_median', 'rolling_year_mean', 'rolling_year_sum', 'rolling_year_max', \n",
    "                     'rolling_6m_median', 'rolling_6m_mean', 'rolling_6m_sum', 'rolling_6m_max',\n",
    "                     'rolling_3m_median', 'rolling_3m_mean', 'rolling_3m_sum', 'rolling_3m_max', \n",
    "                     'rolling_1m_median', 'rolling_1m_mean', 'rolling_1m_sum', 'rolling_1m_max', \n",
    "                     'rolling_16d_median', 'rolling_16d_mean', 'rolling_16d_sum', 'rolling_16d_max', \n",
    "                     'rolling_10d_median', 'rolling_10d_mean', 'rolling_10d_sum', 'rolling_10d_max', \n",
    "                     'rolling_7d_median', 'rolling_7d_mean', 'rolling_7d_sum', 'rolling_7d_max',\n",
    "                     'rolling_5d_median', 'rolling_5d_mean', 'rolling_5d_sum', 'rolling_5d_max',\n",
    "                     'rolling_3d_median', 'rolling_3d_mean', 'rolling_3d_sum', 'rolling_3d_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc634d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16423d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X_all_rows[X_all_rows['date'].isin(test_dates)].reset_index(drop=True).drop(columns=['sales'])\n",
    "test_data = pd.get_dummies(test_data, columns=['store_nbr'], drop_first=True)\n",
    "X = X_all_rows[~X_all_rows['date'].isin(test_dates)].drop(columns=['sales'])\n",
    "X = pd.get_dummies(X, columns=['store_nbr'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a221ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca682e62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_features = {family:0 for family in X_train['family'].unique()}\n",
    "for current_family in X_train['family'].unique():\n",
    "    print(current_family)\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "    scalers = []\n",
    "    for current_feature in features_to_scale:\n",
    "        current_scaler = MinMaxScaler()\n",
    "        X_train_current_family[[current_feature]] = current_scaler.fit_transform(X_train_current_family[[current_feature]])\n",
    "        scalers.append(current_scaler)\n",
    "    \n",
    "    selector = SelectKBest(mutual_info_regression, k=10)\n",
    "    selector.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    best_features[current_family] = selector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75720a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=365 * 33 * 54, n_splits=4, test_size=16 * 33 * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebe925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        columns_to_drop = [x for x in features_to_scale if x not in best_features[current_family]]\n",
    "        columns_to_drop.append('family')\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "        all_scalers = {}\n",
    "        for current_feature in [x for x in features_to_scale if x in best_features[current_family]]:\n",
    "            current_scaler = MinMaxScaler()\n",
    "            X_train_current_family[[current_feature]] = current_scaler.fit_transform(X_train_current_family[[current_feature]])\n",
    "            all_scalers[current_feature] = current_scaler\n",
    "        \n",
    "        \n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        for current_feature in [x for x in features_to_scale if x in best_features[current_family]]:\n",
    "            X_test_current_family[[current_feature]] = all_scalers[current_feature].transform(X_test_current_family[[current_feature]])\n",
    "        \n",
    "        days_to_shift_copy = days_to_shift.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            days_to_shift_copy = days_to_shift_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "            \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a445a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24773b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "966fb909",
   "metadata": {},
   "source": [
    "# 3. Linear Regression, features: 'store_nbr', 'dcoilwtico', 'lags' for target (1, 2, 4, 6, 7, 14 days shift) (recursive strategy), 'rolling' features (L1-based selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19946f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 4, 6, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X['dcoilwtico'].notna()]\n",
    "X = X.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "\n",
    "for current_lag in days_to_shift:\n",
    "    X.loc[:, 'lag_{}'.format(current_lag)] = X.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)\n",
    "    test_data.loc[:, 'lag_{}'.format(current_lag)] = 0\n",
    "    \n",
    "    for i in range(current_lag):\n",
    "        test_data.loc[test_data[test_data['date'] == test_data['date'].unique()[i]].index, 'lag_{}'.format(current_lag)] = X.loc[X[X['date'] == X['date'].unique()[-(current_lag - i)]].index, 'sales'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_sales = pd.read_csv(DATA_ROOT / 'linreg_best_lags_only_v2.csv')\n",
    "test_data['sales'] = test_data_sales['sales'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sales_copy = X['sales'].copy()\n",
    "X = X.drop(columns=['sales'])\n",
    "X['sales'] = X_sales_copy\n",
    "\n",
    "test_dates = test_data['date'].unique()\n",
    "X_all_rows = pd.concat([X, test_data])\n",
    "X_all_rows = X_all_rows.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c783c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_periods = {'year': 365, '6m': 183, '3m': 92, '1m': 31, '16d': 16, '10d': 10, '7d': 7, '5d': 5, '3d': 3}\n",
    "aggregate_functions = ['median', 'mean', 'sum', 'max', 'min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for period, days in rolling_periods.items():\n",
    "    for function in aggregate_functions:\n",
    "        X_all_rows['rolling_{0}_{1}'.format(period, function)] = X_all_rows.groupby(['store_nbr', 'family'])['sales'].apply(lambda x: x.shift().rolling(days).agg({'sales': function}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = ['dcoilwtico', 'rolling_year_median', 'rolling_year_mean', 'rolling_year_sum', 'rolling_year_max', \n",
    "                     'rolling_6m_median', 'rolling_6m_mean', 'rolling_6m_sum', 'rolling_6m_max',\n",
    "                     'rolling_3m_median', 'rolling_3m_mean', 'rolling_3m_sum', 'rolling_3m_max', \n",
    "                     'rolling_1m_median', 'rolling_1m_mean', 'rolling_1m_sum', 'rolling_1m_max', \n",
    "                     'rolling_16d_median', 'rolling_16d_mean', 'rolling_16d_sum', 'rolling_16d_max', \n",
    "                     'rolling_10d_median', 'rolling_10d_mean', 'rolling_10d_sum', 'rolling_10d_max', \n",
    "                     'rolling_7d_median', 'rolling_7d_mean', 'rolling_7d_sum', 'rolling_7d_max',\n",
    "                     'rolling_5d_median', 'rolling_5d_mean', 'rolling_5d_sum', 'rolling_5d_max',\n",
    "                     'rolling_3d_median', 'rolling_3d_mean', 'rolling_3d_sum', 'rolling_3d_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X_all_rows[X_all_rows['date'].isin(test_dates)].reset_index(drop=True).drop(columns=['sales'])\n",
    "test_data = pd.get_dummies(test_data, columns=['store_nbr'], drop_first=True)\n",
    "X = X_all_rows[~X_all_rows['date'].isin(test_dates)].drop(columns=['sales'])\n",
    "X = pd.get_dummies(X, columns=['store_nbr'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ind = X[X.isna().any(axis=1)].index\n",
    "X = X.dropna()\n",
    "y = y.drop(index=nan_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = {}\n",
    "for current_family in X_train['family'].unique():\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "    for current_feature in features_to_scale:\n",
    "        current_scaler = MinMaxScaler()\n",
    "        X_train_current_family[[current_feature]] = current_scaler.fit_transform(X_train_current_family[[current_feature]])\n",
    "        \n",
    "    lss = Lasso(alpha=0.15).fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    model_select = SelectFromModel(lss, prefit=True)\n",
    "    best_features[current_family] = X_train_current_family.drop(columns=['date']).columns[model_select.get_support()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=365 * 33 * 54, n_splits=4, test_size=16 * 33 * 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3489b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "        X_train_current_family = X_train_current_family.drop(columns=[x for x in X_train_current_family.columns if x not in best_features[current_family]])\n",
    "            \n",
    "        all_scalers = {}\n",
    "        for current_feature in [x for x in features_to_scale if x in best_features[current_family]]:\n",
    "            current_scaler = MinMaxScaler()\n",
    "            X_train_current_family[[current_feature]] = current_scaler.fit_transform(X_train_current_family[[current_feature]])\n",
    "            all_scalers[current_feature] = current_scaler\n",
    "        \n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family, y_train_current_family)\n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family]\n",
    "        X_test_current_family = X_test_current_family.drop(columns=[x for x in X_test_current_family.columns \\\n",
    "                                                                    if x not in best_features[current_family] and x != 'date' and x != 'pred'])\n",
    "        for current_feature in [x for x in features_to_scale if x in best_features[current_family]]:\n",
    "            X_test_current_family[[current_feature]] = all_scalers[current_feature].transform(X_test_current_family[[current_feature]])\n",
    "\n",
    "        current_days_to_shift = [int(x[4:]) for x in best_features[current_family] if x[:3] == 'lag']\n",
    "        ends = [(16 - x) for x in current_days_to_shift]\n",
    "        ends.reverse()\n",
    "        \n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in current_days_to_shift:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in current_days_to_shift:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            current_days_to_shift = current_days_to_shift[:-1]\n",
    "            start = end\n",
    "\n",
    "            \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55731dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e049e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2682ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_family in X_train['family'].unique():\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family]\n",
    "    X_train_current_family = X_train_current_family.drop(columns=[x for x in X_train_current_family.columns \\\n",
    "                                                                  if x not in best_features[current_family]])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "                    \n",
    "    all_scalers = {}\n",
    "    for current_feature in [x for x in features_to_scale if x in best_features[current_family]]:\n",
    "        current_scaler = MinMaxScaler()\n",
    "        X_train_current_family[[current_feature]] = current_scaler.fit_transform(X_train_current_family[[current_feature]])\n",
    "        all_scalers[current_feature] = current_scaler\n",
    "        \n",
    "    model = PositiveRegressor(LinearRegression())\n",
    "    model.fit(X_train_current_family, y_train_current_family)    \n",
    "    \n",
    "    X_test_current_family = test_data[test_data['family'] == current_family]\n",
    "    X_test_current_family = X_test_current_family.drop(columns=[x for x in X_test_current_family.columns \\\n",
    "                                                                if x not in best_features[current_family] and x != 'date'])\n",
    "    for current_feature in [x for x in features_to_scale if x in best_features[current_family]]:\n",
    "        X_test_current_family[[current_feature]] = all_scalers[current_feature].transform(X_test_current_family[[current_feature]])\n",
    "    \n",
    "    current_days_to_shift = [int(x[4:]) for x in best_features[current_family] if x[:3] == 'lag']\n",
    "    ends = [(16 - x) for x in current_days_to_shift]\n",
    "    ends.reverse()\n",
    "        \n",
    "    start = 0\n",
    "    current_day_index = 0\n",
    "    for end in ends:\n",
    "        for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "            current_day_plus_x = {}\n",
    "            for current_lag in current_days_to_shift:\n",
    "                current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date'])\n",
    "            predictions = model.predict(X_test_for_current_day)\n",
    "            \n",
    "            for current_lag in current_days_to_shift:\n",
    "                X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                \n",
    "            current_day_index += 1\n",
    "                \n",
    "        current_days_to_shift = current_days_to_shift[:-1]\n",
    "        start = end\n",
    "            \n",
    "        \n",
    "    y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date']))\n",
    "    \n",
    "    test_indices = test_data[test_data['family'] == current_family].index\n",
    "    submission.loc[test_indices, 'sales'] = y_pred_current_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc83e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/linreg_best_features_l1_fs.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68073ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadccb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
