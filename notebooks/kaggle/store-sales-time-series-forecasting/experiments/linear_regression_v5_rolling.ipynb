{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b25974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.environ['PROJECT_ROOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0669a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\mentorship_EPAM\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pdpipe as pdp\n",
    "import statsmodels.api as sm\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, MetaEstimatorMixin, TransformerMixin, clone\n",
    "from datetime import timedelta\n",
    "from statistics import median, mean, stdev\n",
    "from pdpipe import df\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression, mutual_info_regression, RFE\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from mentorship.ml.models.reg import PositiveRegressor\n",
    "from mentorship.ml.models.common import SplitPipeline\n",
    "from mentorship.ml.models.kaggle.storesales.linear import PipelineLinearV1\n",
    "from mentorship.ml.models.kaggle.storesales.ridge import PipelineRidgeV1\n",
    "from mentorship.ml.models.kaggle.storesales.lasso import PipelineLassoV1\n",
    "from mentorship.ml.models.kaggle.storesales.elasticnet import PipelineElasticNetV1\n",
    "from mentorship.features.kaggle.storesales.etl import ETLTransformer\n",
    "from mentorship.ml.cv.split import DateTimeSeriesSplit\n",
    "from mentorship.ml.cv.util import print_cv_test_scores\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c94636",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_METRICS = [\n",
    "    'neg_mean_squared_log_error',\n",
    "    'neg_root_mean_squared_error',\n",
    "    'neg_mean_absolute_error',\n",
    "    # 'neg_mean_absolute_percentage_error',\n",
    "    'r2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebbddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('data', 'kaggle', 'store-sales-time-series-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd374d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866a56e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STORES = train['store_nbr'].nunique()\n",
    "N_FAMILIES = train['family'].nunique()\n",
    "N_TIME_SERIES = N_STORES * N_FAMILIES\n",
    "\n",
    "DAYS_IN_YEAR = 365\n",
    "N_HORIZONS = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb620e",
   "metadata": {},
   "source": [
    " # 1. Linear Regression, features: 'store_nbr', 'dcoilwtico', 'lags' for target (1, 2, 4, 6, 7, 14 days shift) (recursive strategy), 'rolling' features (SelectFromModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20d84056",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2d58116",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 4, 6, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af29b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_dates = test_data['date'].unique()\n",
    "\n",
    "X_all_rows = pd.concat([X, test_data])\n",
    "X_all_rows = X_all_rows.reset_index().drop(columns=['index'])\n",
    "X_all_rows = X_all_rows.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "781949f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_periods = [365, 183, 92, 31, 16, 10, 7, 5, 3]\n",
    "aggregate_functions = ['median', 'mean', 'sum', 'max', 'min', 'std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1db18957",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_rows['lag_1'] = X_all_rows.groupby(['store_nbr', 'family'])['sales'].shift()\n",
    "for rolling_days in rolling_periods:\n",
    "    cols = [f'sales_rolling_{rolling_days}d_{agg}' for agg in aggregate_functions]\n",
    "    X_all_rows[cols] = X_all_rows.groupby(['store_nbr', 'family'])['lag_1'].rolling(rolling_days).agg(aggregate_functions).reset_index([0, 1], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a032d78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>sales_rolling_3d_median</th>\n",
       "      <th>sales_rolling_3d_mean</th>\n",
       "      <th>sales_rolling_3d_sum</th>\n",
       "      <th>sales_rolling_3d_max</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_rolling_183d_sum</th>\n",
       "      <th>sales_rolling_183d_max</th>\n",
       "      <th>sales_rolling_183d_min</th>\n",
       "      <th>sales_rolling_183d_std</th>\n",
       "      <th>sales_rolling_365d_median</th>\n",
       "      <th>sales_rolling_365d_mean</th>\n",
       "      <th>sales_rolling_365d_sum</th>\n",
       "      <th>sales_rolling_365d_max</th>\n",
       "      <th>sales_rolling_365d_min</th>\n",
       "      <th>sales_rolling_365d_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>automotive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>baby care</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>beverages</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>books</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029395</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>poultry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.343281e-12</td>\n",
       "      <td>1.602984e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74573.600930</td>\n",
       "      <td>857.480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.301057</td>\n",
       "      <td>423.294</td>\n",
       "      <td>443.502353</td>\n",
       "      <td>161878.359010</td>\n",
       "      <td>2198.853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.506387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029396</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>prepared foods</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.286438e-12</td>\n",
       "      <td>1.585931e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20754.545002</td>\n",
       "      <td>311.147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.555923</td>\n",
       "      <td>113.978</td>\n",
       "      <td>115.765726</td>\n",
       "      <td>42254.489993</td>\n",
       "      <td>311.147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.048422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029397</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>produce</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.063298e-12</td>\n",
       "      <td>1.818989e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>280142.216800</td>\n",
       "      <td>2861.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>649.904719</td>\n",
       "      <td>1524.197</td>\n",
       "      <td>1622.782758</td>\n",
       "      <td>592315.706600</td>\n",
       "      <td>4059.907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>623.674176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029398</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>school and office supplies</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.063298e-12</td>\n",
       "      <td>1.818989e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2947.000000</td>\n",
       "      <td>203.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.542740</td>\n",
       "      <td>2.000</td>\n",
       "      <td>12.890411</td>\n",
       "      <td>4705.000000</td>\n",
       "      <td>326.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.463839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029399</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>seafood</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.063298e-12</td>\n",
       "      <td>1.818989e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3173.650002</td>\n",
       "      <td>54.162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.919732</td>\n",
       "      <td>15.000</td>\n",
       "      <td>16.475238</td>\n",
       "      <td>6013.461999</td>\n",
       "      <td>54.162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.518278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3029400 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr                      family  sales  dcoilwtico  \\\n",
       "0        2013-01-01          1                  automotive    0.0        0.00   \n",
       "1        2013-01-01          1                   baby care    0.0        0.00   \n",
       "2        2013-01-01          1                      beauty    0.0        0.00   \n",
       "3        2013-01-01          1                   beverages    0.0        0.00   \n",
       "4        2013-01-01          1                       books    0.0        0.00   \n",
       "...             ...        ...                         ...    ...         ...   \n",
       "3029395  2017-08-31          9                     poultry    0.0       47.26   \n",
       "3029396  2017-08-31          9              prepared foods    0.0       47.26   \n",
       "3029397  2017-08-31          9                     produce    0.0       47.26   \n",
       "3029398  2017-08-31          9  school and office supplies    0.0       47.26   \n",
       "3029399  2017-08-31          9                     seafood    0.0       47.26   \n",
       "\n",
       "         lag_1  sales_rolling_3d_median  sales_rolling_3d_mean  \\\n",
       "0          NaN                      NaN                    NaN   \n",
       "1          NaN                      NaN                    NaN   \n",
       "2          NaN                      NaN                    NaN   \n",
       "3          NaN                      NaN                    NaN   \n",
       "4          NaN                      NaN                    NaN   \n",
       "...        ...                      ...                    ...   \n",
       "3029395    0.0                      0.0           5.343281e-12   \n",
       "3029396    0.0                      0.0           5.286438e-12   \n",
       "3029397    0.0                      0.0           6.063298e-12   \n",
       "3029398    0.0                      0.0           6.063298e-12   \n",
       "3029399    0.0                      0.0           6.063298e-12   \n",
       "\n",
       "         sales_rolling_3d_sum  sales_rolling_3d_max  ...  \\\n",
       "0                         NaN                   NaN  ...   \n",
       "1                         NaN                   NaN  ...   \n",
       "2                         NaN                   NaN  ...   \n",
       "3                         NaN                   NaN  ...   \n",
       "4                         NaN                   NaN  ...   \n",
       "...                       ...                   ...  ...   \n",
       "3029395          1.602984e-11                   0.0  ...   \n",
       "3029396          1.585931e-11                   0.0  ...   \n",
       "3029397          1.818989e-11                   0.0  ...   \n",
       "3029398          1.818989e-11                   0.0  ...   \n",
       "3029399          1.818989e-11                   0.0  ...   \n",
       "\n",
       "         sales_rolling_183d_sum  sales_rolling_183d_max  \\\n",
       "0                           NaN                     NaN   \n",
       "1                           NaN                     NaN   \n",
       "2                           NaN                     NaN   \n",
       "3                           NaN                     NaN   \n",
       "4                           NaN                     NaN   \n",
       "...                         ...                     ...   \n",
       "3029395            74573.600930                 857.480   \n",
       "3029396            20754.545002                 311.147   \n",
       "3029397           280142.216800                2861.572   \n",
       "3029398             2947.000000                 203.000   \n",
       "3029399             3173.650002                  54.162   \n",
       "\n",
       "         sales_rolling_183d_min  sales_rolling_183d_std  \\\n",
       "0                           NaN                     NaN   \n",
       "1                           NaN                     NaN   \n",
       "2                           NaN                     NaN   \n",
       "3                           NaN                     NaN   \n",
       "4                           NaN                     NaN   \n",
       "...                         ...                     ...   \n",
       "3029395                     0.0              179.301057   \n",
       "3029396                     0.0               49.555923   \n",
       "3029397                     0.0              649.904719   \n",
       "3029398                     0.0               42.542740   \n",
       "3029399                     0.0                9.919732   \n",
       "\n",
       "         sales_rolling_365d_median  sales_rolling_365d_mean  \\\n",
       "0                              NaN                      NaN   \n",
       "1                              NaN                      NaN   \n",
       "2                              NaN                      NaN   \n",
       "3                              NaN                      NaN   \n",
       "4                              NaN                      NaN   \n",
       "...                            ...                      ...   \n",
       "3029395                    423.294               443.502353   \n",
       "3029396                    113.978               115.765726   \n",
       "3029397                   1524.197              1622.782758   \n",
       "3029398                      2.000                12.890411   \n",
       "3029399                     15.000                16.475238   \n",
       "\n",
       "         sales_rolling_365d_sum  sales_rolling_365d_max  \\\n",
       "0                           NaN                     NaN   \n",
       "1                           NaN                     NaN   \n",
       "2                           NaN                     NaN   \n",
       "3                           NaN                     NaN   \n",
       "4                           NaN                     NaN   \n",
       "...                         ...                     ...   \n",
       "3029395           161878.359010                2198.853   \n",
       "3029396            42254.489993                 311.147   \n",
       "3029397           592315.706600                4059.907   \n",
       "3029398             4705.000000                 326.000   \n",
       "3029399             6013.461999                  54.162   \n",
       "\n",
       "         sales_rolling_365d_min  sales_rolling_365d_std  \n",
       "0                           NaN                     NaN  \n",
       "1                           NaN                     NaN  \n",
       "2                           NaN                     NaN  \n",
       "3                           NaN                     NaN  \n",
       "4                           NaN                     NaN  \n",
       "...                         ...                     ...  \n",
       "3029395                     0.0              195.506387  \n",
       "3029396                     0.0               43.048422  \n",
       "3029397                     0.0              623.674176  \n",
       "3029398                     0.0               39.463839  \n",
       "3029399                     0.0                9.518278  \n",
       "\n",
       "[3029400 rows x 60 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8a3a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_lag in days_to_shift[1:]:\n",
    "    X_all_rows.loc[:, 'lag_{}'.format(current_lag)] = X_all_rows.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90cfa0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = [x for x in X_all_rows.columns if 'rolling' in x or x == 'dcoilwtico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50aa76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94acb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X_all_rows[X_all_rows['date'].isin(test_dates)].reset_index(drop=True).drop(columns=['sales'])\n",
    "test_data = pd.get_dummies(test_data, columns=['store_nbr'], drop_first=True)\n",
    "X = X_all_rows[~X_all_rows['date'].isin(test_dates)].drop(columns=['sales'])\n",
    "X = pd.get_dummies(X, columns=['store_nbr'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c7e36a4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "automotive\n",
      "baby care\n",
      "beauty\n",
      "beverages\n",
      "books\n",
      "bread/bakery\n",
      "celebration\n",
      "cleaning\n",
      "dairy\n",
      "deli\n",
      "eggs\n",
      "frozen foods\n",
      "grocery i\n",
      "grocery ii\n",
      "hardware\n",
      "home and kitchen i\n",
      "home and kitchen ii\n",
      "home appliances\n",
      "home care\n",
      "ladieswear\n",
      "lawn and garden\n",
      "lingerie\n",
      "liquor,wine,beer\n",
      "magazines\n",
      "meats\n",
      "personal care\n",
      "pet supplies\n",
      "players and electronics\n",
      "poultry\n",
      "prepared foods\n",
      "produce\n",
      "school and office supplies\n",
      "seafood\n"
     ]
    }
   ],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]\n",
    "\n",
    "best_features = {}\n",
    "for current_family in X_train['family'].unique():\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_current_family[features_to_scale] = scaler.fit_transform(X_train_current_family[features_to_scale])\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    \n",
    "    importance = np.abs(model.coef_)\n",
    "    threshold = np.sort(importance)[-2] + 0.01\n",
    "    sfm = SelectFromModel(model, threshold=threshold).fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    best_features[current_family] = X_train_current_family.drop(columns=['date']).columns[sfm.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ends = [(16 - x) for x in days_to_shift]\n",
    "ends.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dfe825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        print(current_family)\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        columns_to_drop = [x for x in features_to_scale if x not in best_features[current_family]]\n",
    "        columns_to_drop.append('family')\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        current_features_to_scale = [x for x in features_to_scale if x in best_features[current_family]]\n",
    "        X_train_current_family[current_features_to_scale] = scaler.fit_transform(X_train_current_family[current_features_to_scale])\n",
    "        \n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        X_test_current_family[current_features_to_scale] = scaler.transform(X_test_current_family[current_features_to_scale])\n",
    "        \n",
    "        days_to_shift_copy = days_to_shift.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            days_to_shift_copy = days_to_shift_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "            \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f32a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2adc3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a61542",
   "metadata": {},
   "source": [
    "# 2. Linear Regression, features: 'store_nbr', 'dcoilwtico', 'lags' for target (1, 2, 4, 6, 7, 14 days shift) (recursive strategy), 'rolling' features (SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d620221",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 4, 6, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3466db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_dates = test_data['date'].unique()\n",
    "\n",
    "X_all_rows = pd.concat([X, test_data])\n",
    "X_all_rows = X_all_rows.reset_index().drop(columns=['index'])\n",
    "X_all_rows = X_all_rows.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf18ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_periods = [365, 183, 92, 31, 16, 10, 7, 5, 3]\n",
    "aggregate_functions = ['median', 'mean', 'sum', 'max', 'min', 'std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_rows['lag_1'] = X_all_rows.groupby(['store_nbr', 'family'])['sales'].shift()\n",
    "for rolling_days in rolling_periods:\n",
    "    cols = [f'sales_rolling_{rolling_days}d_{agg}' for agg in aggregate_functions]\n",
    "    X_all_rows[cols] = X_all_rows.groupby(['store_nbr', 'family'])['lag_1'].rolling(rolling_days).agg(aggregate_functions).reset_index([0, 1], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff95341",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_lag in days_to_shift[1:]:\n",
    "    X_all_rows.loc[:, 'lag_{}'.format(current_lag)] = X_all_rows.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb59413",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = [x for x in X_all_rows.columns if 'rolling' in x or x == 'dcoilwtico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc634d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16423d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X_all_rows[X_all_rows['date'].isin(test_dates)].reset_index(drop=True).drop(columns=['sales'])\n",
    "test_data = pd.get_dummies(test_data, columns=['store_nbr'], drop_first=True)\n",
    "X = X_all_rows[~X_all_rows['date'].isin(test_dates)].drop(columns=['sales'])\n",
    "X = pd.get_dummies(X, columns=['store_nbr'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a221ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca682e62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_features = {}\n",
    "for current_family in X_train['family'].unique():\n",
    "    print(current_family)\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_current_family[features_to_scale] = scaler.fit_transform(X_train_current_family[features_to_scale])\n",
    "    \n",
    "    selector = SelectKBest(mutual_info_regression, k=10)\n",
    "    selector.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    best_features[current_family] = selector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75720a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebe925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        columns_to_drop = [x for x in features_to_scale if x not in best_features[current_family]]\n",
    "        columns_to_drop.append('family')\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        current_features_to_scale = [x for x in features_to_scale if x in best_features[current_family]]\n",
    "        X_train_current_family[current_features_to_scale] = scaler.fit_transform(X_train_current_family[current_features_to_scale])\n",
    "        \n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=columns_to_drop)\n",
    "        X_test_current_family[current_features_to_scale] = scaler.transform(X_test_current_family[current_features_to_scale])\n",
    "        \n",
    "        days_to_shift_copy = days_to_shift.copy()\n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in days_to_shift_copy:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            days_to_shift_copy = days_to_shift_copy[:-1]\n",
    "            start = end\n",
    "\n",
    "            \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a445a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24773b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "966fb909",
   "metadata": {},
   "source": [
    "# 3. Linear Regression, features: 'store_nbr', 'dcoilwtico', 'lags' for target (1, 2, 4, 6, 7, 14 days shift) (recursive strategy), 'rolling' features (L1-based selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19946f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_shift = [1, 2, 4, 6, 7, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_dates = test_data['date'].unique()\n",
    "\n",
    "X_all_rows = pd.concat([X, test_data])\n",
    "X_all_rows = X_all_rows.reset_index().drop(columns=['index'])\n",
    "X_all_rows = X_all_rows.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_periods = [365, 183, 92, 31, 16, 10, 7, 5, 3]\n",
    "aggregate_functions = ['median', 'mean', 'sum', 'max', 'min', 'std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_rows['lag_1'] = X_all_rows.groupby(['store_nbr', 'family'])['sales'].shift()\n",
    "for rolling_days in rolling_periods:\n",
    "    cols = [f'sales_rolling_{rolling_days}d_{agg}' for agg in aggregate_functions]\n",
    "    X_all_rows[cols] = X_all_rows.groupby(['store_nbr', 'family'])['lag_1'].rolling(rolling_days).agg(aggregate_functions).reset_index([0, 1], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c783c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_lag in days_to_shift[1:]:\n",
    "    X_all_rows.loc[:, 'lag_{}'.format(current_lag)] = X_all_rows.groupby(['store_nbr', 'family'])['sales'].shift(current_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = [x for x in X_all_rows.columns if 'rolling' in x or x == 'dcoilwtico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X_all_rows[X_all_rows['date'].isin(test_dates)].reset_index(drop=True).drop(columns=['sales'])\n",
    "test_data = pd.get_dummies(test_data, columns=['store_nbr'], drop_first=True)\n",
    "X = X_all_rows[~X_all_rows['date'].isin(test_dates)].drop(columns=['sales'])\n",
    "X = pd.get_dummies(X, columns=['store_nbr'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b5e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ind = X[X.isna().any(axis=1)].index\n",
    "X = X.dropna()\n",
    "y = y.drop(index=nan_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9977b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = {}\n",
    "for current_family in X_train['family'].unique():\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "      \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_current_family[features_to_scale] = scaler.fit_transform(X_train_current_family[features_to_scale])\n",
    "        \n",
    "    lss = Lasso(alpha=0.15).fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    model_select = SelectFromModel(lss, prefit=True)\n",
    "    best_features[current_family] = X_train_current_family.drop(columns=['date']).columns[model_select.get_support()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_TIME_SERIES, n_splits=4, test_size=N_HORIZONS * N_TIME_SERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3489b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in X['family'].unique():\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        \n",
    "        X_train_current_family = X_train_current_family.drop(columns=[x for x in X_train_current_family.columns if x not in best_features[current_family]])\n",
    "            \n",
    "        scaler = MinMaxScaler()\n",
    "        current_features_to_scale = [x for x in features_to_scale if x in best_features[current_family]]\n",
    "        X_train_current_family[current_features_to_scale] = scaler.fit_transform(X_train_current_family[current_features_to_scale])\n",
    "        \n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family, y_train_current_family)\n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family]\n",
    "        X_test_current_family = X_test_current_family.drop(columns=[x for x in X_test_current_family.columns \\\n",
    "                                                                    if x not in best_features[current_family] and x != 'date' and x != 'pred'])\n",
    "        X_test_current_family[current_features_to_scale] = scaler.transform(X_test_current_family[current_features_to_scale])\n",
    "\n",
    "\n",
    "        current_days_to_shift = [int(x[4:]) for x in best_features[current_family] if x[:3] == 'lag']\n",
    "        ends = [(16 - x) for x in current_days_to_shift]\n",
    "        ends.reverse()\n",
    "        \n",
    "        start = 0\n",
    "        current_day_index = 0\n",
    "        for end in ends:\n",
    "            for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "                current_day_plus_x = {}\n",
    "                for current_lag in current_days_to_shift:\n",
    "                    current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "                X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date', 'pred'])\n",
    "                predictions = model.predict(X_test_for_current_day)\n",
    "                \n",
    "                for current_lag in current_days_to_shift:\n",
    "                    X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                    \n",
    "                current_day_index += 1\n",
    "                \n",
    "            current_days_to_shift = current_days_to_shift[:-1]\n",
    "            start = end\n",
    "\n",
    "            \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "        \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    \n",
    "    scores['RMSLE'].append(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "\n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {mean(metric_values):.3f} ± {stdev(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55731dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e049e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2682ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_family in X_train['family'].unique():\n",
    "    current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "    X_train_current_family = X_train[X_train['family'] == current_family]\n",
    "    X_train_current_family = X_train_current_family.drop(columns=[x for x in X_train_current_family.columns \\\n",
    "                                                                  if x not in best_features[current_family]])\n",
    "    y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "                    \n",
    "    scaler = MinMaxScaler()\n",
    "    current_features_to_scale = [x for x in features_to_scale if x in best_features[current_family]]\n",
    "    X_train_current_family[current_features_to_scale] = scaler.fit_transform(X_train_current_family[current_features_to_scale])\n",
    "        \n",
    "    model = PositiveRegressor(LinearRegression())\n",
    "    model.fit(X_train_current_family, y_train_current_family)    \n",
    "    \n",
    "    X_test_current_family = test_data[test_data['family'] == current_family]\n",
    "    X_test_current_family = X_test_current_family.drop(columns=[x for x in X_test_current_family.columns \\\n",
    "                                                                if x not in best_features[current_family] and x != 'date'])\n",
    "    X_test_current_family[current_features_to_scale] = scaler.transform(X_test_current_family[current_features_to_scale])\n",
    "\n",
    "    \n",
    "    current_days_to_shift = [int(x[4:]) for x in best_features[current_family] if x[:3] == 'lag']\n",
    "    ends = [(16 - x) for x in current_days_to_shift]\n",
    "    ends.reverse()\n",
    "        \n",
    "    start = 0\n",
    "    current_day_index = 0\n",
    "    for end in ends:\n",
    "        for current_day in X_test_current_family['date'].unique()[start:end]:\n",
    "            current_day_plus_x = {}\n",
    "            for current_lag in current_days_to_shift:\n",
    "                current_day_plus_x[current_lag] = X_test_current_family['date'].unique()[current_day_index + current_lag]\n",
    "                \n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == current_day].drop(columns=['date'])\n",
    "            predictions = model.predict(X_test_for_current_day)\n",
    "            \n",
    "            for current_lag in current_days_to_shift:\n",
    "                X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day_plus_x[current_lag]].index, 'lag_{}'.format(current_lag)] = predictions\n",
    "                \n",
    "            current_day_index += 1\n",
    "                \n",
    "        current_days_to_shift = current_days_to_shift[:-1]\n",
    "        start = end\n",
    "            \n",
    "        \n",
    "    y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date']))\n",
    "    \n",
    "    test_indices = test_data[test_data['family'] == current_family].index\n",
    "    submission.loc[test_indices, 'sales'] = y_pred_current_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc83e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/linreg_best_features_l1_fs.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68073ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadccb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
