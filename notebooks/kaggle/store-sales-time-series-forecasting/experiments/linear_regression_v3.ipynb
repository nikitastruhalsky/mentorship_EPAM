{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.environ['PROJECT_ROOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pdpipe as pdp\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, MetaEstimatorMixin, TransformerMixin, clone\n",
    "from datetime import timedelta\n",
    "from statistics import median, mean\n",
    "from pdpipe import df\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from mentorship.ml.models.reg import PositiveRegressor\n",
    "from mentorship.ml.models.common import SplitPipeline\n",
    "from mentorship.ml.models.kaggle.storesales.linear import PipelineLinearV1\n",
    "from mentorship.ml.models.kaggle.storesales.ridge import PipelineRidgeV1\n",
    "from mentorship.ml.models.kaggle.storesales.lasso import PipelineLassoV1\n",
    "from mentorship.ml.models.kaggle.storesales.elasticnet import PipelineElasticNetV1\n",
    "from mentorship.features.kaggle.storesales.etl import ETLTransformer\n",
    "from mentorship.ml.cv.split import DateTimeSeriesSplit\n",
    "from mentorship.ml.cv.util import print_cv_test_scores\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_METRICS = [\n",
    "    'neg_mean_squared_log_error',\n",
    "    'neg_root_mean_squared_error',\n",
    "    'neg_mean_absolute_error',\n",
    "    # 'neg_mean_absolute_percentage_error',\n",
    "    'r2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpipe.skintegrate import PdPipelineAndSklearnEstimator\n",
    "\n",
    "class PipelineLinearV2(PdPipelineAndSklearnEstimator):\n",
    "    def __init__(self, num_columns, cat_columns, date_column='date'):\n",
    "        self.num_columns = num_columns\n",
    "        self.cat_columns = cat_columns\n",
    "        self.date_column = date_column\n",
    "        pipeline = pdp.PdPipeline([\n",
    "            pdp.Scale('MinMaxScaler', self.num_columns),\n",
    "            pdp.OneHotEncode(self.cat_columns),\n",
    "            pdp.ColDrop([self.date_column, 'store_nbr']),\n",
    "        ])\n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        super().__init__(pipeline=pipeline, estimator=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "class SplitPipelineV2:\n",
    "    def __init__(self, base_pipeline):\n",
    "        self.base_pipeline = base_pipeline\n",
    "        self.pipelines_ = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for current_store_nbr in X['store_nbr'].unique():\n",
    "            indexer = X[X['store_nbr'] == current_store_nbr].index\n",
    "            X_part = X[X['store_nbr'] == current_store_nbr]\n",
    "            y_part = y.loc[indexer]\n",
    "\n",
    "            pipeline = clone(self.base_pipeline)\n",
    "            pipeline = pipeline.fit(X_part, y_part)\n",
    "\n",
    "            self.pipelines_[current_store_nbr] = pipeline\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X.loc[:, 'forecast'] = 0\n",
    "        for current_store_nbr in X['store_nbr'].unique():\n",
    "            X_part = X[X['store_nbr'] == current_store_nbr]\n",
    "            X_part = X_part.drop('forecast', axis=1)\n",
    "            pipeline = self.pipelines_[current_store_nbr]\n",
    "            X.loc[X_part.index, 'forecast'] = pipeline.predict(X_part)\n",
    "\n",
    "        y_pred = X['forecast']\n",
    "        X = X.drop(columns='forecast')\n",
    "        return y_pred\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'base_pipeline': self.base_pipeline}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e55288",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('data', 'kaggle', 'store-sales-time-series-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880914e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "dates_test_data = test_data['date'].unique()\n",
    "all_data = pd.concat([X, test_data])\n",
    "all_data['lag_16'] = all_data.groupby(['store_nbr', 'family'])['sales'].shift(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['lag_16'] = all_data[all_data['date'].isin(dates_test_data)]['lag_16']\n",
    "X['lag_16'] = X.groupby(['store_nbr', 'family'])['sales'].shift(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4925ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62f1444",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')\n",
    "inds = X.loc[pd.isna(X['dcoilwtico']), :].index\n",
    "X = X[X['dcoilwtico'].notna()]\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.drop(labels=inds)\n",
    "y = y.reset_index(drop=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV2(num_columns=['dcoilwtico'], cat_columns=['family'])\n",
    "modelling_pipeline = SplitPipelineV2(base_pipeline=base_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8001c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361c081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f11958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7b421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4bb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae8128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
