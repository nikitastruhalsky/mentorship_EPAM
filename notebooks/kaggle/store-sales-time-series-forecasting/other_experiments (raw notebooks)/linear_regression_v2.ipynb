{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bebccd",
   "metadata": {},
   "source": [
    "# Experiments with linear models for each family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c43db42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:57:17.369023Z",
     "start_time": "2022-08-22T08:57:17.357953Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.environ['PROJECT_ROOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2443dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:57:18.680600Z",
     "start_time": "2022-08-22T08:57:17.625106Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pdpipe as pdp\n",
    "import collections\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, MetaEstimatorMixin, TransformerMixin, clone\n",
    "from datetime import timedelta\n",
    "from pdpipe import df\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, TimeSeriesSplit, GridSearchCV, cross_val_predict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from mentorship.ml.models.reg import PositiveRegressor\n",
    "from mentorship.ml.models.common import RecursiveTSEstimator\n",
    "from mentorship.ml.models.kaggle.storesales.linear import LinearPipeline\n",
    "from mentorship.features.kaggle.storesales.etl import ETLTransformer\n",
    "from mentorship.features.history import cut_history\n",
    "from mentorship.ml.cv.split import DateTimeSeriesSplit\n",
    "from mentorship.ml.cv.util import format_cv_test_scores\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18239ede",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:57:23.324283Z",
     "start_time": "2022-08-22T08:57:23.310607Z"
    }
   },
   "outputs": [],
   "source": [
    "CV_METRICS = [\n",
    "    'neg_mean_squared_log_error',\n",
    "    'neg_root_mean_squared_error',\n",
    "    'neg_mean_absolute_error',\n",
    "    # 'neg_mean_absolute_percentage_error',\n",
    "    'r2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b45e993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:57:18.759894Z",
     "start_time": "2022-08-22T08:57:18.745879Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('data', 'kaggle', 'store-sales-time-series-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79e6093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:57:21.157579Z",
     "start_time": "2022-08-22T08:57:18.761878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab267208",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STORES = train['store_nbr'].nunique()\n",
    "N_FAMILIES = train['family'].nunique()\n",
    "N_TIME_SERIES = N_STORES * N_FAMILIES\n",
    "\n",
    "DAYS_IN_YEAR = 365\n",
    "N_HORIZONS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6df19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission_file(test_data, model, output_path):\n",
    "    submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "    submission['sales'] = model.predict(test_data)\n",
    "    submission.to_csv(DATA_ROOT / output_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "713dd61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_cross_val_predict(modelling_pipeline, X, y, cv):\n",
    "    # return a dictionary: fold number -> 1-d pd.Series of fold\n",
    "    # predictions with index corresponding to X and y index\n",
    "    predictions = {}\n",
    "    fold_number = 1\n",
    "    for train_indices, test_indices in cv.split(X, y):\n",
    "        X_train = X.iloc[train_indices]\n",
    "        y_train = y.iloc[train_indices]\n",
    "        X_test = X.iloc[test_indices]\n",
    "        y_test = y.iloc[test_indices]\n",
    "\n",
    "        modelling_pipeline.fit(X_train, y_train)\n",
    "        current_fold_preds = modelling_pipeline.predict(X_test)\n",
    "        predictions[fold_number] = current_fold_preds\n",
    "        fold_number += 1\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e6f86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_for_each_horizon(modelling_pipeline, X, y, splitter, date_column='date'):\n",
    "    keys = np.arange(1, 17)\n",
    "    cv_scores = {key : [] for key in keys}\n",
    "    for train_indices, test_indices in splitter.split(X, y):\n",
    "        X_train = X.iloc[train_indices]\n",
    "        y_train = y.iloc[train_indices]\n",
    "        X_test = X.iloc[test_indices]\n",
    "        y_test = y.iloc[test_indices]\n",
    "\n",
    "        modelling_pipeline = modelling_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        for day_index, current_day in enumerate(X_test[date_column].unique()):\n",
    "            X_test_current_day = X_test[X_test[date_column] == current_day]\n",
    "            y_test_current_day = y_test.loc[X_test_current_day.index]\n",
    "        \n",
    "            y_pred = modelling_pipeline.predict(X_test_current_day)\n",
    "            cv_scores[day_index + 1].append(mean_squared_log_error(y_test_current_day, y_pred, squared=False))\n",
    "            \n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5880817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(estimator, X, y, base_pipeline, hyper_params_grid, tscv_inner, tscv_outer, split_key):\n",
    "    scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "    for train_indices, test_indices in tscv_outer.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "        X_test, y_test = X.iloc[test_indices], y.iloc[test_indices]\n",
    "    \n",
    "        X_test.loc[:, 'pred'] = 0\n",
    "        for current_split_key_value in X[split_key].unique():\n",
    "            X_train_current_split_key_value = X_train[X_train[split_key] == current_split_key_value].drop(columns=split_key)\n",
    "            y_train_current_split_key_value = y_train.loc[X_train_current_split_key_value.index]\n",
    "            X_test_current_split_key_value = X_test[X_test[split_key] == current_split_key_value].drop(columns=split_key)\n",
    "        \n",
    "            X_train_current_split_key_value = base_pipeline.pipeline(X_train_current_split_key_value)\n",
    "    \n",
    "            params_tuning_model = GridSearchCV(estimator=estimator, param_grid=hyper_params_grid, \\\n",
    "                                               scoring='neg_mean_squared_log_error', cv=tscv_inner)\n",
    "            params_tuning_model.fit(X_train_current_split_key_value, y_train_current_split_key_value)\n",
    "        \n",
    "            model = PositiveRegressor(estimator(**params_tuning_model.best_params_)) \\\n",
    "                                        .fit(X_train_current_split_key_value, y_train_current_split_key_value)\n",
    "        \n",
    "            X_test_current_split_key_value = base_pipeline.pipeline(X_test_current_split_key_value)\n",
    "            X_test.loc[X_test_current_split_key_value.index, 'pred'] = model.predict(X_test_current_split_key_value.drop(columns=['pred']))\n",
    "        \n",
    "        y_pred = X_test['pred'].copy()\n",
    "        scores['RMSLE'].append(mean_squared_log_error(y_test, y_pred, squared=False))\n",
    "        scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "        scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "        scores['R2'].append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ccd6e",
   "metadata": {},
   "source": [
    "# 0. Linear regression (one for all families) with 'store_nbr' and 'dcoilwtico' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89749884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a72eeab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns=['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "355f508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['dcoilwtico']\n",
    "cols_to_encode = ['store_nbr', 'family']\n",
    "drop_columns = ['onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0fb9a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4bef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in splitter.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    current_pipeline = LinearPipeline(split_key='family', target_col='sales', cols_to_scale=cols_to_scale, \n",
    "                                      cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "    X_train = current_pipeline.pipeline(X_train)\n",
    "    \n",
    "    model = PositiveRegressor(LinearRegression())\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    X_test = current_pipeline.pipeline(X_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    scores['RMSLE'].append(mean_squared_log_error(y_test, y_pred, squared=False))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b70f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores['RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f5496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "289dfb35",
   "metadata": {},
   "source": [
    "# 1. Linear regression with 'store_nbr', 'dcoilwtico' and 'onpromotion' feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2bb0a",
   "metadata": {},
   "source": [
    "<p><b>Preparing train data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9d936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:57:22.645854Z",
     "start_time": "2022-08-22T08:57:21.252403Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344f0a5",
   "metadata": {},
   "source": [
    "<p><b>Cross-validation process</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = 'family'\n",
    "cols_to_scale = ['dcoilwtico', 'onpromotion']\n",
    "cols_to_encode = ['store_nbr']\n",
    "drop_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56162014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:57:23.293329Z",
     "start_time": "2022-08-22T08:57:23.279327Z"
    }
   },
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77126971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:57:23.402482Z",
     "start_time": "2022-08-22T08:57:23.390298Z"
    }
   },
   "outputs": [],
   "source": [
    "base_pipeline = PipelineLinearV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline, split_key=split_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds = ts_cross_val_predict(modelling_pipeline, X, y, cv=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1229c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)\n",
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = scores_for_each_horizon(modelling_pipeline, X, y, splitter=splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e332c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSLE for every day in the test set\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "x = list(cv_scores.keys())\n",
    "y = [np.mean(cv_scores[key]) for key in x]\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69336084",
   "metadata": {},
   "source": [
    "<p><b>Test data preparing</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948567d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:59:41.096063Z",
     "start_time": "2022-08-22T08:59:41.064704Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866fc033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:59:41.793519Z",
     "start_time": "2022-08-22T08:59:41.770513Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = test_transformer.transform(test_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5dfe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:59:42.355008Z",
     "start_time": "2022-08-22T08:59:42.344877Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307946f9",
   "metadata": {},
   "source": [
    "<p><b>Training models and saving predictions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7744c71b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T08:59:45.870812Z",
     "start_time": "2022-08-22T08:59:45.859072Z"
    }
   },
   "outputs": [],
   "source": [
    "base_pipeline = PipelineLinearV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53af0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=365), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c7e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:00:02.934137Z",
     "start_time": "2022-08-22T08:59:48.013922Z"
    }
   },
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission_file(test_data, model=modelling_pipeline, output_path='linreg_dcoilwtico_promo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e4727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308575b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94583b37",
   "metadata": {},
   "source": [
    "# 2. Linear regression with 'store_nbr' and 'time-step' feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ce896",
   "metadata": {},
   "source": [
    "<p><b>Train data preparing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0383f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad4217",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]\n",
    "X = train_transformer.adding_time_step(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbaed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = 'family'\n",
    "cols_to_scale = []\n",
    "cols_to_encode = ['store_nbr']\n",
    "drop_columns = ['dcoilwtico', 'onpromotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23fd55",
   "metadata": {},
   "source": [
    "<p><b>Cross-validation process</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline, split_key=split_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d832924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f85778",
   "metadata": {},
   "source": [
    "<p><b>Test data preparing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca286c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data = test_transformer.adding_time_step(test_data)\n",
    "# test_dates['time'] = np.arange(len(X_dates.index), len(X_dates.index) + len(test_dates.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d75d5f9",
   "metadata": {},
   "source": [
    "<p><b>Training models and saving predictions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=365), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186efa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31181091",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission_file(test_data, model=modelling_pipeline, output_path='linreg_timestep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8fe4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf2348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4ec747b",
   "metadata": {},
   "source": [
    "# 3. Linear regression with 'store_nbr' and 'dcoilwtico' features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a6fdc",
   "metadata": {},
   "source": [
    "<p><b>Train data preparing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3edb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53101c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6feac",
   "metadata": {},
   "source": [
    "<p><b>Cross-validation process</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c20157",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = 'family'\n",
    "cols_to_scale = ['dcoilwtico']\n",
    "cols_to_encode = ['store_nbr']\n",
    "drop_columns = ['onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline, split_key=split_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55633978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08383291",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = scores_for_each_horizon(estimator=LinearRegression(), X=X, y=y, splitter=splitter, \\\n",
    "                                    base_pipeline=base_pipeline, split_key=split_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e93048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSLE for every day in the test set\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "x = list(cv_scores.keys())\n",
    "y = [np.mean(cv_scores[key]) for key in x]\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db729207",
   "metadata": {},
   "source": [
    "<p><b>Test data preparing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0de947",
   "metadata": {},
   "source": [
    "<p><b>Training models and saving predictions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceaf8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=365), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13883edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9906595",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission_file(test_data, model=modelling_pipeline, output_path='linreg_dcoilwtico.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bcb038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a3eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee4ef882",
   "metadata": {},
   "source": [
    "# 4. Linear regression with 'store_nbr', 'dcoilwtico' and 'time-step' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97097eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]\n",
    "X = train_transformer.adding_time_step(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f610673",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c22b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = 'family'\n",
    "cols_to_scale = ['dcoilwtico']\n",
    "cols_to_encode = ['store_nbr']\n",
    "drop_columns = ['onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline, split_key=split_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e788c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6733a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec331631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cfa0ee6",
   "metadata": {},
   "source": [
    "# 5. Linear Regression with 'store_nbr', 'dcoilwtico' and 'is_holiday' binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87006682",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]\n",
    "X.loc[:, 'is_holiday'] = train_transformer.adding_is_holiday_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba954fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c85296",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = 'family'\n",
    "cols_to_scale = ['dcoilwtico']\n",
    "cols_to_encode = ['store_nbr']\n",
    "drop_columns = ['onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline, split_key=split_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b27a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f399bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa19f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data.loc[:, 'is_holiday'] = train_transformer.adding_is_holiday_feature(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b541f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=365), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02df5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f03cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission_file(test_data, model=modelling_pipeline, output_path='linreg_dcoilwtico_is_holiday.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e08d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea90aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3832804",
   "metadata": {},
   "source": [
    "# 6. Linear Regression with 'store_nbr', 'dcoilwtico' and 'store_type' features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeadcf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb52b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_transformer.adding_stores_data(X, columns_to_add=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0790be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f91959",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = 'family'\n",
    "cols_to_scale = ['dcoilwtico']\n",
    "cols_to_encode = ['store_nbr', 'store_type']\n",
    "drop_columns = ['onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cf1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline, split_key=split_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb869a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761cd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbde28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29508e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5dfb002",
   "metadata": {},
   "source": [
    "# 7. Linear Regression with 'store_nbr', 'dcoilwtico' and 'lag' feature (16 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b51570",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "dates_test_data = test_data['date'].unique()\n",
    "all_data = pd.concat([X, test_data])\n",
    "all_data['lag_16'] = all_data.groupby(['store_nbr', 'family'])['sales'].shift(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['lag_16'] = all_data[all_data['date'].isin(dates_test_data)]['lag_16']\n",
    "X['lag_16'] = all_data[~all_data['date'].isin(dates_test_data)]['lag_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ff7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc254695",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = 'family'\n",
    "cols_to_scale = ['dcoilwtico', 'lag_16']\n",
    "cols_to_encode = ['store_nbr']\n",
    "drop_columns = ['onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline, split_key=split_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce8c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58613c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cabd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=365), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission_file(test_data, model=modelling_pipeline, output_path='linreg_dcoilwtico_lag16.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f387f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a795f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc9e8b4c",
   "metadata": {},
   "source": [
    "# 8. Ridge Regression with 'store_nbr', 'dcoilwtico' and 'lag' feature (16 days), params: alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "\n",
    "test_dates = test_data['date'].unique()\n",
    "all_data = pd.concat([X, test_data])\n",
    "all_data['lag_16'] = all_data.groupby(['store_nbr', 'family'])['sales'].shift(16)\n",
    "\n",
    "test_data = all_data[all_data['date'].isin(test_dates)].drop(columns=['sales'])\n",
    "X = all_data[~all_data['date'].isin(test_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a568882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7241c05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_grid = {'alpha': np.array([0.01, 0.1, 1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = 'family'\n",
    "cols_to_scale = ['dcoilwtico']\n",
    "cols_to_encode = ['store_nbr']\n",
    "drop_columns = ['onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(model, X, y, base_pipeline, hyper_params_grid, tscv_inner, tscv_outer, split_key, scoring):\n",
    "    scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "    for train_indices, test_indices in tscv_outer.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "        X_test, y_test = X.iloc[test_indices], y.iloc[test_indices]\n",
    "    \n",
    "        X_test.loc[:, 'pred'] = 0\n",
    "        for current_split_key_value in X[split_key].unique():\n",
    "            X_train_current_split_key_value = X_train[X_train[split_key] == current_split_key_value].drop(columns=split_key)\n",
    "            y_train_current_split_key_value = y_train.loc[X_train_current_split_key_value.index]\n",
    "            X_test_current_split_key_value = X_test[X_test[split_key] == current_split_key_value].drop(columns=split_key)\n",
    "            \n",
    "            X_train_current_split_key_value = base_pipeline.pipeline(X_train_current_split_key_value)\n",
    "            \n",
    "            params_tuning_model = GridSearchCV(estimator=model, param_grid=hyper_params_grid, scoring=scoring, cv=tscv_inner)\n",
    "            params_tuning_model.fit(X_train_current_split_key_value, y_train_current_split_key_value)\n",
    "            \n",
    "            model = model.set_params(**params_tuning_model.best_params_)\n",
    "            model = PositiveRegressor(model).fit(X_train_current_split_key_value, y_train_current_split_key_value)\n",
    "            \n",
    "            X_test_current_split_key_value = base_pipeline.pipeline(X_test_current_split_key_value)\n",
    "            X_test.loc[X_test_current_split_key_value.index, 'pred'] = model.predict(X_test_current_split_key_value.drop(columns=['pred']))\n",
    "            \n",
    "        y_pred = X_test['pred'].copy()\n",
    "        scores['RMSLE'].append(mean_squared_log_error(y_test, y_pred, squared=False))\n",
    "        scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "        scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "        scores['R2'].append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ffbf97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tscv_inner = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR - 60) * N_STORES, n_splits=4,\n",
    "                             test_size=N_HORIZONS * N_STORES)\n",
    "tscv_outer = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * N_TIME_SERIES, n_splits=4,\n",
    "                             test_size=N_HORIZONS * N_TIME_SERIES)\n",
    "base_pipeline = PipelineRidgeV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "scores = nested_cv(model=Ridge(), X=X, y=y, base_pipeline=base_pipeline, hyper_params_grid=hyper_params_grid,\n",
    "                   tscv_inner=tscv_inner, tscv_outer=tscv_outer, split_key=split_key, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {np.mean(metric_values):.3f} ± {np.std(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cut_history(X=X, date_column='date', keep_interval=timedelta(days=365), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "tscv = TimeSeriesSplit(gap=0, max_train_size=(DAYS_IN_YEAR - 60) * N_STORES, n_splits=4, test_size=N_HORIZONS * N_STORES)\n",
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "for current_split_key_value in X[split_key].unique():\n",
    "    X_train_current_split_key_value = X_train[X_train[split_key] == current_split_key_value].drop(columns=split_key)\n",
    "    y_train_current_split_key_value = y_train.loc[X_train_current_split_key_value.index]\n",
    "    \n",
    "    base_pipeline = PipelineRidgeV1(cols_to_scale=cols_to_scale, cols_to_encode=cols_to_encode, drop_columns=drop_columns)\n",
    "    X_train_current_split_key_value = base_pipeline.pipeline(X_train_current_split_key_value)\n",
    "    \n",
    "    params_tuning_model = GridSearchCV(estimator=Ridge(), param_grid=hyper_params_grid, cv=tscv)\n",
    "    params_tuning_model.fit(X_train_current_split_key_value, y_train_current_split_key_value)\n",
    "    \n",
    "    model = Ridge(**params_tuning_model.best_params_).fit(X_train_current_split_key_value, y_train_current_split_key_value)\n",
    "    test_data_current_split_key_value = test_data[test_data[split_key] == current_split_key_value].drop(columns=split_key)\n",
    "    test_data_current_split_key_value = base_pipeline.pipeline(test_data_current_split_key_value)\n",
    "    \n",
    "    current_split_key_value_pred = model.predict(test_data_current_split_key_value)\n",
    "    current_split_key_value_pred[current_split_key_value_pred < 0] = 0\n",
    "    submission.loc[test_data_current_split_key_value.index, 'sales'] = current_split_key_value_pred\n",
    "    \n",
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/ridgereg_dcoilwtico_lag_sixteen.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b959d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac46965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4604335f",
   "metadata": {},
   "source": [
    "# *9. Lasso Regression with 'store_nbr', 'dcoilwtico' and 'lag' feature (16 days), params: alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d00259",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "dates_test_data = test_data['date'].unique()\n",
    "all_data = pd.concat([X, test_data])\n",
    "all_data['lag_16'] = all_data.groupby(['store_nbr', 'family'])['sales'].shift(16)\n",
    "\n",
    "test_data['lag_16'] = all_data[all_data['date'].isin(dates_test_data)]['lag_16']\n",
    "X['lag_16'] = X.groupby(['store_nbr', 'family'])['sales'].shift(16)\n",
    "\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]\n",
    "\n",
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321649c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {'alpha': np.array([0.001, 0.01, 0.1, 1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "for alpha in hyper_params['alpha']:\n",
    "    base_pipeline = PipelineLassoV1(num_columns=['dcoilwtico'], cat_columns=['store_nbr'], best_params=alpha)\n",
    "    modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)\n",
    "    \n",
    "    print('alpha: ', alpha)\n",
    "    print_cv_test_scores(scores)\n",
    "    print('/n/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e798519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf59c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fffb858",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipeline = PipelineLassoV1(num_columns=['dcoilwtico'], cat_columns=['store_nbr'], best_params=0.001)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bac515",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714df194",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "submission['sales'] = modelling_pipeline.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/lassoreg_dcoilwtico_lag_sixteen.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c309ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17dc1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fdf117c",
   "metadata": {},
   "source": [
    "# 10. Linear Regression with 'store_nbr', 'dcoilwtico' and 'lag' feature (16 days), params: alpha (ElasticNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39114a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv').drop(columns=['onpromotion'])\n",
    "dates_test_data = test_data['date'].unique()\n",
    "all_data = pd.concat([X, test_data])\n",
    "all_data['lag_16'] = all_data.groupby(['store_nbr', 'family'])['sales'].shift(16)\n",
    "\n",
    "test_data['lag_16'] = all_data[all_data['date'].isin(dates_test_data)]['lag_16']\n",
    "X['lag_16'] = X.groupby(['store_nbr', 'family'])['sales'].shift(16)\n",
    "\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]\n",
    "\n",
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef0351",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {'alpha': np.array([0.001, 0.01, 0.1, 1]), 'l1_ratio': np.array([0.05, 0.1, 0.15, 0.2, 0.3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255d965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "for alpha in hyper_params['alpha']:\n",
    "    for l1_ratio in hyper_params['l1_ratio']:\n",
    "        base_pipeline = PipelineElasticNetV1(num_columns=['dcoilwtico'], cat_columns=['store_nbr'], alpha=alpha, l1_ratio=l1_ratio)\n",
    "        modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)\n",
    "    \n",
    "        scores = cross_validate(\n",
    "            modelling_pipeline, X, y,\n",
    "            cv=splitter, scoring=CV_METRICS, return_estimator=True)\n",
    "    \n",
    "        print('alpha: ', alpha, 'l1_ratio: ', l1_ratio)\n",
    "        print_cv_test_scores(scores)\n",
    "        print('/n/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549dde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be547753",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train = X[X['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train = y.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380a349",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipeline = PipelineElasticNetV1(num_columns=['dcoilwtico'], cat_columns=['store_nbr'], alpha=0.001, l1_ratio=0.15)\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623397d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "submission['sales'] = modelling_pipeline.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d68b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/elasticnet_dcoilwtico_lag_sixteen.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9010d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1bb747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80da5a4e",
   "metadata": {},
   "source": [
    "# 11. Linear Regression with 'store_nbr', 'dcoilwtico', **'onpromotion' and 'lag' feature (16 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "dates_test_data = test_data['date'].unique()\n",
    "all_data = pd.concat([X, test_data])\n",
    "all_data['lag_16'] = all_data.groupby(['store_nbr', 'family'])['sales'].shift(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58921fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['lag_16'] = all_data[all_data['date'].isin(dates_test_data)]['lag_16']\n",
    "X['lag_16'] = X.groupby(['store_nbr', 'family'])['sales'].shift(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00181042",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d870c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "families_with_promo = ['beauty', 'beverages', 'home and kitchen ii', 'home care', 'produce', 'school and office supplies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e17dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_promo = X[X['family'].isin(families_with_promo)].index\n",
    "X_with_promo = X[X['family'].isin(families_with_promo)]\n",
    "y_with_promo = y.loc[indices_promo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca53806",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV1(num_columns=['dcoilwtico', 'onpromotion'], cat_columns=['store_nbr'])\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d02b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X_with_promo, y_with_promo,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8cd0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data_with_promo_indices = test_data[test_data['family'].isin(families_with_promo)].index\n",
    "test_data_with_promo = test_data[test_data['family'].isin(families_with_promo)]\n",
    "test_data_with_promo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6461c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X_with_promo['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X_with_promo[X_with_promo['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train_with_promo = X_with_promo[X_with_promo['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train_with_promo = y_with_promo.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68030745",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipeline = PipelineLinearV1(num_columns=['dcoilwtico', 'onpromotion'], cat_columns=['store_nbr'])\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22097a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train_with_promo, y_train_with_promo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38257459",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d15ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission.loc[test_data_with_promo_indices, 'sales'] = modelling_pipeline.predict(test_data_with_promo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_without_promo = X[~X['family'].isin(families_with_promo)].index\n",
    "X_without_promo = X[~X['family'].isin(families_with_promo)]\n",
    "y_without_promo = y.loc[indices_without_promo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe15a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV1(num_columns=['dcoilwtico'], cat_columns=['store_nbr'])\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef0d10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X_without_promo, y_without_promo,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69843855",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46010f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_without_promo_indices = test_data[~test_data['family'].isin(families_with_promo)].index\n",
    "test_data_without_promo = test_data[~test_data['family'].isin(families_with_promo)]\n",
    "test_data_without_promo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5338728",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = X_without_promo[X_without_promo['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train_without_promo = X_without_promo[X_without_promo['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train_without_promo = y_without_promo.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd05c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipeline = PipelineLinearV1(num_columns=['dcoilwtico'], cat_columns=['store_nbr'])\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14676c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling_pipeline.fit(X_train_without_promo, y_train_without_promo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88723d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission.loc[test_data_without_promo_indices, 'sales'] = modelling_pipeline.predict(test_data_without_promo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f1576",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/linreg_dcoilwtico_lag_sixteen_promo.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f25e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80497087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b355d21",
   "metadata": {},
   "source": [
    "# 12. Linear Regression with 'store_nbr', 'dcoilwtico', 'store_city' and 'lag' feature (16 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72733ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy().drop(columns='onpromotion')\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27473b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_transformer.adding_stores_data(X, columns_to_add=['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fcf111",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a92e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfd03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = DateTimeSeriesSplit()\n",
    "base_pipeline = PipelineLinearV1(num_columns=['dcoilwtico'], cat_columns=['store_nbr', 'store_city'])\n",
    "modelling_pipeline = SplitPipeline(base_pipeline=base_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60150e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "        modelling_pipeline, X, y,\n",
    "        cv=splitter, scoring=CV_METRICS, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_test_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff242d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2895f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec9de55a",
   "metadata": {},
   "source": [
    "# 13. Linear Regression with 'store_nbr', 'dcoilwtico', **'onpromotion' and 'lag' feature (1 day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "train_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "X = train_transformer.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ff078",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['lag_1'] = X.groupby(['store_nbr', 'family'])['sales'].shift()\n",
    "\n",
    "y = X['sales'].copy()\n",
    "X = X.drop(columns='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e84da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=['store_nbr'], drop_first=True)\n",
    "lag_1 = X['lag_1'].copy()\n",
    "X = X.drop(columns=['lag_1'])\n",
    "X['lag_1'] = lag_1\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e66917",
   "metadata": {},
   "outputs": [],
   "source": [
    "families_with_promo = ['beauty', 'beverages', 'home and kitchen ii', 'home care', 'produce', 'school and office supplies']\n",
    "families_without_promo = [family for family in X['family'].unique() if family not in families_with_promo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96847a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv_promo = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * len(families_with_promo) * N_STORES, n_splits=4,\n",
    "                             test_size=N_HORIZONS * len(families_with_promo) * N_STORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2485c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_promo = X[X['family'].isin(families_with_promo)].index\n",
    "X_with_promo = X[X['family'].isin(families_with_promo)].copy()\n",
    "y_with_promo = y.loc[indices_promo].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv_promo.split(X_with_promo, y_with_promo):\n",
    "    X_train = X_with_promo.iloc[train_indices]\n",
    "    y_train = y_with_promo.iloc[train_indices]\n",
    "    X_test = X_with_promo.iloc[test_indices]\n",
    "    y_test = y_with_promo.iloc[test_indices]\n",
    "\n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in families_with_promo:\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        scaler_oil = MinMaxScaler()\n",
    "        scaler_promo = MinMaxScaler()\n",
    "        X_train_current_family[['dcoilwtico']] = scaler_oil.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "        X_train_current_family[['onpromotion']] = scaler_promo.fit_transform(X_train_current_family[['onpromotion']])\n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        \n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=['family'])\n",
    "        X_test_current_family[['dcoilwtico']] = scaler_oil.transform(X_test_current_family[['dcoilwtico']])\n",
    "        X_test_current_family[['onpromotion']] = scaler_promo.transform(X_test_current_family[['onpromotion']])\n",
    "\n",
    "        previous_day = X_test_current_family['date'].unique()[0]\n",
    "        for current_day in X_test_current_family['date'].unique()[1:]:\n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == previous_day].drop(columns=['pred', 'date'])\n",
    "            predictions = model.predict(X_test_for_current_day)\n",
    "    \n",
    "            #######\n",
    "            X_test_current_family.loc[X_test_current_family['date'] == current_day, 'lag_1'] = predictions\n",
    "            #######\n",
    "            \n",
    "            previous_day = current_day\n",
    "            \n",
    "            \n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "             \n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    scores['RMSLE'].append(mean_squared_log_error(y_test, y_pred, squared=False))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))\n",
    "          \n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {np.mean(metric_values):.3f} ± {np.std(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv_without_promo = TimeSeriesSplit(gap=0, max_train_size=DAYS_IN_YEAR * len(families_without_promo) * N_STORES, n_splits=4, \n",
    "                                     test_size=N_HORIZONS * len(families_without_promo) * N_STORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_without_promo = X[X['family'].isin(families_without_promo)].index\n",
    "X_without_promo = X[X['family'].isin(families_without_promo)].copy().drop(columns=['onpromotion'])\n",
    "y_without_promo = y.loc[indices_without_promo].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cff2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'RMSLE': [], 'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_indices, test_indices in tscv_without_promo.split(X_without_promo, y_without_promo):\n",
    "    X_train = X_without_promo.iloc[train_indices]\n",
    "    y_train = y_without_promo.iloc[train_indices]\n",
    "    X_test = X_without_promo.iloc[test_indices]\n",
    "    y_test = y_without_promo.iloc[test_indices]\n",
    "    \n",
    "    X_test.loc[:, 'pred'] = 0\n",
    "    for current_family in families_without_promo:\n",
    "        current_family_indices_train = X_train[X_train['family'] == current_family].index\n",
    "        X_train_current_family = X_train[X_train['family'] == current_family].drop(columns=['family'])\n",
    "        y_train_current_family = y_train.loc[current_family_indices_train]\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_current_family[['dcoilwtico']] = scaler.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "        model = PositiveRegressor(LinearRegression())\n",
    "        model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "        \n",
    "        \n",
    "        current_family_indices_test = X_test[X_test['family'] == current_family].index\n",
    "        X_test_current_family = X_test[X_test['family'] == current_family].drop(columns=['family'])\n",
    "        X_test_current_family[['dcoilwtico']] = scaler.transform(X_test_current_family[['dcoilwtico']])\n",
    "        \n",
    "        previous_day = X_test_current_family['date'].unique()[0]\n",
    "        for current_day in X_test_current_family['date'].unique()[1:]:\n",
    "            X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == previous_day].drop(columns=['date', 'pred'])\n",
    "            predictions = model.predict(X_test_for_current_day)\n",
    "    \n",
    "            #######\n",
    "            X_test_current_family.loc[X_test_current_family['date'] == current_day, 'lag_1'] = predictions\n",
    "            #######\n",
    "            \n",
    "            previous_day = current_day\n",
    "            \n",
    "\n",
    "        y_pred_current_family = model.predict(X_test_current_family.drop(columns=['date', 'pred']))\n",
    "        X_test.loc[current_family_indices_test, 'pred'] = y_pred_current_family\n",
    "\n",
    "    y_pred = X_test['pred'].copy()\n",
    "    X_test = X_test.drop(columns=['pred'])\n",
    "    scores['RMSLE'].append(mean_squared_log_error(y_test, y_pred, squared=False))\n",
    "    scores['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "    scores['MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "    scores['R2'].append(r2_score(y_test, y_pred))   \n",
    "      \n",
    "for metric_name, metric_values in scores.items():\n",
    "    print(f'{metric_name}: {np.mean(metric_values):.3f} ± {np.std(metric_values):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf160026",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day_of_last_year = pd.to_datetime(X['date'].unique()[-1]) - timedelta(days=365)\n",
    "indexer = X_with_promo[X_with_promo['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train_promo = X_with_promo[X_with_promo['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train_promo = y_with_promo.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e05733",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_ROOT / 'test.csv')\n",
    "test_transformer = ETLTransformer(date_column='date', id_column='id')\n",
    "test_data = test_transformer.transform(test_data)[0]\n",
    "test_data = pd.get_dummies(test_data, columns=['store_nbr'], drop_first=True)\n",
    "test_data['lag_1'] = 0\n",
    "test_data_with_promo = test_data[test_data['family'].isin(families_with_promo)]\n",
    "test_data_with_promo.loc[test_data_with_promo[test_data_with_promo['date'] == test_data_with_promo['date'].unique()[0]].index, 'lag_1'] = y_train_promo.loc[X_train_promo['date'] == X_train_promo['date'].unique()[-1]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(DATA_ROOT / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ce6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_family in families_with_promo:\n",
    "    current_family_indices_train = X_train_promo[X_train_promo['family'] == current_family].index\n",
    "    X_train_current_family = X_train_promo[X_train_promo['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train_promo.loc[current_family_indices_train]\n",
    "    scaler_oil = MinMaxScaler()\n",
    "    scaler_promo = MinMaxScaler()\n",
    "    X_train_current_family[['dcoilwtico']] = scaler_oil.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "    X_train_current_family[['onpromotion']] = scaler_promo.fit_transform(X_train_current_family[['onpromotion']])\n",
    "    \n",
    "    model = PositiveRegressor(LinearRegression())\n",
    "    model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    \n",
    "    X_test_current_family = test_data_with_promo[test_data_with_promo['family'] == current_family].drop(columns=['family'])\n",
    "    \n",
    "    X_test_current_family[['dcoilwtico']] = scaler_oil.transform(X_test_current_family[['dcoilwtico']])\n",
    "    X_test_current_family[['onpromotion']] = scaler_promo.transform(X_test_current_family[['onpromotion']])\n",
    "    \n",
    "    previous_day = X_test_current_family['date'].unique()[0]\n",
    "    for current_day in X_test_current_family['date'].unique()[1:]:\n",
    "        X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == previous_day].drop('date', axis=1)\n",
    "        predictions = model.predict(X_test_for_current_day)\n",
    "        X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day].index, 'lag_1'] = predictions\n",
    "        previous_day = current_day\n",
    "            \n",
    "    X_test_current_family = X_test_current_family.drop(columns=['date'])\n",
    "        \n",
    "    y_pred_current_family = model.predict(X_test_current_family)\n",
    "        \n",
    "    test_indices = test_data_with_promo[test_data_with_promo['family'] == current_family].index\n",
    "    submission.loc[test_indices, 'sales'] = y_pred_current_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = X_without_promo[X_without_promo['date'] >= str(first_day_of_last_year).split(' ')[0]].index\n",
    "X_train_without_promo = X_without_promo[X_without_promo['date'] >= str(first_day_of_last_year).split(' ')[0]]\n",
    "y_train_without_promo = y_without_promo.loc[indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0db5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_without_promo = test_data[test_data['family'].isin(families_without_promo)].drop(columns=['onpromotion'])\n",
    "test_data_without_promo.loc[test_data_without_promo[test_data_without_promo['date'] == test_data_without_promo['date'].unique()[0]].index, 'lag_1'] = y_train_without_promo.loc[X_train_without_promo['date'] == X_train_without_promo['date'].unique()[-1]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4687becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_family in families_without_promo:\n",
    "    current_family_indices_train = X_train_without_promo[X_train_without_promo['family'] == current_family].index\n",
    "    X_train_current_family = X_train_without_promo[X_train_without_promo['family'] == current_family].drop(columns=['family'])\n",
    "    y_train_current_family = y_train_without_promo.loc[current_family_indices_train]\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_current_family[['dcoilwtico']] = scaler.fit_transform(X_train_current_family[['dcoilwtico']])\n",
    "    model = PositiveRegressor(LinearRegression())\n",
    "    model.fit(X_train_current_family.drop(columns=['date']), y_train_current_family)\n",
    "    \n",
    "    X_test_current_family = test_data_without_promo[test_data_without_promo['family'] == current_family].drop(columns=['family'])\n",
    "    \n",
    "    X_test_current_family[['dcoilwtico']] = scaler.transform(X_test_current_family[['dcoilwtico']])\n",
    "    \n",
    "    previous_day = X_test_current_family['date'].unique()[0]\n",
    "    for current_day in X_test_current_family['date'].unique()[1:]:\n",
    "        X_test_for_current_day = X_test_current_family[X_test_current_family['date'] == previous_day].drop('date', axis=1)\n",
    "        predictions = model.predict(X_test_for_current_day)\n",
    "        X_test_current_family.loc[X_test_current_family[X_test_current_family['date'] == current_day].index, 'lag_1'] = predictions\n",
    "        previous_day = current_day\n",
    "            \n",
    "    X_test_current_family = X_test_current_family.drop(columns=['date'])\n",
    "        \n",
    "    y_pred_current_family = model.predict(X_test_current_family)\n",
    "        \n",
    "    test_indices = test_data_without_promo[test_data_without_promo['family'] == current_family].index\n",
    "    submission.loc[test_indices, 'sales'] = y_pred_current_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22342999",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./data/kaggle/store-sales-time-series-forecasting/linreg_dcoilwtico_lag_one_and_promo.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa831b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7feff62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
