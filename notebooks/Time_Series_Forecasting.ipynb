{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Su5oVLIL-GK5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "1jUWQVXZ-HOs",
    "outputId": "28317993-f1b2-44c1-d468-1fd00fb58f0f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('C:\\\\Users\\\\Owner\\\\Desktop\\\\Proga\\\\REPOS\\\\mentorship_EPAM\\\\data\\\\train.csv', index_col = \"id\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"family\"] = train_data[\"family\"].str.lower()     # for easier reading \n",
    "train_data.describe(percentiles=[.25, 0.375, .5, .75, .875]).drop([\"count\"])       \n",
    "\n",
    "# I dropped \"count\" row to get rid of exponentioal number presentation\n",
    "# And added .875 percentile to understand approximately how many objects have no onpromotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yDCEDYYGveo",
    "outputId": "839affcc-2928-4892-c798-459ff56b59f0"
   },
   "outputs": [],
   "source": [
    "train_data[\"family\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>The only categorical feature (in this table) \"family\" has 33 possible unique values (not so a lot) <br>\n",
    "That means we can easily use one-hot-encoding during model training</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_values = train_data[\"family\"].unique()\n",
    "family_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "for i, value in zip(range(len(family_values)), family_values):\n",
    "  plt.subplot(len(family_values)//3, 3, i+1)\n",
    "  current_value_data = train_data[train_data[\"family\"] == value].groupby([\"date\"]).mean()\n",
    "  plt.xlim=(0, 1750)\n",
    "  plt.ylim=(0, current_value_data[\"sales\"].max())\n",
    "  plt.scatter(x=np.arange(len(current_value_data.index)), y=current_value_data[\"sales\"])\n",
    "  plt.title(value)\n",
    "plt.xlim=(0, 1750)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Actually, these plots don't really help us, because, looking on them, we can only catch some common \"trends\", which describe global changes in some products sales.<br>For example, we can be sure that on the 1th January every year number of sales is equal to 0 (actually, it is necessary to check, but I think it is obvious). <br> Also we can say that the number of sales in general has a positive dynamic (for example, 'automotive', 'bread/bakery', 'grocery i', 'personal care', ...).<br>Some of the product types have a negative dynamic (such as lingerie).<br>Some goods have very interesting sales distribution (books, produce, froxen foods, ladieswear, ...), and we can't say right now, what is the reason of that.<br>Also some goods families have seasonal increase in sales('school and office supplies', 'liquor, wine, beer', 'grocery ii', 'frozen foods'). </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 110))\n",
    "for i, family_value in zip(range(len(family_values)), family_values):\n",
    "    plt.subplot(17, 2, i+1)\n",
    "    average_sales = train_data[train_data['family'] == family_value].groupby('date').mean()['sales']\n",
    "    trend = average_sales.rolling(\n",
    "        window=365,\n",
    "        center=True,\n",
    "        min_periods=183,\n",
    "    ).mean()\n",
    "    ax = average_sales.plot(alpha=0.5)\n",
    "    ax = trend.plot(ax=ax, linewidth=3)\n",
    "    plt.title(family_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 70))\n",
    "for i, value in zip(range(len(family_values)), family_values):\n",
    "  plt.subplot(len(family_values)//3, 3, i+1)\n",
    "  current_value_data = train_data[train_data['family'] == value].groupby([\"date\"]).mean()\n",
    "  sns.distplot(current_value_data['sales'], color='g', bins=100, hist_kws={'alpha': 0.4});\n",
    "  plt.title(value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>These plots show that, roughly speaking, sales distributions of all families divided on two parts: <br>1) Normal or close to normal (such as 'automotive', 'bread/bakery', 'cleaning', 'eggs', 'grocery', 'lingerie', ...). Interesting fact that most of distributions from this category have right asymmetry (asymmetry coefficient is positive). The prove is below.<br>2) Distribution, where the biggest density is concentrated in zero or near zero. Other data is distributed differently (some values such as 'home and kitchen i', 'ladieswear' have something like normal distributions). It means that such goods categories aren't essential for people, that is why a number of sales during the day mostly is equal to 0.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in family_values:\n",
    "    print(value, ': ', round(train_data[train_data['family'] == value].groupby([\"date\"]).mean().skew()['sales'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_and_onpromotion_data = train_data.drop(['date', 'store_nbr', 'family'], axis=1)\n",
    "sales_and_onpromotion_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "for i, value in zip(range(len(family_values)), family_values):\n",
    "  plt.subplot(len(family_values)//3, 3, i+1)\n",
    "  current_value_data = train_data[train_data[\"family\"] == value].groupby([\"date\"]).mean()\n",
    "  plt.scatter(x='onpromotion', y='sales', data=current_value_data)\n",
    "  plt.title(value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>It becomes understandable that promotions have a pretty good influence on sales INCREASING (in general, talking about all the data).<br>As we can see on the plots above, most of the 'family' values (but not all of them!) prove this fact. Interesting fact that 'books' didn't have any promotions during he whole period of observations.<br>Moreover, correlation is influenced by outliers, so this coefficient may not be accurate.<br>Nevertheless, 'onpromotion' feature is useful for the predictions.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stores_data = pd.read_csv('C:\\\\Users\\\\Owner\\\\Desktop\\\\Proga\\\\REPOS\\\\mentorship_EPAM\\\\data\\\\stores.csv')\n",
    "stores_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Store id doesn't help itself with the sales predictions, so it is necessary to replace the store id with the corresponding information about it</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.merge(stores_data, on=\"store_nbr\", how=\"left\")\n",
    "train_data = train_data.drop('store_nbr', axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of \\'city\\', \\'state\\', \\'type\\' unique values: \\n')\n",
    "for feature in ['city', 'state', 'type']:\n",
    "    print(feature, len(train_data[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,9))\n",
    "sns.countplot(x=train_data['city'], alpha=0.7, data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,9))\n",
    "sns.countplot(x=train_data['state'], alpha=0.7, data=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>It seems that the presence of both features 'state' and 'city' isn't necessary, that is why we should delete one of them.<br>I'll choose 'state' feature, because 'city' feature gives us more information (there can be few cities in the state).<br>'city' feature has only 7 more values than 'state' feature, that is why speaking about the model complexity, there should not be much difference.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('state', axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "train_data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 100))\n",
    "for i, family_value in zip(range(len(family_values)), family_values):\n",
    "  plt.subplot(17, 2, i+1)\n",
    "  for city in train_data_copy['city'].unique():\n",
    "      average_sales = train_data_copy[(train_data_copy['family'] == family_value) &\n",
    "                                 (train_data_copy['city'] == city)].groupby('date').mean()['sales']\n",
    "      trend = average_sales.rolling(\n",
    "          window=365,\n",
    "          center=True,\n",
    "          min_periods=183,\n",
    "      ).mean()\n",
    "      ax = average_sales.plot(alpha=0)\n",
    "      ax = trend.plot(ax=ax, linewidth=3)\n",
    "  plt.title(family_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x=train_data['type'], alpha=0.7, data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 100))\n",
    "for i, family_value in zip(range(len(family_values)), family_values):\n",
    "  plt.subplot(17, 2, i+1)\n",
    "  for store_type in train_data_copy['type'].unique():\n",
    "      #plt.plot(np.arange(len(current_type_and_family_data.index)), current_type_and_family_data['sales'])\n",
    "      average_sales = train_data_copy[(train_data_copy['family'] == family_value) &\n",
    "                                 (train_data_copy['type'] == store_type)].groupby('date').mean()['sales']\n",
    "      trend = average_sales.rolling(\n",
    "          window=365,\n",
    "          center=True,\n",
    "          min_periods=183,\n",
    "      ).mean()\n",
    "      ax = average_sales.plot(alpha=0)\n",
    "      ax = trend.plot(ax=ax, linewidth=3)\n",
    "  plt.title(family_value)\n",
    "  plt.legend(train_data_copy['type'].unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>As we can see, the store type has a great impact on the target (type D is leader and it is logical, because the plot above shows us, that type D stores are the most), that is why 'type' feature is very important.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x=train_data['cluster'], alpha=0.7, data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sales_and_cluster_data = train_data_copy.drop(['date', 'family', 'onpromotion', 'city', 'type'], axis=1)\n",
    "sales_and_cluster_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figsize=(10, 7)\n",
    "plt.scatter(x='cluster', y='sales', data=sales_and_cluster_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>'cluster' feature doesn't correlate with the target, and I can't see any dependecies between these 2 features. But I think that this feature can be useful, because it connects similar stores together.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Tiavh7PK-HYv",
    "outputId": "4d198de7-7161-4413-eefa-45b6201bd547"
   },
   "outputs": [],
   "source": [
    "oil_data = pd.read_csv('C:\\\\Users\\\\Owner\\\\Desktop\\\\Proga\\\\REPOS\\\\mentorship_EPAM\\\\data\\\\oil.csv')\n",
    "oil_data[\"time\"] = np.arange(len(oil_data.index))\n",
    "oil_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDbzS7RpNnKK",
    "outputId": "ef457345-a324-40da-db3e-6a7362248416"
   },
   "outputs": [],
   "source": [
    "oil_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Bt59gF6ePlOZ",
    "outputId": "9af1e0e1-f125-40ef-ba81-c9c889b7ba91"
   },
   "outputs": [],
   "source": [
    "oil_data_copy = oil_data.copy()\n",
    "oil_data_copy.plot(kind=\"scatter\", x=\"time\", y=\"dcoilwtico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.merge(oil_data, on='date', how=\"left\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_oil = train_data.fillna(train_data['dcoilwtico'].mean())\n",
    "train_data_oil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_oil.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_events_data = pd.read_csv('C:\\\\Users\\\\Owner\\\\Desktop\\\\Proga\\\\REPOS\\\\mentorship_EPAM\\\\data\\\\holidays_events.csv')\n",
    "holidays_events_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NURqer_T-HVH",
    "outputId": "855d832d-b8f2-4e74-989b-3759665e01b0"
   },
   "outputs": [],
   "source": [
    "transactions_data = pd.read_csv('C:\\\\Users\\\\Owner\\\\Desktop\\\\Proga\\\\REPOS\\\\mentorship_EPAM\\\\data\\\\transactions.csv')\n",
    "transactions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xsgHqzXzGC4V",
    "outputId": "1de2f810-16ef-4a0d-b4aa-68f446c26749"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sqAeouXFGC68",
    "outputId": "d5d04706-877d-4f22-f34d-dd3c4f448bab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Io6f4l_3GDBN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Time_Series_Forecasting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
